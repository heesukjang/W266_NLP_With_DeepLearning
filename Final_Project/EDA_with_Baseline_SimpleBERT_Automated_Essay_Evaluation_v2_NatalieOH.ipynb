{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heesukjang/W266_NLP_With_DeepLearning/blob/main/Final_Project/EDA_with_Baseline_SimpleBERT_Automated_Essay_Evaluation_v2_NatalieOH.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline: A Simple Pre-Trained BERT for the Text Classification - Automated "
      ],
      "metadata": {
        "id": "C07W8FRxqtjH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To set up a BERT model for a classification task using essays as an input, you can follow these general steps:\n",
        "\n",
        "1. Data preprocessing: Preprocess the essays by tokenizing them into individual words and applying any necessary cleaning or normalization techniques.\n",
        "\n",
        "2. Data splitting: Split the preprocessed essays into training, validation, and test sets.\n",
        "\n",
        "3. Model architecture: Choose a pre-trained BERT model (e.g., BERT base, BERT large) and adapt it for your classification task by adding a classification layer on top of the BERT output.\n",
        "\n",
        "4. Fine-tuning: Fine-tune the pre-trained BERT model on the training set by minimizing a suitable loss function. During fine-tuning, the weights of the BERT model will be updated to better fit the specific classification task.\n",
        "\n",
        "5. Evaluation: Evaluate the fine-tuned model on the validation set to tune any hyperparameters (e.g., learning rate, number of epochs). After finalizing the hyperparameters, evaluate the model on the test set to obtain the final performance metrics.\n",
        "\n",
        "6. Inference: Use the trained BERT model to predict the classification label for new essays by passing them through the preprocessed and fine-tuned model.\n",
        "\n",
        "There are many libraries and frameworks available to help you set up a BERT model for classification tasks, such as Hugging Face's Transformers library in Python. You can find many tutorials and code examples online to help you get started."
      ],
      "metadata": {
        "id": "Jzl9h9_KqjCM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A sample Python code to train a BERT model for text classification using the PyTorch library:"
      ],
      "metadata": {
        "id": "rNMVaUGssu5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# from transformers import BertModel, BertTokenizer\n",
        "# from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# class MyDataset(Dataset):\n",
        "#     def __init__(self, data, tokenizer, max_len):\n",
        "#         self.tokenizer = tokenizer\n",
        "#         self.data = data\n",
        "#         self.max_len = max_len\n",
        "    \n",
        "#     def __len__(self):\n",
        "#         return len(self.data)\n",
        "    \n",
        "#     def __getitem__(self, index):\n",
        "#         text = self.data[index]['text']\n",
        "#         label = self.data[index]['label']\n",
        "#         encoding = self.tokenizer.encode_plus(\n",
        "#             text,\n",
        "#             add_special_tokens=True,\n",
        "#             max_length=self.max_len,\n",
        "#             padding='max_length',\n",
        "#             truncation=True,\n",
        "#             return_attention_mask=True,\n",
        "#             return_tensors='pt',\n",
        "#         )\n",
        "#         return {\n",
        "#             'text': text,\n",
        "#             'input_ids': encoding['input_ids'].flatten(),\n",
        "#             'attention_mask': encoding['attention_mask'].flatten(),\n",
        "#             'label': torch.tensor(label, dtype=torch.long)\n",
        "#         }\n",
        "\n",
        "# class BERTClassifier(nn.Module):\n",
        "#     def __init__(self, num_classes):\n",
        "#         super(BERTClassifier, self).__init__()\n",
        "#         self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "#         self.dropout = nn.Dropout(p=0.1)\n",
        "#         self.classifier = nn.Linear(self.bert.config.hidden_size, num_classes)\n",
        "    \n",
        "#     def forward(self, input_ids, attention_mask):\n",
        "#         output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "#         output = self.dropout(output.pooler_output)\n",
        "#         output = self.classifier(output)\n",
        "#         return output\n",
        "\n",
        "# def train(model, train_loader, criterion, optimizer, device):\n",
        "#     model.train()\n",
        "#     train_loss = 0.0\n",
        "#     correct = 0\n",
        "#     total = 0\n",
        "#     for batch in train_loader:\n",
        "#         input_ids = batch['input_ids'].to(device)\n",
        "#         attention_mask = batch['attention_mask'].to(device)\n",
        "#         label = batch['label'].to(device)\n",
        "#         optimizer.zero_grad()\n",
        "#         output = model(input_ids, attention_mask)\n",
        "#         loss = criterion(output, label)\n",
        "#         train_loss += loss.item() * input_ids.size(0)\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "#         pred = torch.argmax(output, dim=1)\n",
        "#         correct += (pred == label).sum().item()\n",
        "#         total += input_ids.size(0)\n",
        "#     train_acc = 100 * correct / total\n",
        "#     train_loss = train_loss / total\n",
        "#     return train_loss, train_acc\n",
        "\n",
        "# def validate(model, val_loader, criterion, device):\n",
        "#     model.eval()\n",
        "#     val_loss = 0.0\n",
        "#     correct = 0\n",
        "#     total = 0\n",
        "#     with torch.no_grad():\n",
        "#         for batch in val_loader:\n",
        "#             input_ids = batch['input_ids'].to(device)\n",
        "#             attention_mask = batch['attention_mask'].to(device)\n",
        "#             label = batch['label'].to(device)\n",
        "#             output = model(input_ids, attention_mask)\n",
        "#             loss = criterion(output, label)\n",
        "#             val_loss += loss.item() * input_ids.size(0)\n",
        "#             pred = torch.argmax(output, dim=1)\n",
        "#             correct += (pred == label).sum().item()\n",
        "#             total += input_ids.size(0)\n",
        "#     val_acc = 100 * correct / total\n",
        "#     val_loss = val_loss / total\n",
        "#     return val_loss, val_acc\n",
        "\n",
        "# def train_model(train_data, val_data, batch_size, max_len, num_classes, num_epochs, learning_rate, device):\n",
        "#     tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "#     train_dataset = MyDataset(train_data, tokenizer, max\n",
        "\n",
        "\n",
        "# Regenerate response\n"
      ],
      "metadata": {
        "id": "Qr4bY23Ds2gX"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36uPk8UpIAar",
        "outputId": "bf8cc0cf-11b1-4b83-c9fc-7026d9530f36"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.26.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wordcloud"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1uKKcEclcxx",
        "outputId": "6ca65bcc-4fb3-4b43-a739-7306e5e6211a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.8/dist-packages (1.8.2.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from wordcloud) (8.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from wordcloud) (3.5.3)\n",
            "Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.8/dist-packages (from wordcloud) (1.22.4)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->wordcloud) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->wordcloud) (23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib->wordcloud) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->wordcloud) (0.11.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->wordcloud) (3.0.9)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->wordcloud) (4.38.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "print(f'transformers version: {transformers.__version__}')\n",
        "from transformers import logging as hf_logging\n",
        "hf_logging.set_verbosity_error()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xc2cOvvaIESK",
        "outputId": "bd6c4941-77bb-4a6f-f9d3-85e7de5e2d55"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "transformers version: 4.26.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from wordcloud import WordCloud\n",
        "from wordcloud import STOPWORDS\n",
        "from wordcloud import ImageColorGenerator\n",
        "import sys\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils.layer_utils import count_params\n",
        "\n",
        "from tensorflow.keras.layers import RandomFlip\n",
        "from tensorflow.keras.layers import RandomZoom\n",
        "from tensorflow.keras.layers import RandomRotation\n",
        "from tensorflow.keras.layers import Conv1D\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Concatenate\n",
        "from tensorflow.keras.layers import MaxPooling1D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import GlobalMaxPooling2D\n",
        "from tensorflow.keras.layers import GlobalAveragePooling1D\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import Lambda\n",
        "from tensorflow.keras.layers import Multiply\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Bidirectional\n",
        "from tensorflow.keras.layers import PReLU\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.convolutional import SeparableConv1D\n",
        "from keras.layers.convolutional import SeparableConv2D\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.applications.densenet import *\n",
        "from keras.applications.resnet import ResNet152\n",
        "from keras.applications.nasnet import NASNetMobile\n",
        "from keras.applications.nasnet import NASNetLarge\n",
        "from keras.applications.efficientnet import EfficientNetB7\n",
        "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
        "from keras.applications.nasnet import preprocess_input\n",
        "from keras.applications import MobileNetV2\n",
        "from keras.applications.xception import Xception\n",
        "from keras.applications.inception_v3 import *\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import array_to_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import save_img\n",
        "\n",
        "from tensorflow.python.ops.numpy_ops import np_config\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "\n",
        "from tensorflow.keras.losses import mae\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "\n",
        "from keras.models import Model\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.regularizers import l1\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.models import load_model\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iydyyeUzGgGh",
        "outputId": "ab959794-8e3e-44d3-ab0d-10782f56ef97"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def set_seed(seed = 99):\n",
        "#     np.random.seed(seed)\n",
        "#     tf.random.set_seed(seed)\n",
        "#     os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "#     os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/MyDrive/Kaggle\"\n",
        "\n",
        "# set_seed(20230214)"
      ],
      "metadata": {
        "id": "c1xyrAakIN6N"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pd.set_option('display.max_columns', None)\n",
        "# pd.set_option('display.max_columns', None)"
      ],
      "metadata": {
        "id": "N3wsPqDpbyKe"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build a classifier for each rubric metric i.e. cohesion, vocab, etc\n",
        "## Evaluatio metrics (possibly use ChatGPT to produce reference essays):\n",
        "- BLUE score\n",
        "- ROUGE score"
      ],
      "metadata": {
        "id": "wa5FdRVWPx5K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/content/gdrive/MyDrive/Kaggle/train.csv'\n",
        "test_path = '/content/gdrive/MyDrive/Kaggle/test.csv'\n",
        "\n",
        "train_df = pd.read_csv(train_path)\n",
        "test_df = pd.read_csv(test_path)"
      ],
      "metadata": {
        "id": "VX90lv6fIN9a"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generally, the training and validation data set is split into an 80:20 ratio. Thus, 20% of the data is set aside for validation purposes. The ratio changes based on the size of the data."
      ],
      "metadata": {
        "id": "Nss2jbPXOVsj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "CvQNiv_FIOA0",
        "outputId": "fdd3319a-5530-40be-dba8-05804577878a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        text_id                                          full_text  cohesion  \\\n",
              "0  0016926B079C  I think that students would benefit from learn...       3.5   \n",
              "1  0022683E9EA5  When a problem is a change you have to let it ...       2.5   \n",
              "2  00299B378633  Dear, Principal\\n\\nIf u change the school poli...       3.0   \n",
              "3  003885A45F42  The best time in life is when you become yours...       4.5   \n",
              "4  0049B1DF5CCC  Small act of kindness can impact in other peop...       2.5   \n",
              "\n",
              "   syntax  vocabulary  phraseology  grammar  conventions  \n",
              "0     3.5         3.0          3.0      4.0          3.0  \n",
              "1     2.5         3.0          2.0      2.0          2.5  \n",
              "2     3.5         3.0          3.0      3.0          2.5  \n",
              "3     4.5         4.5          4.5      4.0          5.0  \n",
              "4     3.0         3.0          3.0      2.5          2.5  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-008eaf17-1e1b-4b4d-a0f6-2de94bfc2989\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_id</th>\n",
              "      <th>full_text</th>\n",
              "      <th>cohesion</th>\n",
              "      <th>syntax</th>\n",
              "      <th>vocabulary</th>\n",
              "      <th>phraseology</th>\n",
              "      <th>grammar</th>\n",
              "      <th>conventions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0016926B079C</td>\n",
              "      <td>I think that students would benefit from learn...</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0022683E9EA5</td>\n",
              "      <td>When a problem is a change you have to let it ...</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00299B378633</td>\n",
              "      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>003885A45F42</td>\n",
              "      <td>The best time in life is when you become yours...</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0049B1DF5CCC</td>\n",
              "      <td>Small act of kindness can impact in other peop...</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-008eaf17-1e1b-4b4d-a0f6-2de94bfc2989')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-008eaf17-1e1b-4b4d-a0f6-2de94bfc2989 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-008eaf17-1e1b-4b4d-a0f6-2de94bfc2989');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "pgtye2X4IOK0",
        "outputId": "cc68c039-63a9-4943-84da-c3ba4faba826"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        text_id                                          full_text\n",
              "0  0000C359D63E  when a person has no experience on a job their...\n",
              "1  000BAD50D026  Do you think students would benefit from being...\n",
              "2  00367BB2546B  Thomas Jefferson once states that \"it is wonde..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ab2940a9-a34d-401c-8eb1-060f63671de5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_id</th>\n",
              "      <th>full_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000C359D63E</td>\n",
              "      <td>when a person has no experience on a job their...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000BAD50D026</td>\n",
              "      <td>Do you think students would benefit from being...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00367BB2546B</td>\n",
              "      <td>Thomas Jefferson once states that \"it is wonde...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ab2940a9-a34d-401c-8eb1-060f63671de5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ab2940a9-a34d-401c-8eb1-060f63671de5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ab2940a9-a34d-401c-8eb1-060f63671de5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# add new columns for aggregation: 'average_score', 'total_score', and 'total_score_in_perc'\n",
        "print(train_df.columns)\n",
        "cols = ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n",
        "\n",
        "# row-wise aggregation\n",
        "total_points = 30\n",
        "train_df['avg_score'] = train_df[cols].mean(axis=1).round(1)\n",
        "train_df['total_score'] = train_df[cols].sum(axis=1)\n",
        "train_df['final_score_in_perc'] = (train_df[cols].sum(axis=1)/total_points*100).round(1)\n",
        "\n",
        "final_grades = []\n",
        "for score in train_df['final_score_in_perc']:\n",
        "  if score < 60:\n",
        "    final_grades.append('F')\n",
        "  elif score < 70:\n",
        "    final_grades.append('D')\n",
        "  elif score < 80:\n",
        "    final_grades.append('C')\n",
        "  elif score < 90:\n",
        "    final_grades.append('B')\n",
        "  elif score < 95:\n",
        "    final_grades.append('A')\n",
        "  else:\n",
        "    final_grades.append('A+')    \n",
        "# print(final_grades)\n",
        "train_df['final_grade_letter'] = final_grades\n",
        "# cat_cohesion = pd.cut(train_df['cohesion'],[1,2,3,4,5])\n",
        "# train_df['cat_cohesion'] = cat_cohesion\n",
        "# train_df['num_label_cohesion'] = train_df['cat_cohesion'].cat.codes\n",
        "# train_df['str_label_cohesion'] = train_df.apply(lambda x: x['num_label_cohesion'])\n",
        "\n",
        "train_df[['full_text','cohesion']].head()"
      ],
      "metadata": {
        "id": "v5Zr_M9Eioex",
        "outputId": "35ad4467-5cd1-4e56-9842-da974b169f60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['text_id', 'full_text', 'cohesion', 'syntax', 'vocabulary',\n",
            "       'phraseology', 'grammar', 'conventions', 'avg_score', 'total_score',\n",
            "       'final_score_in_perc', 'final_grade_letter'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           full_text  cohesion\n",
              "0  I think that students would benefit from learn...       3.5\n",
              "1  When a problem is a change you have to let it ...       2.5\n",
              "2  Dear, Principal\\n\\nIf u change the school poli...       3.0\n",
              "3  The best time in life is when you become yours...       4.5\n",
              "4  Small act of kindness can impact in other peop...       2.5"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e2f1b996-0cf7-445c-9bbd-7101c602dcae\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>full_text</th>\n",
              "      <th>cohesion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I think that students would benefit from learn...</td>\n",
              "      <td>3.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>When a problem is a change you have to let it ...</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The best time in life is when you become yours...</td>\n",
              "      <td>4.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Small act of kindness can impact in other peop...</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e2f1b996-0cf7-445c-9bbd-7101c602dcae')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e2f1b996-0cf7-445c-9bbd-7101c602dcae button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e2f1b996-0cf7-445c-9bbd-7101c602dcae');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Unique Values in Each Metric:\\n==================================================')\n",
        "for col in cols:\n",
        "  print(f'{col}: {train_df[col].unique()}')"
      ],
      "metadata": {
        "id": "lwraTmbgxUw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create 5 point likert scale for each metric\n"
      ],
      "metadata": {
        "id": "8LOvOF8g2efS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z3aEKuYj2mZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wGUH108V2mRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.shape, test_df.shape"
      ],
      "metadata": {
        "id": "Ef7dkQIKIOQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.info()"
      ],
      "metadata": {
        "id": "tw8BrkKUavyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[train_df.final_score_in_perc >= 95]"
      ],
      "metadata": {
        "id": "5-c4m7N6Y_Ll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.describe()"
      ],
      "metadata": {
        "id": "a24hMTB0IOT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_cols = train_df.columns[2:]\n",
        "label_cols"
      ],
      "metadata": {
        "id": "5zhCwo3EIOVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[label_cols].drop_duplicates()"
      ],
      "metadata": {
        "id": "fySyzE9na2fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[label_cols].value_counts()"
      ],
      "metadata": {
        "id": "rHlRJSyxbF9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# label_cols = label_cols[:-1]\n",
        "label_cols"
      ],
      "metadata": {
        "id": "1aRBUiOTcihf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[train_df.total_score == 30][['full_text', 'avg_score', 'total_score', 'final_score_in_perc']]"
      ],
      "metadata": {
        "id": "RnU0aM72ccMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, len(label_cols), figsize=(20,4))\n",
        "\n",
        "for idx, label in enumerate(label_cols):\n",
        "    sns.histplot(x = label, \n",
        "                 data = train_df,\n",
        "                 ax = ax[idx]\n",
        "                )\n",
        "    ax[idx].set_title(label)\n",
        "    "
      ],
      "metadata": {
        "id": "D5oPta4FIOXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for label in label_cols[:-4]:\n",
        "    train_df[label + '_above_or_below_avg_flag'] = np.where(train_df[label] > np.mean(train_df[label]), 1, 0)"
      ],
      "metadata": {
        "id": "8R0r_nBQfoJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, len(label_cols[:-4]), figsize=(50,10))\n",
        "for idx, label in enumerate(label_cols[:-4]):\n",
        "    sns.countplot(x = train_df[label + '_above_or_below_avg_flag'], ax = ax[idx])\n",
        "    ax[idx].set_title(label)"
      ],
      "metadata": {
        "id": "NVZfLgRfgUaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr = train_df[label_cols].corr()\n",
        "\n",
        "# Generate a mask for the upper triangle\n",
        "mask = np.triu(np.ones_like(corr, dtype = bool))\n",
        "\n",
        "sns.set(rc = {\"figure.figsize\": (10, 8)})\n",
        "\n",
        "sns.heatmap(corr, \n",
        "            annot = True, \n",
        "            cmap = \"coolwarm\", \n",
        "            mask = mask,\n",
        "            fmt  = \".2f\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SJ0v0dbcIOY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# corr bt word count and score in each category"
      ],
      "metadata": {
        "id": "5oYA2b6JcS-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_essay = train_df['full_text'][0]\n",
        "print(f'In the First Essay\\n=====================================\\nnum_words (tokens) = {len(first_essay.split())}\\nnum_characters_in_first_essay = {len(first_essay)}\\n=====================================')\n",
        "first_essay"
      ],
      "metadata": {
        "id": "qijc-agXJF57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(15, 5))\n",
        "train_df['word_count'] = train_df['full_text'].apply(lambda x: len(x.split()))\n",
        "sns.histplot(data = train_df, x = \"word_count\")\n",
        "plt.title(\"full_text word count histogram plot\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FvEJgKOEIOav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mean > median\n",
        "plt.figure(figsize = (15,5))\n",
        "sns.distplot(train_df['word_count'])\n",
        "plt.axvline(x = np.mean(train_df['word_count']), color = 'red')\n",
        "plt.title('full_text length distribution plot')\n",
        "\n",
        "print(f'Average word count = {int(train_df.word_count.mean())}')"
      ],
      "metadata": {
        "id": "ZKGTFnxne64w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# options to explore:\n",
        "# - truncate (anything longer than 512 max length)\n",
        "# - split each essay to multiple essay and average (median or mode) them (to see a whole essay)"
      ],
      "metadata": {
        "id": "fSYnm84_clUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(15, 5))\n",
        "train_df['full_text_len'] = train_df['full_text'].apply(lambda x: len(x))\n",
        "sns.histplot(data = train_df, x = \"full_text_len\")\n",
        "plt.title(\"full_text length histogram plot\")\n",
        "print(f'Average length of letter sequences in essays = {int(train_df.full_text_len.mean())}')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kgx_XC0NIOxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (15,5))\n",
        "sns.distplot(train_df['full_text_len'])\n",
        "plt.axvline(x = np.mean(train_df['full_text_len']), color = 'red')\n",
        "plt.title('full_text length distribution plot')"
      ],
      "metadata": {
        "id": "SwGbbrYieg4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.describe()"
      ],
      "metadata": {
        "id": "w75FQcH2IO0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = train_df[(train_df.cohesion == 5) & \n",
        "                (train_df.syntax == 5) & \n",
        "                (train_df.vocabulary == 5) & \n",
        "                (train_df.phraseology == 5) & \n",
        "                (train_df.grammar == 5) & \n",
        "                (train_df.conventions == 5)]['full_text'].values[0]\n",
        "word_cloud = WordCloud(max_font_size = 50, max_words = 100, background_color = \"white\").generate(text)\n",
        "plt.imshow(word_cloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pL8xqkGQIO6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#make it easier to use a variety of BERT subword models\n",
        "model_checkpoint = 'bert-base-cased'   # case sensitive (care about upper and lower case)"
      ],
      "metadata": {
        "id": "IBNArt4gUxIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, TFBertModel\n",
        "\n",
        "bert_tokenizer = BertTokenizer.from_pretrained(model_checkpoint)\n",
        "bert_model = TFBertModel.from_pretrained(model_checkpoint)"
      ],
      "metadata": {
        "id": "HRZ4b6WnIO8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts = train_df['full_text']\n",
        "train_texts"
      ],
      "metadata": {
        "id": "yLX0DvQKIPAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(f'len(train_texts)={len(train_texts)} | type(train_texts)={type(train_texts)}')\n",
        "train_texts = train_texts.values.tolist()\n",
        "print(f'len(train_texts)={len(train_texts)} | type(train_texts)={type(train_texts)}')"
      ],
      "metadata": {
        "id": "mWG0ebdXXjEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_encodings = bert_tokenizer(train_texts, truncation=True, padding=True, max_length=200, return_tensors='tf')"
      ],
      "metadata": {
        "id": "RkF44O6qIPFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'len(train_encodings.input_ids[:1] = {len(train_encodings.input_ids[:1])}')\n",
        "# Average length of sequences in essays = 2334\n"
      ],
      "metadata": {
        "id": "GY_C2MJpIPMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- 6 models for each score for 6 categories: ordinal logistic regression.\n",
        "- seq to seq for multi-output model\n",
        "\n",
        "**Natalie's comment:**<br>\n",
        "1) build a classifier for each metric OR<br>\n",
        "2) build a multi-label multi-class model where you set up 6 output classification layer with one input tokenized by BERT tokenizer (maybe use CLS token layer for our input layer)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UBivgW2Kd64F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_simple_bert(checkpoint = model_checkpoint,\n",
        "                       num_classes=9,   # [1, 1.5, 2, 2.5....4.5, 5]: 9 classes\n",
        "                       hidden_size=201,\n",
        "                       dropout=0.3,\n",
        "                       learning_rate=0.00005,\n",
        "                       max_length=512):\n",
        "    \"\"\"\n",
        "    Build a simple classification model with BERT. Use the Pooler Output for classification purposes.\n",
        "    \"\"\"\n",
        "    bert_model = TFBertModel.from_pretrained(checkpoint)                                              \n",
        "    bert_model.trainable = False     \n",
        "\n",
        "    input_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int64, name='input_ids_layer')\n",
        "    token_type_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int64, name='token_type_ids_layer')\n",
        "    attention_mask = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int64, name='attention_mask_layer')\n",
        "\n",
        "    bert_inputs = {'input_ids': input_ids,\n",
        "                   'token_type_ids': token_type_ids,\n",
        "                   'attention_mask': attention_mask}\n",
        "\n",
        "    bert_out = bert_model(bert_inputs)   # full features\n",
        "\n",
        "    # ======== revise to utilize logistic regression =================\n",
        "    pooler_output = bert_out[1]    # one vector for each  \n",
        "    # cls token layer\n",
        "\n",
        "    hidden = tf.keras.layers.Dense(hidden_size, activation='relu', name='hidden_layer')(pooler_output)   # may not be needed\n",
        "    hidden = tf.keras.layers.Dropout(dropout)(hidden)  \n",
        "\n",
        "    classification = tf.keras.layers.Dense(num_classes, activation='softmax',name='classification_layer')(hidden)    \n",
        "    classification_model = tf.keras.Model(inputs=[input_ids, token_type_ids, attention_mask], outputs=[classification])\n",
        "\n",
        "    classification_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "                                 loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),          # A 'sigmoid' activation layer turns the output \"logit\" into a value, 0-1 \n",
        "                                 metrics='accuracy')                                        # work for both string and integer based labels - if your data is imbalanced, you would want F1 score or BLUE for the text classification\n",
        "                                #  metrics=tf.keras.metrics.SparseCategoricalAccuracy())    # only for the integer based labels\n",
        "    ### END YOUR CODE\n",
        "    return classification_model"
      ],
      "metadata": {
        "id": "vrRdqrScIPPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "b30qbyaHFOIn"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AvkA6pc3IPUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R3pB2CVcIPX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UlAn8KA8IPdv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}