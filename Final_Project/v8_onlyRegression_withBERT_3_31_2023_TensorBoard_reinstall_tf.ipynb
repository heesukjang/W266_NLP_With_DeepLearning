{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "7KEXkejkI7tk",
        "sjrm1a84QMVM",
        "3fpxoKBywieJ",
        "_KeKQmlyxvNm",
        "0RxLdSc1yYOj",
        "MXmeI1vhz7KC",
        "rv7WCZF31zg6",
        "fS2RzaGi2zS-",
        "ni3sz9wxa1nR",
        "NUMZkNvJcufY",
        "kndLU2phLRns",
        "LbgDBdUTFIa7",
        "hhWJgI2QONaS",
        "A1TQQfdIPNn0",
        "FQzHk9gJTpGF",
        "QTjC60_xP1gv",
        "KXwT00dRHxGN",
        "R-EOY4qnIcUW",
        "FPKsmw8oIlLy",
        "Lm57jeEsN-Vf",
        "v1l2yTGnKzsy",
        "wAW3Z-BxX9qi",
        "kdda-LBvO-Qd",
        "_AGO4SrlYcZQ",
        "Blag-pumPIgu",
        "gEfySDbNOTJN",
        "4e-8H751RROi",
        "rcB_ojpNXh4r",
        "x08cEWvzKdEF",
        "C-wgt-ouU3it",
        "bILNga0wabjS"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heesukjang/W266_NLP_With_DeepLearning/blob/main/Final_Project/v8_onlyRegression_withBERT_3_31_2023_TensorBoard_reinstall_tf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Update the version of tensorflow to 2.11.0**"
      ],
      "metadata": {
        "id": "SITfG-PPCctj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip uninstall tensorflow              # uninstall the current version of tf that Colab automatically installs\n",
        "# !pip install tensorflow==2.11.0        # install 2.11.0 version, which the model worked at that point with a GPU\n",
        "# # Next step: go to \"Runtime\" and \"Restart runtime\"\n",
        "# # then confirm if the version is properly updated to 2.11.0 by running the followin print statement - \"import tensorflow as tf | print(tf.__version__)\""
      ],
      "metadata": {
        "id": "_YybQCRZo7Sx"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check the version of tensorflow"
      ],
      "metadata": {
        "id": "Q-uHgs_j5r3T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_MzdaKXpl0G",
        "outputId": "ddc30bd3-a564-4748-a1a6-fce323ce8d99"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install New Libraries"
      ],
      "metadata": {
        "id": "6e9-ObmNw2XJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qOq60doCAwZ",
        "outputId": "9900e39f-791a-4d9f-d6ec-b3902b231ac3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (3.8.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from nltk) (4.65.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk) (1.1.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk) (2022.10.31)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk) (8.1.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.9/dist-packages (1.8.2.2)\n",
            "Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.9/dist-packages (from wordcloud) (1.22.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from wordcloud) (3.7.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (from wordcloud) (8.4.0)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->wordcloud) (5.12.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->wordcloud) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->wordcloud) (3.0.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->wordcloud) (23.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->wordcloud) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->wordcloud) (2.8.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->wordcloud) (1.0.7)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->wordcloud) (4.39.3)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->wordcloud) (3.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.27.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk\n",
        "!pip install wordcloud\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Importing Libraries**"
      ],
      "metadata": {
        "id": "KvNGnUjZCg62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "#NLP related libraries\n",
        "import transformers\n",
        "print(f'transformers version: {transformers.__version__}')\n",
        "from transformers import logging as hf_logging\n",
        "from transformers import BertTokenizer, TFBertModel\n",
        "hf_logging.set_verbosity_error()\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import spacy      \n",
        "from spacy import displacy\n",
        "from wordcloud import WordCloud\n",
        "from wordcloud import STOPWORDS\n",
        "from wordcloud import ImageColorGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Other required libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "pd.set_option('display.width', 180)    # increase pandas display output in Colab\n",
        "import numpy as np\n",
        "import re\n",
        "import copy\n",
        "import sys\n",
        "import datetime\n",
        "import time\n",
        "from keras.utils.layer_utils import count_params\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Data visualization libraries\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Tensorflow libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.utils.layer_utils import count_params\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.losses import mae\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "from keras.models import Model\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.regularizers import l1\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from keras.models import load_model\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "rTT4UBIqCRxT",
        "outputId": "31632279-b0a2-4bbe-fcb5-4a9b132b3b6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "transformers version: 4.27.4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Functions**"
      ],
      "metadata": {
        "id": "CM7dVhGpQF-Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Set Config Parameters**"
      ],
      "metadata": {
        "id": "7KEXkejkI7tk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_config_param(seed = 99):\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    tf.keras.backend.clear_session()\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/MyDrive/Kaggle\"\n",
        "    pd.set_option('display.max_columns', None)\n",
        "    pd.set_option('display.max_columns', None)\n",
        "    \n",
        "    \n",
        "set_config_param(20230214)"
      ],
      "metadata": {
        "id": "52YR9iGODH8P"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Count Plot**"
      ],
      "metadata": {
        "id": "sjrm1a84QMVM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def plot_count(df, labels):\n",
        "#   sns.set_style('whitegrid')\n",
        "#   plt.figure(figsize=(18,10))\n",
        "#   for idx, label in enumerate(labels):\n",
        "#       plt.subplot(2, 3, idx+1)\n",
        "#       sns.countplot(x = label, data = df)"
      ],
      "metadata": {
        "id": "E-XKyBFhQO3t"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Adding Feature Columns**"
      ],
      "metadata": {
        "id": "3fpxoKBywieJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_feature(df):\n",
        "\n",
        "    # Cleaning up full_text : Removing tabl and carriage return characters\n",
        "    df['full_text'] = df[\"full_text\"].replace(re.compile(r'[\\n\\r\\t]'), ' ', regex=True)\n",
        "\n",
        "    # Adding word count, sentence count, total score and full text length\n",
        "    df['word_count'] = df['full_text'].apply(lambda x: len(x.split()))\n",
        "    df['sentence_count'] = df['full_text'].apply(lambda x: len(sent_tokenize(x)))\n",
        "    df['total_score'] = df['cohesion'] + df_train['syntax'] + df['vocabulary'] + df['phraseology'] + df['grammar'] + df['conventions']\n",
        "    df['full_text_len'] = df['full_text'].apply(lambda x: len(x))\n",
        "\n",
        "    # Adding mean, median score per label and indicator column \n",
        "    # whether the label value is below or above mean or median value\n",
        "    for label in label_cols:\n",
        "        df[label + '_avg_score'] = np.mean(df[label])\n",
        "        df[label + '_above_or_below_avg_flag'] = np.where(df[label] > np.mean(df[label]), 1, 0)  \n",
        "        df[label + '_median_score'] = np.median(df[label])\n",
        "        df[label + '_above_or_below_median_flag'] = np.where(df[label] > np.median(df[label]), 1, 0)  \n",
        "        df[label + '_rounded_val'] = np.round(df[label])  \n",
        "    \n",
        "    return df"
      ],
      "metadata": {
        "id": "ZuDGICk6wlrZ"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Getting Unique Values for Each Label**"
      ],
      "metadata": {
        "id": "_KeKQmlyxvNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def get_unique_values_for_labels(df, col_list):\n",
        "#     print('Unique Values in Each Metric:\\n==================================================')\n",
        "#     for col in col_list:\n",
        "#         print(f'{col}: {df[col].unique()}')"
      ],
      "metadata": {
        "id": "dmV_f0MpxzcY"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Getting Value Counts for Each Label**"
      ],
      "metadata": {
        "id": "0RxLdSc1yYOj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def get_value_counts_for_labels(df, col_list):\n",
        "#     print('Counts for Each Metric:\\n==================================================')\n",
        "#     for col in col_list:\n",
        "#         print(f\"Column: {col}\")\n",
        "#         print(f'{df[col].value_counts().sort_values()}')\n",
        "#         print(\"*****\")"
      ],
      "metadata": {
        "id": "yX2dg3dFydT1"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Getting Histogram for a Column**"
      ],
      "metadata": {
        "id": "MXmeI1vhz7KC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def get_histogram_for_col(df, col_list, col_name):\n",
        "#     sns.set_style('whitegrid')\n",
        "#     plt.figure(figsize=(18,10))\n",
        "#     for idx, label in enumerate(col_list):\n",
        "#         plt.subplot(2, 3, idx+1)\n",
        "#         sns.histplot(x=col_name, hue = label, data = df)\n",
        "#         plt.xlabel('Word Count', fontsize=10)"
      ],
      "metadata": {
        "id": "a3jN8_D-z-32"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Getting Count Plot for Indicator Columns**"
      ],
      "metadata": {
        "id": "rv7WCZF31zg6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def get_count_plot_for_ind_col(df, search_string, col_list):\n",
        "#     fig, ax = plt.subplots(1, len(col_list), figsize=(50,10))\n",
        "#     for idx, label in enumerate(col_list):\n",
        "#         sns.countplot(x = df[label + search_string], ax = ax[idx])\n",
        "#         ax[idx].set_title(label)"
      ],
      "metadata": {
        "id": "zZ6f_gYB1-BB"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Getting Bar Plot for Each Label**"
      ],
      "metadata": {
        "id": "fS2RzaGi2zS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def get_barplot_for_each_label(df, col_list, search_string):\n",
        "#     avg_score_cols = [col + search_string for col in col_list]\n",
        "#     plt.figure(figsize=(8,5))\n",
        "#     ax = sns.barplot(x=col_list, y=np.array(df[avg_score_cols].drop_duplicates())[0], palette='rocket')\n",
        "#     plt.xlabel('Scoring Metric', fontsize=12)\n",
        "#     if search_string == '_avg_score':\n",
        "#         plt.ylabel('Average Score', fontsize=12)\n",
        "#         plt.title('Average Score in Each Metric', fontsize=16)\n",
        "#     elif search_string == '_median_score':\n",
        "#         plt.ylabel('Median Score', fontsize=12)\n",
        "#         plt.title('Median Score in Each Metric', fontsize=16)"
      ],
      "metadata": {
        "id": "uheekcFB223E"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Label Processing**"
      ],
      "metadata": {
        "id": "ni3sz9wxa1nR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_cat_label_cols(col_list):\n",
        "    return ['cat_' + col for col in col_list]"
      ],
      "metadata": {
        "id": "Q0wGK-_1cIpG"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_label_map(df, label_map, col_list):\n",
        "  for col in col_list:\n",
        "      df[col + '_map'] = df[col].map(label_map)\n",
        "  return df"
      ],
      "metadata": {
        "id": "rMwmH1dUfOLd"
      },
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_label_values(df, col_list):\n",
        "    return [np.array(df[col]) for col in col_list]"
      ],
      "metadata": {
        "id": "yvaG7kEHpI7M"
      },
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_label_dict(df, col_list_1, col_list_2):\n",
        "    return dict(zip(col_list_2, get_label_values(df, col_list_1)))"
      ],
      "metadata": {
        "id": "UPdesUBqpLW-"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Plot Loss and Accuracy**"
      ],
      "metadata": {
        "id": "NHXFA4eNQNFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def plot_loss_accuracy(history, col_list):\n",
        "#     fig, ax = plt.subplots(2, 6, figsize=(16, 6), sharex='col', sharey='row')\n",
        "#     fig.tight_layout(pad=5.0)\n",
        "#     for idx, col in enumerate(col_list):\n",
        "\n",
        "#         ax[0, idx].plot(history[col + '_loss'], lw=2, color='darkgoldenrod')\n",
        "#         ax[0, idx].plot(history['val_' + col + '_loss'], lw=2, color='indianred')\n",
        "#         #ax[0, idx].legend(loc='center left')\n",
        "#         ax[0, idx].legend(['Train', 'Validation'], fontsize=5)\n",
        "#         ax[0, idx].set_xlabel('Epochs', size=10)\n",
        "#         ax[0, idx].set_title('Loss: ' + col)\n",
        "\n",
        "#         ax[1, idx].plot(history[col + '_accuracy'], lw=2, color='darkgoldenrod')\n",
        "#         ax[1, idx].plot(history['val_' + col + '_accuracy'], lw=2, color='indianred')\n",
        "#         #ax[0, idx].legend(loc='center left')\n",
        "#         ax[1, idx].legend(['Train', 'Validation'], fontsize=5)\n",
        "#         ax[1, idx].set_xlabel('Epochs', size=10)\n",
        "#         ax[1, idx].set_title('Accuracy: ' + col)"
      ],
      "metadata": {
        "id": "kAnS-9wCQP80"
      },
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**[MCRMSE (Mean Column-wise Root Mean Squared Error)](https://www.kaggle.com/competitions/feedback-prize-english-language-learning/overview/evaluation)**<br>\n",
        "![Screen Shot 2023-03-27 at 9.25.56 PM.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "R1hWmJQV6tXq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def MCRMSE(y_true, y_pred):\n",
        "    colwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=1)\n",
        "    return tf.reduce_mean(tf.sqrt(colwise_mse), axis=-1, keepdims=True)"
      ],
      "metadata": {
        "id": "fsK0z8u96rqS"
      },
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import median_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# https://medium.com/ilb-labs-publications/fine-tuning-bert-for-a-regression-task-is-a-description-enough-to-predict-a-propertys-list-price-cf97cd7cb98a\n",
        "def addtl_loss(y_true, y_pred):  \n",
        "  mae = mean_absolute_error(y_true, y_pred)\n",
        "  mdae = median_absolute_error(y_true, y_pred)\n",
        "  return mae, mdae"
      ],
      "metadata": {
        "id": "yxhnpcVxMjuP"
      },
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def addtl_metrics(y_true, y_pred):\n",
        "  r_squared = r2_score(y_true, y_pred)\n",
        "  return r_squared  "
      ],
      "metadata": {
        "id": "dVYTPQfEOwHu"
      },
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load Input Files**"
      ],
      "metadata": {
        "id": "MdKA5le7FE3f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/content/gdrive/MyDrive/Kaggle/train.csv'\n",
        "test_path = '/content/gdrive/MyDrive/Kaggle/test.csv'\n",
        "\n",
        "input_train_df = pd.read_csv(train_path)\n",
        "input_test_df = pd.read_csv(test_path)\n",
        "\n",
        "# input_train_df = pd.read_csv('train.csv')\n",
        "# input_test_df = pd.read_csv('test.csv')\n",
        "\n",
        "float_labels, int_map_labels = np.arange(1, 5.5, 0.5), np.arange(9)\n",
        "label_map = dict(zip(float_labels, int_map_labels))\n",
        "\n",
        "float_scaled_labels, int_scaled_labels = np.arange(1, 6, 1), np.arange(6)\n",
        "label_scaled_map = dict(zip(float_scaled_labels, int_scaled_labels))\n",
        "\n",
        "orig_train_df = copy.deepcopy(input_train_df)\n",
        "orig_train_df.head()"
      ],
      "metadata": {
        "id": "Hyh8MQ_0DH_V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "bf23efd9-6eaa-4432-9619-ab3093302f08"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        text_id                                          full_text  cohesion  syntax  vocabulary  phraseology  grammar  conventions\n",
              "0  0016926B079C  I think that students would benefit from learn...       3.5     3.5         3.0          3.0      4.0          3.0\n",
              "1  0022683E9EA5  When a problem is a change you have to let it ...       2.5     2.5         3.0          2.0      2.0          2.5\n",
              "2  00299B378633  Dear, Principal\\n\\nIf u change the school poli...       3.0     3.5         3.0          3.0      3.0          2.5\n",
              "3  003885A45F42  The best time in life is when you become yours...       4.5     4.5         4.5          4.5      4.0          5.0\n",
              "4  0049B1DF5CCC  Small act of kindness can impact in other peop...       2.5     3.0         3.0          3.0      2.5          2.5"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8c0017e6-356b-4eff-a1c6-0d026057aa27\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_id</th>\n",
              "      <th>full_text</th>\n",
              "      <th>cohesion</th>\n",
              "      <th>syntax</th>\n",
              "      <th>vocabulary</th>\n",
              "      <th>phraseology</th>\n",
              "      <th>grammar</th>\n",
              "      <th>conventions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0016926B079C</td>\n",
              "      <td>I think that students would benefit from learn...</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0022683E9EA5</td>\n",
              "      <td>When a problem is a change you have to let it ...</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00299B378633</td>\n",
              "      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>003885A45F42</td>\n",
              "      <td>The best time in life is when you become yours...</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0049B1DF5CCC</td>\n",
              "      <td>Small act of kindness can impact in other peop...</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8c0017e6-356b-4eff-a1c6-0d026057aa27')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8c0017e6-356b-4eff-a1c6-0d026057aa27 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8c0017e6-356b-4eff-a1c6-0d026057aa27');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"Map\" columns are basically scaled columns of the original metric values. There are total 9 levels in map columns. Original mretric columns range from 1 to 5. Through map columns, they range from 0 to 8.\n",
        "\n",
        "\"Scaled\" columns map numbers .5, 1.5, 2.5, 3.5 and 4.5 to nearset integers. Thus it will have range from 1 to 5."
      ],
      "metadata": {
        "id": "BWvHPTt5UI7_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_map"
      ],
      "metadata": {
        "id": "GOY_-Ooc_dCu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5e17be3-8640-4379-b1b3-c5f110ce7464"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1.0: 0, 1.5: 1, 2.0: 2, 2.5: 3, 3.0: 4, 3.5: 5, 4.0: 6, 4.5: 7, 5.0: 8}"
            ]
          },
          "metadata": {},
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_scaled_map"
      ],
      "metadata": {
        "id": "sat02ZKdTliA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7dd14af-8352-40d5-e6f2-dabda3c28b92"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 0, 2: 1, 3: 2, 4: 3, 5: 4}"
            ]
          },
          "metadata": {},
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Split Data** into **3 Dataframes**\n",
        "- df_train\n",
        "- df_val\n",
        "- df_test\n",
        "\n",
        "Original test data is very limited, there are only 3 records and it does not have labels to test. So we decided to repurpose the given train data to split into train, test and validation sets."
      ],
      "metadata": {
        "id": "NUMZkNvJcufY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shuffle = np.random.permutation(np.arange(orig_train_df.shape[0]))\n",
        "orig_train_df = orig_train_df.iloc[shuffle]\n",
        "split=(0.8,0.1,0.1)\n",
        "splits = np.multiply(len(orig_train_df), split).astype(int)\n",
        "df_train, df_val, df_test = np.split(orig_train_df, [splits[0], splits[0] + splits[1]])\n",
        "df_train.head()"
      ],
      "metadata": {
        "id": "Z7ELuUWlcxAS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "66e4314e-ddd0-4bca-c709-428464713752"
      },
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           text_id                                          full_text  cohesion  syntax  vocabulary  phraseology  grammar  conventions\n",
              "134   0A8B8F282E45  Winston Churchill once said \"success consists ...       3.0     2.0         2.5          2.5      2.5          2.5\n",
              "1470  71BA665B1B31  I think that imagination is not more important...       3.0     4.0         3.0          3.5      3.5          3.0\n",
              "1216  5EA71157D48F  I supported that people make their own decisio...       2.5     2.5         2.5          2.5      3.0          3.5\n",
              "3705  F7B5DF87EA1D  If we didn't take a action, What should we do?...       2.5     2.5         3.0          3.0      3.5          3.5\n",
              "2121  9EBCC1131B13  As we have two different people, we have two t...       4.5     3.0         4.0          3.5      3.0          3.5"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bcedbad9-b32e-4f2a-9ed2-0ce754ef47ae\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_id</th>\n",
              "      <th>full_text</th>\n",
              "      <th>cohesion</th>\n",
              "      <th>syntax</th>\n",
              "      <th>vocabulary</th>\n",
              "      <th>phraseology</th>\n",
              "      <th>grammar</th>\n",
              "      <th>conventions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>134</th>\n",
              "      <td>0A8B8F282E45</td>\n",
              "      <td>Winston Churchill once said \"success consists ...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1470</th>\n",
              "      <td>71BA665B1B31</td>\n",
              "      <td>I think that imagination is not more important...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1216</th>\n",
              "      <td>5EA71157D48F</td>\n",
              "      <td>I supported that people make their own decisio...</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3705</th>\n",
              "      <td>F7B5DF87EA1D</td>\n",
              "      <td>If we didn't take a action, What should we do?...</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2121</th>\n",
              "      <td>9EBCC1131B13</td>\n",
              "      <td>As we have two different people, we have two t...</td>\n",
              "      <td>4.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bcedbad9-b32e-4f2a-9ed2-0ce754ef47ae')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bcedbad9-b32e-4f2a-9ed2-0ce754ef47ae button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bcedbad9-b32e-4f2a-9ed2-0ce754ef47ae');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_cols = df_train.columns[2:]\n",
        "print(label_cols)\n",
        "label_rounded_cols = [col + '_rounded_val' for col in label_cols]\n",
        "label_map_cols = [col + '_map' for col in label_cols]\n",
        "cat_label_cols = get_cat_label_cols(label_cols)\n",
        "\n",
        "df_train = apply_label_map(df_train, label_map, label_cols)\n",
        "df_test = apply_label_map(df_test, label_map, label_cols)\n",
        "df_val = apply_label_map(df_val, label_map, label_cols)"
      ],
      "metadata": {
        "id": "iDAM32Xagb7S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88c16bfd-d48e-4805-db34-d26f32b0f380"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_cols, label_rounded_cols, label_map_cols, cat_label_cols"
      ],
      "metadata": {
        "id": "O42263iZjHQI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fc5f4bf-ced3-40de-e2d3-7ccedd7c6fc4"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Index(['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions'], dtype='object'),\n",
              " ['cohesion_rounded_val',\n",
              "  'syntax_rounded_val',\n",
              "  'vocabulary_rounded_val',\n",
              "  'phraseology_rounded_val',\n",
              "  'grammar_rounded_val',\n",
              "  'conventions_rounded_val'],\n",
              " ['cohesion_map',\n",
              "  'syntax_map',\n",
              "  'vocabulary_map',\n",
              "  'phraseology_map',\n",
              "  'grammar_map',\n",
              "  'conventions_map'],\n",
              " ['cat_cohesion',\n",
              "  'cat_syntax',\n",
              "  'cat_vocabulary',\n",
              "  'cat_phraseology',\n",
              "  'cat_grammar',\n",
              "  'cat_conventions'])"
            ]
          },
          "metadata": {},
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Addiung Other Feature Columns**"
      ],
      "metadata": {
        "id": "kndLU2phLRns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = add_feature(df_train)\n",
        "df_test = add_feature(df_test)\n",
        "df_val = add_feature(df_val)"
      ],
      "metadata": {
        "id": "qqe2GSfzLY1a"
      },
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EDA**"
      ],
      "metadata": {
        "id": "LbgDBdUTFIa7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head()"
      ],
      "metadata": {
        "id": "01k0v_RODICu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "fb5daf80-2846-4e30-8f7b-304b9a4523af"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           text_id                                          full_text  cohesion  syntax  vocabulary  phraseology  grammar  conventions  cohesion_map  syntax_map  vocabulary_map  \\\n",
              "134   0A8B8F282E45  Winston Churchill once said \"success consists ...       3.0     2.0         2.5          2.5      2.5          2.5             4           2               3   \n",
              "1470  71BA665B1B31  I think that imagination is not more important...       3.0     4.0         3.0          3.5      3.5          3.0             4           6               4   \n",
              "1216  5EA71157D48F  I supported that people make their own decisio...       2.5     2.5         2.5          2.5      3.0          3.5             3           3               3   \n",
              "3705  F7B5DF87EA1D  If we didn't take a action, What should we do?...       2.5     2.5         3.0          3.0      3.5          3.5             3           3               4   \n",
              "2121  9EBCC1131B13  As we have two different people, we have two t...       4.5     3.0         4.0          3.5      3.0          3.5             7           4               6   \n",
              "\n",
              "      phraseology_map  grammar_map  conventions_map  word_count  sentence_count  total_score  full_text_len  cohesion_avg_score  cohesion_above_or_below_avg_flag  \\\n",
              "134                 3            3                3         446              15         15.0           2373            3.128676                                 0   \n",
              "1470                5            5                4         226              14         20.0           1216            3.128676                                 0   \n",
              "1216                3            4                5         164               7         16.5            841            3.128676                                 0   \n",
              "3705                4            5                5         347              25         18.0           1876            3.128676                                 0   \n",
              "2121                5            4                5         573              19         21.5           3176            3.128676                                 1   \n",
              "\n",
              "      cohesion_median_score  cohesion_above_or_below_median_flag  cohesion_rounded_val  syntax_avg_score  syntax_above_or_below_avg_flag  syntax_median_score  \\\n",
              "134                     3.0                                    0                   3.0           3.03133                               0                  3.0   \n",
              "1470                    3.0                                    0                   3.0           3.03133                               1                  3.0   \n",
              "1216                    3.0                                    0                   2.0           3.03133                               0                  3.0   \n",
              "3705                    3.0                                    0                   2.0           3.03133                               0                  3.0   \n",
              "2121                    3.0                                    1                   4.0           3.03133                               0                  3.0   \n",
              "\n",
              "      syntax_above_or_below_median_flag  syntax_rounded_val  vocabulary_avg_score  vocabulary_above_or_below_avg_flag  vocabulary_median_score  \\\n",
              "134                                   0                 2.0              3.235134                                   0                      3.0   \n",
              "1470                                  1                 4.0              3.235134                                   0                      3.0   \n",
              "1216                                  0                 2.0              3.235134                                   0                      3.0   \n",
              "3705                                  0                 2.0              3.235134                                   0                      3.0   \n",
              "2121                                  0                 3.0              3.235134                                   1                      3.0   \n",
              "\n",
              "      vocabulary_above_or_below_median_flag  vocabulary_rounded_val  phraseology_avg_score  phraseology_above_or_below_avg_flag  phraseology_median_score  \\\n",
              "134                                       0                     2.0               3.123242                                    0                       3.0   \n",
              "1470                                      0                     3.0               3.123242                                    1                       3.0   \n",
              "1216                                      0                     2.0               3.123242                                    0                       3.0   \n",
              "3705                                      0                     3.0               3.123242                                    0                       3.0   \n",
              "2121                                      1                     4.0               3.123242                                    1                       3.0   \n",
              "\n",
              "      phraseology_above_or_below_median_flag  phraseology_rounded_val  grammar_avg_score  grammar_above_or_below_avg_flag  grammar_median_score  \\\n",
              "134                                        0                      2.0           3.029252                                0                   3.0   \n",
              "1470                                       1                      4.0           3.029252                                1                   3.0   \n",
              "1216                                       0                      2.0           3.029252                                0                   3.0   \n",
              "3705                                       0                      3.0           3.029252                                1                   3.0   \n",
              "2121                                       1                      4.0           3.029252                                0                   3.0   \n",
              "\n",
              "      grammar_above_or_below_median_flag  grammar_rounded_val  conventions_avg_score  conventions_above_or_below_avg_flag  conventions_median_score  \\\n",
              "134                                    0                  2.0               3.081841                                    0                       3.0   \n",
              "1470                                   1                  4.0               3.081841                                    0                       3.0   \n",
              "1216                                   0                  3.0               3.081841                                    1                       3.0   \n",
              "3705                                   1                  4.0               3.081841                                    1                       3.0   \n",
              "2121                                   0                  3.0               3.081841                                    1                       3.0   \n",
              "\n",
              "      conventions_above_or_below_median_flag  conventions_rounded_val  \n",
              "134                                        0                      2.0  \n",
              "1470                                       0                      3.0  \n",
              "1216                                       1                      4.0  \n",
              "3705                                       1                      4.0  \n",
              "2121                                       1                      4.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0961397d-ac47-463d-b01b-a3b937549b1b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_id</th>\n",
              "      <th>full_text</th>\n",
              "      <th>cohesion</th>\n",
              "      <th>syntax</th>\n",
              "      <th>vocabulary</th>\n",
              "      <th>phraseology</th>\n",
              "      <th>grammar</th>\n",
              "      <th>conventions</th>\n",
              "      <th>cohesion_map</th>\n",
              "      <th>syntax_map</th>\n",
              "      <th>vocabulary_map</th>\n",
              "      <th>phraseology_map</th>\n",
              "      <th>grammar_map</th>\n",
              "      <th>conventions_map</th>\n",
              "      <th>word_count</th>\n",
              "      <th>sentence_count</th>\n",
              "      <th>total_score</th>\n",
              "      <th>full_text_len</th>\n",
              "      <th>cohesion_avg_score</th>\n",
              "      <th>cohesion_above_or_below_avg_flag</th>\n",
              "      <th>cohesion_median_score</th>\n",
              "      <th>cohesion_above_or_below_median_flag</th>\n",
              "      <th>cohesion_rounded_val</th>\n",
              "      <th>syntax_avg_score</th>\n",
              "      <th>syntax_above_or_below_avg_flag</th>\n",
              "      <th>syntax_median_score</th>\n",
              "      <th>syntax_above_or_below_median_flag</th>\n",
              "      <th>syntax_rounded_val</th>\n",
              "      <th>vocabulary_avg_score</th>\n",
              "      <th>vocabulary_above_or_below_avg_flag</th>\n",
              "      <th>vocabulary_median_score</th>\n",
              "      <th>vocabulary_above_or_below_median_flag</th>\n",
              "      <th>vocabulary_rounded_val</th>\n",
              "      <th>phraseology_avg_score</th>\n",
              "      <th>phraseology_above_or_below_avg_flag</th>\n",
              "      <th>phraseology_median_score</th>\n",
              "      <th>phraseology_above_or_below_median_flag</th>\n",
              "      <th>phraseology_rounded_val</th>\n",
              "      <th>grammar_avg_score</th>\n",
              "      <th>grammar_above_or_below_avg_flag</th>\n",
              "      <th>grammar_median_score</th>\n",
              "      <th>grammar_above_or_below_median_flag</th>\n",
              "      <th>grammar_rounded_val</th>\n",
              "      <th>conventions_avg_score</th>\n",
              "      <th>conventions_above_or_below_avg_flag</th>\n",
              "      <th>conventions_median_score</th>\n",
              "      <th>conventions_above_or_below_median_flag</th>\n",
              "      <th>conventions_rounded_val</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>134</th>\n",
              "      <td>0A8B8F282E45</td>\n",
              "      <td>Winston Churchill once said \"success consists ...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>446</td>\n",
              "      <td>15</td>\n",
              "      <td>15.0</td>\n",
              "      <td>2373</td>\n",
              "      <td>3.128676</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.03133</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.235134</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.123242</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.029252</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.081841</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1470</th>\n",
              "      <td>71BA665B1B31</td>\n",
              "      <td>I think that imagination is not more important...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>226</td>\n",
              "      <td>14</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1216</td>\n",
              "      <td>3.128676</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.03133</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.235134</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.123242</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.029252</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.081841</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1216</th>\n",
              "      <td>5EA71157D48F</td>\n",
              "      <td>I supported that people make their own decisio...</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>164</td>\n",
              "      <td>7</td>\n",
              "      <td>16.5</td>\n",
              "      <td>841</td>\n",
              "      <td>3.128676</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.03133</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.235134</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.123242</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.029252</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.081841</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3705</th>\n",
              "      <td>F7B5DF87EA1D</td>\n",
              "      <td>If we didn't take a action, What should we do?...</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>347</td>\n",
              "      <td>25</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1876</td>\n",
              "      <td>3.128676</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.03133</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.235134</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.123242</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.029252</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.081841</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2121</th>\n",
              "      <td>9EBCC1131B13</td>\n",
              "      <td>As we have two different people, we have two t...</td>\n",
              "      <td>4.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>573</td>\n",
              "      <td>19</td>\n",
              "      <td>21.5</td>\n",
              "      <td>3176</td>\n",
              "      <td>3.128676</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.03133</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.235134</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.123242</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.029252</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.081841</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0961397d-ac47-463d-b01b-a3b937549b1b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0961397d-ac47-463d-b01b-a3b937549b1b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0961397d-ac47-463d-b01b-a3b937549b1b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for col in label_cols:\n",
        "    print(df_train[col + '_rounded_val'].unique())"
      ],
      "metadata": {
        "id": "P0wTM1KR4IWQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f79a246-c6f4-4f65-c8d1-32bd8bb63a71"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3. 2. 4. 1. 5.]\n",
            "[2. 4. 3. 1. 5.]\n",
            "[2. 3. 4. 1. 5.]\n",
            "[2. 4. 3. 5. 1.]\n",
            "[2. 4. 3. 1. 5.]\n",
            "[2. 3. 4. 1. 5.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.iloc[0]"
      ],
      "metadata": {
        "id": "T3y2j7by33P2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22e1f67c-6394-429f-ec3c-0cb44e06533c"
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text_id                                                                        0A8B8F282E45\n",
              "full_text                                 Winston Churchill once said \"success consists ...\n",
              "cohesion                                                                                3.0\n",
              "syntax                                                                                  2.0\n",
              "vocabulary                                                                              2.5\n",
              "phraseology                                                                             2.5\n",
              "grammar                                                                                 2.5\n",
              "conventions                                                                             2.5\n",
              "cohesion_map                                                                              4\n",
              "syntax_map                                                                                2\n",
              "vocabulary_map                                                                            3\n",
              "phraseology_map                                                                           3\n",
              "grammar_map                                                                               3\n",
              "conventions_map                                                                           3\n",
              "word_count                                                                              446\n",
              "sentence_count                                                                           15\n",
              "total_score                                                                            15.0\n",
              "full_text_len                                                                          2373\n",
              "cohesion_avg_score                                                                 3.128676\n",
              "cohesion_above_or_below_avg_flag                                                          0\n",
              "cohesion_median_score                                                                   3.0\n",
              "cohesion_above_or_below_median_flag                                                       0\n",
              "cohesion_rounded_val                                                                    3.0\n",
              "syntax_avg_score                                                                    3.03133\n",
              "syntax_above_or_below_avg_flag                                                            0\n",
              "syntax_median_score                                                                     3.0\n",
              "syntax_above_or_below_median_flag                                                         0\n",
              "syntax_rounded_val                                                                      2.0\n",
              "vocabulary_avg_score                                                               3.235134\n",
              "vocabulary_above_or_below_avg_flag                                                        0\n",
              "vocabulary_median_score                                                                 3.0\n",
              "vocabulary_above_or_below_median_flag                                                     0\n",
              "vocabulary_rounded_val                                                                  2.0\n",
              "phraseology_avg_score                                                              3.123242\n",
              "phraseology_above_or_below_avg_flag                                                       0\n",
              "phraseology_median_score                                                                3.0\n",
              "phraseology_above_or_below_median_flag                                                    0\n",
              "phraseology_rounded_val                                                                 2.0\n",
              "grammar_avg_score                                                                  3.029252\n",
              "grammar_above_or_below_avg_flag                                                           0\n",
              "grammar_median_score                                                                    3.0\n",
              "grammar_above_or_below_median_flag                                                        0\n",
              "grammar_rounded_val                                                                     2.0\n",
              "conventions_avg_score                                                              3.081841\n",
              "conventions_above_or_below_avg_flag                                                       0\n",
              "conventions_median_score                                                                3.0\n",
              "conventions_above_or_below_median_flag                                                    0\n",
              "conventions_rounded_val                                                                 2.0\n",
              "Name: 134, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.head()"
      ],
      "metadata": {
        "id": "2JBKHMhFDIGF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "41416460-1df8-4964-ee5e-42f51cc565d2"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           text_id                                          full_text  cohesion  syntax  vocabulary  phraseology  grammar  conventions  cohesion_map  syntax_map  vocabulary_map  \\\n",
              "3317  E587CBD5D1E4  How we know the first impression is important ...       3.5     2.5         3.5          3.5      2.5          3.0             5           3               5   \n",
              "3172  DF149975C610  I agree with emerson's statement. I will grow ...       3.0     3.0         3.0          3.5      2.5          3.0             4           4               4   \n",
              "2999  D7301CAAFAB0  When are parents gave us advice we are able to...       2.5     2.0         2.5          2.0      2.0          3.0             3           2               3   \n",
              "2824  CDDCA13DB734  The determination make us to do something and ...       3.5     3.0         3.0          2.5      2.5          3.5             5           4               4   \n",
              "310   16B9EB49892E  The should be people make their own decision, ...       2.5     2.5         2.5          2.0      2.5          2.0             3           3               3   \n",
              "\n",
              "      phraseology_map  grammar_map  conventions_map  word_count  sentence_count  total_score  full_text_len  cohesion_avg_score  cohesion_above_or_below_avg_flag  \\\n",
              "3317                5            3                4         265               8          NaN           1350            3.105867                                 1   \n",
              "3172                5            3                4         502              39          NaN           2534            3.105867                                 0   \n",
              "2999                2            2                4         496              27          NaN           2449            3.105867                                 0   \n",
              "2824                3            3                5         309              14          NaN           1567            3.105867                                 1   \n",
              "310                 2            3                2         169               9          NaN            926            3.105867                                 0   \n",
              "\n",
              "      cohesion_median_score  cohesion_above_or_below_median_flag  cohesion_rounded_val  syntax_avg_score  syntax_above_or_below_avg_flag  syntax_median_score  \\\n",
              "3317                    3.0                                    1                   4.0          3.010204                               0                  3.0   \n",
              "3172                    3.0                                    0                   3.0          3.010204                               0                  3.0   \n",
              "2999                    3.0                                    0                   2.0          3.010204                               0                  3.0   \n",
              "2824                    3.0                                    1                   4.0          3.010204                               0                  3.0   \n",
              "310                     3.0                                    0                   2.0          3.010204                               0                  3.0   \n",
              "\n",
              "      syntax_above_or_below_median_flag  syntax_rounded_val  vocabulary_avg_score  vocabulary_above_or_below_avg_flag  vocabulary_median_score  \\\n",
              "3317                                  0                 2.0              3.242347                                   1                      3.0   \n",
              "3172                                  0                 3.0              3.242347                                   0                      3.0   \n",
              "2999                                  0                 2.0              3.242347                                   0                      3.0   \n",
              "2824                                  0                 3.0              3.242347                                   0                      3.0   \n",
              "310                                   0                 2.0              3.242347                                   0                      3.0   \n",
              "\n",
              "      vocabulary_above_or_below_median_flag  vocabulary_rounded_val  phraseology_avg_score  phraseology_above_or_below_avg_flag  phraseology_median_score  \\\n",
              "3317                                      1                     4.0               3.067602                                    1                       3.0   \n",
              "3172                                      0                     3.0               3.067602                                    1                       3.0   \n",
              "2999                                      0                     2.0               3.067602                                    0                       3.0   \n",
              "2824                                      0                     3.0               3.067602                                    0                       3.0   \n",
              "310                                       0                     2.0               3.067602                                    0                       3.0   \n",
              "\n",
              "      phraseology_above_or_below_median_flag  phraseology_rounded_val  grammar_avg_score  grammar_above_or_below_avg_flag  grammar_median_score  \\\n",
              "3317                                       1                      4.0           3.042092                                0                   3.0   \n",
              "3172                                       1                      4.0           3.042092                                0                   3.0   \n",
              "2999                                       0                      2.0           3.042092                                0                   3.0   \n",
              "2824                                       0                      2.0           3.042092                                0                   3.0   \n",
              "310                                        0                      2.0           3.042092                                0                   3.0   \n",
              "\n",
              "      grammar_above_or_below_median_flag  grammar_rounded_val  conventions_avg_score  conventions_above_or_below_avg_flag  conventions_median_score  \\\n",
              "3317                                   0                  2.0               3.068878                                    0                       3.0   \n",
              "3172                                   0                  2.0               3.068878                                    0                       3.0   \n",
              "2999                                   0                  2.0               3.068878                                    0                       3.0   \n",
              "2824                                   0                  2.0               3.068878                                    1                       3.0   \n",
              "310                                    0                  2.0               3.068878                                    0                       3.0   \n",
              "\n",
              "      conventions_above_or_below_median_flag  conventions_rounded_val  \n",
              "3317                                       0                      3.0  \n",
              "3172                                       0                      3.0  \n",
              "2999                                       0                      3.0  \n",
              "2824                                       1                      4.0  \n",
              "310                                        0                      2.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-da31788f-1133-4ed8-985c-e2a8de9c1dbf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_id</th>\n",
              "      <th>full_text</th>\n",
              "      <th>cohesion</th>\n",
              "      <th>syntax</th>\n",
              "      <th>vocabulary</th>\n",
              "      <th>phraseology</th>\n",
              "      <th>grammar</th>\n",
              "      <th>conventions</th>\n",
              "      <th>cohesion_map</th>\n",
              "      <th>syntax_map</th>\n",
              "      <th>vocabulary_map</th>\n",
              "      <th>phraseology_map</th>\n",
              "      <th>grammar_map</th>\n",
              "      <th>conventions_map</th>\n",
              "      <th>word_count</th>\n",
              "      <th>sentence_count</th>\n",
              "      <th>total_score</th>\n",
              "      <th>full_text_len</th>\n",
              "      <th>cohesion_avg_score</th>\n",
              "      <th>cohesion_above_or_below_avg_flag</th>\n",
              "      <th>cohesion_median_score</th>\n",
              "      <th>cohesion_above_or_below_median_flag</th>\n",
              "      <th>cohesion_rounded_val</th>\n",
              "      <th>syntax_avg_score</th>\n",
              "      <th>syntax_above_or_below_avg_flag</th>\n",
              "      <th>syntax_median_score</th>\n",
              "      <th>syntax_above_or_below_median_flag</th>\n",
              "      <th>syntax_rounded_val</th>\n",
              "      <th>vocabulary_avg_score</th>\n",
              "      <th>vocabulary_above_or_below_avg_flag</th>\n",
              "      <th>vocabulary_median_score</th>\n",
              "      <th>vocabulary_above_or_below_median_flag</th>\n",
              "      <th>vocabulary_rounded_val</th>\n",
              "      <th>phraseology_avg_score</th>\n",
              "      <th>phraseology_above_or_below_avg_flag</th>\n",
              "      <th>phraseology_median_score</th>\n",
              "      <th>phraseology_above_or_below_median_flag</th>\n",
              "      <th>phraseology_rounded_val</th>\n",
              "      <th>grammar_avg_score</th>\n",
              "      <th>grammar_above_or_below_avg_flag</th>\n",
              "      <th>grammar_median_score</th>\n",
              "      <th>grammar_above_or_below_median_flag</th>\n",
              "      <th>grammar_rounded_val</th>\n",
              "      <th>conventions_avg_score</th>\n",
              "      <th>conventions_above_or_below_avg_flag</th>\n",
              "      <th>conventions_median_score</th>\n",
              "      <th>conventions_above_or_below_median_flag</th>\n",
              "      <th>conventions_rounded_val</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3317</th>\n",
              "      <td>E587CBD5D1E4</td>\n",
              "      <td>How we know the first impression is important ...</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>265</td>\n",
              "      <td>8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1350</td>\n",
              "      <td>3.105867</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.010204</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.242347</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.067602</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.042092</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.068878</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3172</th>\n",
              "      <td>DF149975C610</td>\n",
              "      <td>I agree with emerson's statement. I will grow ...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>502</td>\n",
              "      <td>39</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2534</td>\n",
              "      <td>3.105867</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.010204</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.242347</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.067602</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.042092</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.068878</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2999</th>\n",
              "      <td>D7301CAAFAB0</td>\n",
              "      <td>When are parents gave us advice we are able to...</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>496</td>\n",
              "      <td>27</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2449</td>\n",
              "      <td>3.105867</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.010204</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.242347</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.067602</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.042092</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.068878</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2824</th>\n",
              "      <td>CDDCA13DB734</td>\n",
              "      <td>The determination make us to do something and ...</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>309</td>\n",
              "      <td>14</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1567</td>\n",
              "      <td>3.105867</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.010204</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.242347</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.067602</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.042092</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.068878</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>310</th>\n",
              "      <td>16B9EB49892E</td>\n",
              "      <td>The should be people make their own decision, ...</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>169</td>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>926</td>\n",
              "      <td>3.105867</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.010204</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.242347</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.067602</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.042092</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.068878</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-da31788f-1133-4ed8-985c-e2a8de9c1dbf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-da31788f-1133-4ed8-985c-e2a8de9c1dbf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-da31788f-1133-4ed8-985c-e2a8de9c1dbf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_val.head()"
      ],
      "metadata": {
        "id": "m_aKUdVEdf-i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "0d8df23a-d6eb-4c34-a005-7f7a5685ecbf"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           text_id                                          full_text  cohesion  syntax  vocabulary  phraseology  grammar  conventions  cohesion_map  syntax_map  vocabulary_map  \\\n",
              "299   16005A45A20A  There's 90% of people in the world that wants ...       4.0     3.0         3.0          3.0      3.5          3.5             6           4               4   \n",
              "1371  698A3F2B43B9  Have you ever thought about staring your futur...       4.0     3.0         4.0          3.5      3.5          3.0             6           4               6   \n",
              "3087  DB34A89420F2  I understand why you want to add an hour and t...       2.5     3.0         3.0          2.5      3.5          3.0             3           4               4   \n",
              "1047  4FE6EABBFC00  One topic that is frequently debated is if peo...       5.0     4.5         4.0          4.5      4.0          4.5             8           7               6   \n",
              "1453  6FEF6D46714D  Has it ever crossed your mind that people toda...       2.5     3.5         3.5          3.5      3.5          2.5             3           5               5   \n",
              "\n",
              "      phraseology_map  grammar_map  conventions_map  word_count  sentence_count  total_score  full_text_len  cohesion_avg_score  cohesion_above_or_below_avg_flag  \\\n",
              "299                 4            5                5        1072              47          NaN           5449             3.13555                                 1   \n",
              "1371                5            5                4         650              29          NaN           3372             3.13555                                 1   \n",
              "3087                3            5                4         486              13          NaN           2508             3.13555                                 0   \n",
              "1047                7            6                7         194              10          NaN           1128             3.13555                                 1   \n",
              "1453                5            5                3         597              27          NaN           3239             3.13555                                 0   \n",
              "\n",
              "      cohesion_median_score  cohesion_above_or_below_median_flag  cohesion_rounded_val  syntax_avg_score  syntax_above_or_below_avg_flag  syntax_median_score  \\\n",
              "299                     3.0                                    1                   4.0          3.021739                               0                  3.0   \n",
              "1371                    3.0                                    1                   4.0          3.021739                               0                  3.0   \n",
              "3087                    3.0                                    0                   2.0          3.021739                               0                  3.0   \n",
              "1047                    3.0                                    1                   5.0          3.021739                               1                  3.0   \n",
              "1453                    3.0                                    0                   2.0          3.021739                               1                  3.0   \n",
              "\n",
              "      syntax_above_or_below_median_flag  syntax_rounded_val  vocabulary_avg_score  vocabulary_above_or_below_avg_flag  vocabulary_median_score  \\\n",
              "299                                   0                 3.0              3.234015                                   0                      3.0   \n",
              "1371                                  0                 3.0              3.234015                                   1                      3.0   \n",
              "3087                                  0                 3.0              3.234015                                   0                      3.0   \n",
              "1047                                  1                 4.0              3.234015                                   1                      3.0   \n",
              "1453                                  1                 4.0              3.234015                                   1                      3.0   \n",
              "\n",
              "      vocabulary_above_or_below_median_flag  vocabulary_rounded_val  phraseology_avg_score  phraseology_above_or_below_avg_flag  phraseology_median_score  \\\n",
              "299                                       0                     3.0                3.11509                                    0                       3.0   \n",
              "1371                                      1                     4.0                3.11509                                    1                       3.0   \n",
              "3087                                      0                     3.0                3.11509                                    0                       3.0   \n",
              "1047                                      1                     4.0                3.11509                                    1                       3.0   \n",
              "1453                                      1                     4.0                3.11509                                    1                       3.0   \n",
              "\n",
              "      phraseology_above_or_below_median_flag  phraseology_rounded_val  grammar_avg_score  grammar_above_or_below_avg_flag  grammar_median_score  \\\n",
              "299                                        0                      3.0            3.05243                                1                   3.0   \n",
              "1371                                       1                      4.0            3.05243                                1                   3.0   \n",
              "3087                                       0                      2.0            3.05243                                1                   3.0   \n",
              "1047                                       1                      4.0            3.05243                                1                   3.0   \n",
              "1453                                       1                      4.0            3.05243                                1                   3.0   \n",
              "\n",
              "      grammar_above_or_below_median_flag  grammar_rounded_val  conventions_avg_score  conventions_above_or_below_avg_flag  conventions_median_score  \\\n",
              "299                                    1                  4.0               3.086957                                    1                       3.0   \n",
              "1371                                   1                  4.0               3.086957                                    0                       3.0   \n",
              "3087                                   1                  4.0               3.086957                                    0                       3.0   \n",
              "1047                                   1                  4.0               3.086957                                    1                       3.0   \n",
              "1453                                   1                  4.0               3.086957                                    0                       3.0   \n",
              "\n",
              "      conventions_above_or_below_median_flag  conventions_rounded_val  \n",
              "299                                        1                      4.0  \n",
              "1371                                       0                      3.0  \n",
              "3087                                       0                      3.0  \n",
              "1047                                       1                      4.0  \n",
              "1453                                       0                      2.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f1072fda-3c4c-4644-bf27-bccd664d3cde\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_id</th>\n",
              "      <th>full_text</th>\n",
              "      <th>cohesion</th>\n",
              "      <th>syntax</th>\n",
              "      <th>vocabulary</th>\n",
              "      <th>phraseology</th>\n",
              "      <th>grammar</th>\n",
              "      <th>conventions</th>\n",
              "      <th>cohesion_map</th>\n",
              "      <th>syntax_map</th>\n",
              "      <th>vocabulary_map</th>\n",
              "      <th>phraseology_map</th>\n",
              "      <th>grammar_map</th>\n",
              "      <th>conventions_map</th>\n",
              "      <th>word_count</th>\n",
              "      <th>sentence_count</th>\n",
              "      <th>total_score</th>\n",
              "      <th>full_text_len</th>\n",
              "      <th>cohesion_avg_score</th>\n",
              "      <th>cohesion_above_or_below_avg_flag</th>\n",
              "      <th>cohesion_median_score</th>\n",
              "      <th>cohesion_above_or_below_median_flag</th>\n",
              "      <th>cohesion_rounded_val</th>\n",
              "      <th>syntax_avg_score</th>\n",
              "      <th>syntax_above_or_below_avg_flag</th>\n",
              "      <th>syntax_median_score</th>\n",
              "      <th>syntax_above_or_below_median_flag</th>\n",
              "      <th>syntax_rounded_val</th>\n",
              "      <th>vocabulary_avg_score</th>\n",
              "      <th>vocabulary_above_or_below_avg_flag</th>\n",
              "      <th>vocabulary_median_score</th>\n",
              "      <th>vocabulary_above_or_below_median_flag</th>\n",
              "      <th>vocabulary_rounded_val</th>\n",
              "      <th>phraseology_avg_score</th>\n",
              "      <th>phraseology_above_or_below_avg_flag</th>\n",
              "      <th>phraseology_median_score</th>\n",
              "      <th>phraseology_above_or_below_median_flag</th>\n",
              "      <th>phraseology_rounded_val</th>\n",
              "      <th>grammar_avg_score</th>\n",
              "      <th>grammar_above_or_below_avg_flag</th>\n",
              "      <th>grammar_median_score</th>\n",
              "      <th>grammar_above_or_below_median_flag</th>\n",
              "      <th>grammar_rounded_val</th>\n",
              "      <th>conventions_avg_score</th>\n",
              "      <th>conventions_above_or_below_avg_flag</th>\n",
              "      <th>conventions_median_score</th>\n",
              "      <th>conventions_above_or_below_median_flag</th>\n",
              "      <th>conventions_rounded_val</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>16005A45A20A</td>\n",
              "      <td>There's 90% of people in the world that wants ...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>1072</td>\n",
              "      <td>47</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5449</td>\n",
              "      <td>3.13555</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.021739</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.234015</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.11509</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.05243</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.086957</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1371</th>\n",
              "      <td>698A3F2B43B9</td>\n",
              "      <td>Have you ever thought about staring your futur...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>650</td>\n",
              "      <td>29</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3372</td>\n",
              "      <td>3.13555</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.021739</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.234015</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.11509</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.05243</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.086957</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3087</th>\n",
              "      <td>DB34A89420F2</td>\n",
              "      <td>I understand why you want to add an hour and t...</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>486</td>\n",
              "      <td>13</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2508</td>\n",
              "      <td>3.13555</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.021739</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.234015</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.11509</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.05243</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.086957</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1047</th>\n",
              "      <td>4FE6EABBFC00</td>\n",
              "      <td>One topic that is frequently debated is if peo...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>194</td>\n",
              "      <td>10</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1128</td>\n",
              "      <td>3.13555</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.021739</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.234015</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.11509</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.05243</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.086957</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1453</th>\n",
              "      <td>6FEF6D46714D</td>\n",
              "      <td>Has it ever crossed your mind that people toda...</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>597</td>\n",
              "      <td>27</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3239</td>\n",
              "      <td>3.13555</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.021739</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.234015</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.11509</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.05243</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.086957</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f1072fda-3c4c-4644-bf27-bccd664d3cde')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f1072fda-3c4c-4644-bf27-bccd664d3cde button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f1072fda-3c4c-4644-bf27-bccd664d3cde');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.shape, df_test.shape, df_val.shape"
      ],
      "metadata": {
        "id": "pDxgsliNCR0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5a65a10-f90e-4cdb-f2f3-e3fae6111e6d"
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3128, 48), (392, 48), (391, 48))"
            ]
          },
          "metadata": {},
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.describe()"
      ],
      "metadata": {
        "id": "FtENTOWsCR66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "c3cff0dd-a7a4-4ef6-ca72-7d3a9a0bc961"
      },
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          cohesion       syntax   vocabulary  phraseology      grammar  conventions  cohesion_map   syntax_map  vocabulary_map  phraseology_map  grammar_map  conventions_map  \\\n",
              "count  3128.000000  3128.000000  3128.000000  3128.000000  3128.000000  3128.000000   3128.000000  3128.000000     3128.000000      3128.000000  3128.000000      3128.000000   \n",
              "mean      3.128676     3.031330     3.235134     3.123242     3.029252     3.081841      4.257353     4.062660        4.470269         4.246483     4.058504         4.163683   \n",
              "std       0.660566     0.642023     0.582582     0.656872     0.697791     0.670081      1.321132     1.284046        1.165164         1.313744     1.395581         1.340161   \n",
              "min       1.000000     1.000000     1.000000     1.000000     1.000000     1.000000      0.000000     0.000000        0.000000         0.000000     0.000000         0.000000   \n",
              "25%       2.500000     2.500000     3.000000     2.500000     2.500000     2.500000      3.000000     3.000000        4.000000         3.000000     3.000000         3.000000   \n",
              "50%       3.000000     3.000000     3.000000     3.000000     3.000000     3.000000      4.000000     4.000000        4.000000         4.000000     4.000000         4.000000   \n",
              "75%       3.500000     3.500000     3.500000     3.500000     3.500000     3.500000      5.000000     5.000000        5.000000         5.000000     5.000000         5.000000   \n",
              "max       5.000000     5.000000     5.000000     5.000000     5.000000     5.000000      8.000000     8.000000        8.000000         8.000000     8.000000         8.000000   \n",
              "\n",
              "        word_count  sentence_count  total_score  full_text_len  cohesion_avg_score  cohesion_above_or_below_avg_flag  cohesion_median_score  cohesion_above_or_below_median_flag  \\\n",
              "count  3128.000000     3128.000000  3128.000000    3128.000000         3128.000000                       3128.000000                 3128.0                          3128.000000   \n",
              "mean    431.981458       18.186061    18.629476    2341.242327            3.128676                          0.429348                    3.0                             0.429348   \n",
              "std     191.928298       10.180678     3.355094    1029.872033            0.000000                          0.495062                    0.0                             0.495062   \n",
              "min      51.000000        1.000000     6.000000     269.000000            3.128676                          0.000000                    3.0                             0.000000   \n",
              "25%     294.750000       10.000000    16.000000    1601.000000            3.128676                          0.000000                    3.0                             0.000000   \n",
              "50%     401.000000       17.000000    18.500000    2174.000000            3.128676                          0.000000                    3.0                             0.000000   \n",
              "75%     530.000000       24.000000    21.000000    2869.250000            3.128676                          1.000000                    3.0                             1.000000   \n",
              "max    1260.000000       99.000000    30.000000    6044.000000            3.128676                          1.000000                    3.0                             1.000000   \n",
              "\n",
              "       cohesion_rounded_val  syntax_avg_score  syntax_above_or_below_avg_flag  syntax_median_score  syntax_above_or_below_median_flag  syntax_rounded_val  vocabulary_avg_score  \\\n",
              "count           3128.000000        3128.00000                     3128.000000               3128.0                        3128.000000         3128.000000          3.128000e+03   \n",
              "mean               3.143542           3.03133                        0.351662                  3.0                           0.351662            3.023338          3.235134e+00   \n",
              "std                0.853247           0.00000                        0.477566                  0.0                           0.477566            0.838645          4.441602e-16   \n",
              "min                1.000000           3.03133                        0.000000                  3.0                           0.000000            1.000000          3.235134e+00   \n",
              "25%                2.000000           3.03133                        0.000000                  3.0                           0.000000            2.000000          3.235134e+00   \n",
              "50%                3.000000           3.03133                        0.000000                  3.0                           0.000000            3.000000          3.235134e+00   \n",
              "75%                4.000000           3.03133                        1.000000                  3.0                           1.000000            4.000000          3.235134e+00   \n",
              "max                5.000000           3.03133                        1.000000                  3.0                           1.000000            5.000000          3.235134e+00   \n",
              "\n",
              "       vocabulary_above_or_below_avg_flag  vocabulary_median_score  vocabulary_above_or_below_median_flag  vocabulary_rounded_val  phraseology_avg_score  \\\n",
              "count                         3128.000000                   3128.0                            3128.000000             3128.000000           3.128000e+03   \n",
              "mean                             0.445332                      3.0                               0.445332                3.283887           3.123242e+00   \n",
              "std                              0.497082                      0.0                               0.497082                0.755728           4.441602e-16   \n",
              "min                              0.000000                      3.0                               0.000000                1.000000           3.123242e+00   \n",
              "25%                              0.000000                      3.0                               0.000000                3.000000           3.123242e+00   \n",
              "50%                              0.000000                      3.0                               0.000000                3.000000           3.123242e+00   \n",
              "75%                              1.000000                      3.0                               1.000000                4.000000           3.123242e+00   \n",
              "max                              1.000000                      3.0                               1.000000                5.000000           3.123242e+00   \n",
              "\n",
              "       phraseology_above_or_below_avg_flag  phraseology_median_score  phraseology_above_or_below_median_flag  phraseology_rounded_val  grammar_avg_score  \\\n",
              "count                          3128.000000                    3128.0                             3128.000000              3128.000000        3128.000000   \n",
              "mean                              0.417519                       3.0                                0.417519                 3.130754           3.029252   \n",
              "std                               0.493229                       0.0                                0.493229                 0.847789           0.000000   \n",
              "min                               0.000000                       3.0                                0.000000                 1.000000           3.029252   \n",
              "25%                               0.000000                       3.0                                0.000000                 2.000000           3.029252   \n",
              "50%                               0.000000                       3.0                                0.000000                 3.000000           3.029252   \n",
              "75%                               1.000000                       3.0                                1.000000                 4.000000           3.029252   \n",
              "max                               1.000000                       3.0                                1.000000                 5.000000           3.029252   \n",
              "\n",
              "       grammar_above_or_below_avg_flag  grammar_median_score  grammar_above_or_below_median_flag  grammar_rounded_val  conventions_avg_score  conventions_above_or_below_avg_flag  \\\n",
              "count                      3128.000000                3128.0                         3128.000000          3128.000000           3.128000e+03                          3128.000000   \n",
              "mean                          0.378836                   3.0                            0.378836             3.018862           3.081841e+00                             0.397059   \n",
              "std                           0.485175                   0.0                            0.485175             0.876785           4.441602e-16                             0.489367   \n",
              "min                           0.000000                   3.0                            0.000000             1.000000           3.081841e+00                             0.000000   \n",
              "25%                           0.000000                   3.0                            0.000000             2.000000           3.081841e+00                             0.000000   \n",
              "50%                           0.000000                   3.0                            0.000000             3.000000           3.081841e+00                             0.000000   \n",
              "75%                           1.000000                   3.0                            1.000000             4.000000           3.081841e+00                             1.000000   \n",
              "max                           1.000000                   3.0                            1.000000             5.000000           3.081841e+00                             1.000000   \n",
              "\n",
              "       conventions_median_score  conventions_above_or_below_median_flag  conventions_rounded_val  \n",
              "count                    3128.0                             3128.000000              3128.000000  \n",
              "mean                        3.0                                0.397059                 3.086637  \n",
              "std                         0.0                                0.489367                 0.855674  \n",
              "min                         3.0                                0.000000                 1.000000  \n",
              "25%                         3.0                                0.000000                 2.000000  \n",
              "50%                         3.0                                0.000000                 3.000000  \n",
              "75%                         3.0                                1.000000                 4.000000  \n",
              "max                         3.0                                1.000000                 5.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-47e901b7-e9af-4b55-ba4d-74b2f8dc9ee5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cohesion</th>\n",
              "      <th>syntax</th>\n",
              "      <th>vocabulary</th>\n",
              "      <th>phraseology</th>\n",
              "      <th>grammar</th>\n",
              "      <th>conventions</th>\n",
              "      <th>cohesion_map</th>\n",
              "      <th>syntax_map</th>\n",
              "      <th>vocabulary_map</th>\n",
              "      <th>phraseology_map</th>\n",
              "      <th>grammar_map</th>\n",
              "      <th>conventions_map</th>\n",
              "      <th>word_count</th>\n",
              "      <th>sentence_count</th>\n",
              "      <th>total_score</th>\n",
              "      <th>full_text_len</th>\n",
              "      <th>cohesion_avg_score</th>\n",
              "      <th>cohesion_above_or_below_avg_flag</th>\n",
              "      <th>cohesion_median_score</th>\n",
              "      <th>cohesion_above_or_below_median_flag</th>\n",
              "      <th>cohesion_rounded_val</th>\n",
              "      <th>syntax_avg_score</th>\n",
              "      <th>syntax_above_or_below_avg_flag</th>\n",
              "      <th>syntax_median_score</th>\n",
              "      <th>syntax_above_or_below_median_flag</th>\n",
              "      <th>syntax_rounded_val</th>\n",
              "      <th>vocabulary_avg_score</th>\n",
              "      <th>vocabulary_above_or_below_avg_flag</th>\n",
              "      <th>vocabulary_median_score</th>\n",
              "      <th>vocabulary_above_or_below_median_flag</th>\n",
              "      <th>vocabulary_rounded_val</th>\n",
              "      <th>phraseology_avg_score</th>\n",
              "      <th>phraseology_above_or_below_avg_flag</th>\n",
              "      <th>phraseology_median_score</th>\n",
              "      <th>phraseology_above_or_below_median_flag</th>\n",
              "      <th>phraseology_rounded_val</th>\n",
              "      <th>grammar_avg_score</th>\n",
              "      <th>grammar_above_or_below_avg_flag</th>\n",
              "      <th>grammar_median_score</th>\n",
              "      <th>grammar_above_or_below_median_flag</th>\n",
              "      <th>grammar_rounded_val</th>\n",
              "      <th>conventions_avg_score</th>\n",
              "      <th>conventions_above_or_below_avg_flag</th>\n",
              "      <th>conventions_median_score</th>\n",
              "      <th>conventions_above_or_below_median_flag</th>\n",
              "      <th>conventions_rounded_val</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>3128.000000</td>\n",
              "      <td>3128.000000</td>\n",
              "      <td>3128.000000</td>\n",
              "      <td>3128.000000</td>\n",
              "      <td>3128.000000</td>\n",
              "      <td>3128.000000</td>\n",
              "      <td>3128.000000</td>\n",
              "      <td>3128.000000</td>\n",
              "      <td>3128.000000</td>\n",
              "      <td>3128.000000</td>\n",
              "      <td>3128.000000</td>\n",
              "      <td>3128.000000</td>\n",
              "      <td>3128.000000</td>\n",
              "      <td>3128.000000</td>\n",
              "      <td>3128.000000</td>\n",
              "      <td>3128.000000</td>\n",
              "      <td>3128.000000</td>\n",
              "      <td>3128.000000</td>\n",
              "      <td>3128.0</td>\n",
              "      <td>3128.000000</td>\n",
              "      <td>3128.000000</td>\n",
              "      <td>3128.00000</td>\n",
              "      <td>3128.000000</td>\n",
              "      <td>3128.0</td>\n",
              "      <td>3128.000000</td>\n",
              "      <td>3128.000000</td>\n",
              "      <td>3.128000e+03</td>\n",
              "      <td>3128.000000</td>\n",
              "      <td>3128.0</td>\n",
              "      <td>3128.000000</td>\n",
              "      <td>3128.000000</td>\n",
              "      <td>3.128000e+03</td>\n",
              "      <td>3128.000000</td>\n",
              "      <td>3128.0</td>\n",
              "      <td>3128.000000</td>\n",
              "      <td>3128.000000</td>\n",
              "      <td>3128.000000</td>\n",
              "      <td>3128.000000</td>\n",
              "      <td>3128.0</td>\n",
              "      <td>3128.000000</td>\n",
              "      <td>3128.000000</td>\n",
              "      <td>3.128000e+03</td>\n",
              "      <td>3128.000000</td>\n",
              "      <td>3128.0</td>\n",
              "      <td>3128.000000</td>\n",
              "      <td>3128.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.128676</td>\n",
              "      <td>3.031330</td>\n",
              "      <td>3.235134</td>\n",
              "      <td>3.123242</td>\n",
              "      <td>3.029252</td>\n",
              "      <td>3.081841</td>\n",
              "      <td>4.257353</td>\n",
              "      <td>4.062660</td>\n",
              "      <td>4.470269</td>\n",
              "      <td>4.246483</td>\n",
              "      <td>4.058504</td>\n",
              "      <td>4.163683</td>\n",
              "      <td>431.981458</td>\n",
              "      <td>18.186061</td>\n",
              "      <td>18.629476</td>\n",
              "      <td>2341.242327</td>\n",
              "      <td>3.128676</td>\n",
              "      <td>0.429348</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.429348</td>\n",
              "      <td>3.143542</td>\n",
              "      <td>3.03133</td>\n",
              "      <td>0.351662</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.351662</td>\n",
              "      <td>3.023338</td>\n",
              "      <td>3.235134e+00</td>\n",
              "      <td>0.445332</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.445332</td>\n",
              "      <td>3.283887</td>\n",
              "      <td>3.123242e+00</td>\n",
              "      <td>0.417519</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.417519</td>\n",
              "      <td>3.130754</td>\n",
              "      <td>3.029252</td>\n",
              "      <td>0.378836</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.378836</td>\n",
              "      <td>3.018862</td>\n",
              "      <td>3.081841e+00</td>\n",
              "      <td>0.397059</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.397059</td>\n",
              "      <td>3.086637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.660566</td>\n",
              "      <td>0.642023</td>\n",
              "      <td>0.582582</td>\n",
              "      <td>0.656872</td>\n",
              "      <td>0.697791</td>\n",
              "      <td>0.670081</td>\n",
              "      <td>1.321132</td>\n",
              "      <td>1.284046</td>\n",
              "      <td>1.165164</td>\n",
              "      <td>1.313744</td>\n",
              "      <td>1.395581</td>\n",
              "      <td>1.340161</td>\n",
              "      <td>191.928298</td>\n",
              "      <td>10.180678</td>\n",
              "      <td>3.355094</td>\n",
              "      <td>1029.872033</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.495062</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.495062</td>\n",
              "      <td>0.853247</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.477566</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.477566</td>\n",
              "      <td>0.838645</td>\n",
              "      <td>4.441602e-16</td>\n",
              "      <td>0.497082</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.497082</td>\n",
              "      <td>0.755728</td>\n",
              "      <td>4.441602e-16</td>\n",
              "      <td>0.493229</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.493229</td>\n",
              "      <td>0.847789</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.485175</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.485175</td>\n",
              "      <td>0.876785</td>\n",
              "      <td>4.441602e-16</td>\n",
              "      <td>0.489367</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.489367</td>\n",
              "      <td>0.855674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>269.000000</td>\n",
              "      <td>3.128676</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.03133</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.235134e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.123242e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.029252</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.081841e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.500000</td>\n",
              "      <td>2.500000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.500000</td>\n",
              "      <td>2.500000</td>\n",
              "      <td>2.500000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>294.750000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>1601.000000</td>\n",
              "      <td>3.128676</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.03133</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.235134e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.123242e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.029252</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.081841e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>401.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>18.500000</td>\n",
              "      <td>2174.000000</td>\n",
              "      <td>3.128676</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.03133</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.235134e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.123242e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.029252</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.081841e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>3.500000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>530.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>2869.250000</td>\n",
              "      <td>3.128676</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.03133</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.235134e+00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.123242e+00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.029252</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.081841e+00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>1260.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>6044.000000</td>\n",
              "      <td>3.128676</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.03133</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.235134e+00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.123242e+00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.029252</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.081841e+00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-47e901b7-e9af-4b55-ba4d-74b2f8dc9ee5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-47e901b7-e9af-4b55-ba4d-74b2f8dc9ee5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-47e901b7-e9af-4b55-ba4d-74b2f8dc9ee5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df_train.columns"
      ],
      "metadata": {
        "id": "eO3UOIBgfvef"
      },
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Unique Values for Each Label**"
      ],
      "metadata": {
        "id": "hhWJgI2QONaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get_unique_values_for_labels(df_train, label_cols)"
      ],
      "metadata": {
        "id": "iS7iZnEIHpOc"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Unique Values for Each Rounded Label**"
      ],
      "metadata": {
        "id": "A1TQQfdIPNn0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get_unique_values_for_labels(df_train, label_rounded_cols)"
      ],
      "metadata": {
        "id": "3DWAOVw49kZE"
      },
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Value Counts for Each Label**"
      ],
      "metadata": {
        "id": "FQzHk9gJTpGF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get_value_counts_for_labels(df_train, label_cols)"
      ],
      "metadata": {
        "id": "vEOP_FvYTtL2"
      },
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot_count(df_train, label_cols)"
      ],
      "metadata": {
        "id": "prGSzmkPZ3gn"
      },
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Value Counts for Each Rounded Label**"
      ],
      "metadata": {
        "id": "QTjC60_xP1gv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get_value_counts_for_labels(df_train, label_rounded_cols)"
      ],
      "metadata": {
        "id": "Pldhpwbx9o30"
      },
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot_count(df_train, label_rounded_cols)"
      ],
      "metadata": {
        "id": "KIaZwxVU9vqs"
      },
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Full Text Length Stats**"
      ],
      "metadata": {
        "id": "KXwT00dRHxGN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df_train.full_text.str.len().describe()"
      ],
      "metadata": {
        "id": "xmi1gFYbHsGb"
      },
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Word Count Stats**"
      ],
      "metadata": {
        "id": "R-EOY4qnIcUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df_train.word_count.describe()"
      ],
      "metadata": {
        "id": "qvE2zoXjIfyB"
      },
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Sentence Count Stats**"
      ],
      "metadata": {
        "id": "FPKsmw8oIlLy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df_train.sentence_count.describe()"
      ],
      "metadata": {
        "id": "IDyYyghnIoW9"
      },
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_train[df_train.sentence_count == 1][['full_text']]"
      ],
      "metadata": {
        "id": "ZbPqbB4DIyEw"
      },
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Visualization**"
      ],
      "metadata": {
        "id": "oYdTWC6zAFzi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Corelation Matrix of the Label Columns**"
      ],
      "metadata": {
        "id": "Lm57jeEsN-Vf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# corr = df_train[label_cols].corr()\n",
        "\n",
        "# # Generate a mask for the upper triangle\n",
        "# mask = np.triu(np.ones_like(corr, dtype = bool))\n",
        "\n",
        "# sns.set(rc = {\"figure.figsize\": (10, 8)})\n",
        "\n",
        "# sns.heatmap(corr, \n",
        "#             annot = True, \n",
        "#             cmap = \"coolwarm\", \n",
        "#             mask = mask,\n",
        "#             fmt  = \".5f\")\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "OsNghRH8GBHb"
      },
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Essay Length, Word Count, Total Score, Sentence Count Distribution**\n",
        "\n",
        "Essay length, word count and sentence count diostributions have normal shape, though left skewed. Total score distribution looks bi-modal."
      ],
      "metadata": {
        "id": "v1l2yTGnKzsy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.figure(figsize=(20,5))\n",
        "\n",
        "# plt.subplot(1,4,1)\n",
        "# sns.histplot(data=df_train, x='word_count', kde=True)\n",
        "# plt.axvline(x=df_train['word_count'].mean(),color='red')\n",
        "# plt.axvline(x=df_train['word_count'].median(),color='black')\n",
        "# plt.xlabel('Word Count Distribution',fontsize=12)\n",
        "# plt.title('Word Count Distribution',fontsize=16)\n",
        "\n",
        "# plt.subplot(1,4,2)\n",
        "# sns.histplot(data=df_train, x='full_text_len', kde=True)\n",
        "# plt.axvline(x=df_train['full_text_len'].mean(),color='red')\n",
        "# plt.axvline(x=df_train['full_text_len'].median(),color='black')\n",
        "# plt.xlabel('Full Text Length Distribution',fontsize=12)\n",
        "# plt.title('Full Text Length Distribution',fontsize=16)\n",
        "\n",
        "# plt.subplot(1,4,3)\n",
        "# sns.histplot(data=df_train, x='total_score', kde=True)\n",
        "# plt.axvline(x=df_train['total_score'].mean(),color='red')\n",
        "# plt.axvline(x=df_train['total_score'].median(),color='black')\n",
        "# plt.xlabel('Total Score Distribution',fontsize=12)\n",
        "# plt.title('Total Score Distribution',fontsize=16)\n",
        "\n",
        "# plt.subplot(1,4,4)\n",
        "# sns.histplot(data=df_train, x='sentence_count', kde=True)\n",
        "# plt.axvline(x=df_train['sentence_count'].mean(),color='red')\n",
        "# plt.axvline(x=df_train['sentence_count'].median(),color='black')\n",
        "# plt.xlabel('Sentence Count Distribution',fontsize=12)\n",
        "# plt.title('Sentence Count Distribution',fontsize=16)"
      ],
      "metadata": {
        "id": "jMSfYQqLK3UW"
      },
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Word Count Vs Individual Label Scores**"
      ],
      "metadata": {
        "id": "wAW3Z-BxX9qi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get_histogram_for_col(df_train, label_cols, 'word_count')"
      ],
      "metadata": {
        "id": "uDO43g-fzqqD"
      },
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Word Count Vs Individual Rounded Label Scores**"
      ],
      "metadata": {
        "id": "kdda-LBvO-Qd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get_histogram_for_col(df_train, label_rounded_cols, 'word_count')"
      ],
      "metadata": {
        "id": "N4orWBDq0ERo"
      },
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Sentence Count Vs Individual Label Scores**"
      ],
      "metadata": {
        "id": "_AGO4SrlYcZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get_histogram_for_col(df_train, label_cols, 'sentence_count')"
      ],
      "metadata": {
        "id": "vWBjXi0R0MUv"
      },
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Sentence Count Vs Individual Rounded Label Scores**"
      ],
      "metadata": {
        "id": "Blag-pumPIgu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get_histogram_for_col(df_train, label_rounded_cols, 'sentence_count')"
      ],
      "metadata": {
        "id": "un2OywUX9Zkn"
      },
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Distribution of Labels Above and Below Average in the Respective Category**"
      ],
      "metadata": {
        "id": "gEfySDbNOTJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get_count_plot_for_ind_col(df_train, '_above_or_below_avg_flag', label_cols)"
      ],
      "metadata": {
        "id": "J0ilIF_dE7-z"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Distribution of Labels Above and Below Median in the Respective Category**"
      ],
      "metadata": {
        "id": "4e-8H751RROi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get_count_plot_for_ind_col(df_train, '_above_or_below_median_flag', label_cols)"
      ],
      "metadata": {
        "id": "NWcHq1tTRUwE"
      },
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For all the labels we see that most of the label values are below average and median values."
      ],
      "metadata": {
        "id": "zOZHsj_VRlg-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Distribution of Labels**"
      ],
      "metadata": {
        "id": "rcB_ojpNXh4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fig, ax = plt.subplots(1, len(label_cols), figsize=(40,10))\n",
        "\n",
        "# for idx, label in enumerate(label_cols):\n",
        "#     sns.distplot(x = df_train[label],\n",
        "#                  ax = ax[idx]\n",
        "#                 )\n",
        "#     ax[idx].set_title(label)\n",
        "#     #plt.show(block = False)"
      ],
      "metadata": {
        "id": "qs86knBLIEOR"
      },
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Average Score Per Label**"
      ],
      "metadata": {
        "id": "x08cEWvzKdEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get_barplot_for_each_label(df_train, label_cols, '_avg_score')"
      ],
      "metadata": {
        "id": "dO58Qh1VE8B8"
      },
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Median Score Per Label**"
      ],
      "metadata": {
        "id": "C-wgt-ouU3it"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get_barplot_for_each_label(df_train, label_cols, '_median_score')"
      ],
      "metadata": {
        "id": "VsGe1C0bWUGE"
      },
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Most Frequent Words**"
      ],
      "metadata": {
        "id": "bILNga0wabjS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# text = df_train[df_train[label_cols].sum(axis=1)==30]['full_text'].values[0]\n",
        "# word_cloud = WordCloud(stopwords=STOPWORDS, colormap='Pastel1', collocations=False, width=1200, height=700, background_color = \"black\").generate(text)\n",
        "# plt.figure(figsize=(20,8))\n",
        "# plt.imshow(word_cloud)\n",
        "# plt.axis(\"off\")\n",
        "# plt.show()\n",
        "     "
      ],
      "metadata": {
        "id": "gk6gXM4_E8E2"
      },
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Regression** Model with **BERT**\n",
        "[Regression with Text Input Using BERT and Transformers](https://lajavaness.medium.com/regression-with-text-input-using-bert-and-transformers-71c155034b13)\n"
      ],
      "metadata": {
        "id": "Tkyi4qkae3pt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Checkpoint and **Tokenization** from Pre-trained BERT"
      ],
      "metadata": {
        "id": "sZfveEfmubRr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, TFBertModel\n",
        "\n",
        "#make it easier to use a variety of BERT subword models\n",
        "model_checkpoint = 'bert-base-cased'   # case sensitive (care about upper and lower case)\n",
        "bert_model = TFBertModel.from_pretrained(model_checkpoint)  \n",
        "bert_tokenizer = BertTokenizer.from_pretrained(model_checkpoint)"
      ],
      "metadata": {
        "id": "prqm6UhKE8H-"
      },
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for layer in bert_model.weights:\n",
        "#     print(layer.name, layer.trainable)"
      ],
      "metadata": {
        "id": "5TC3uLX46ykI"
      },
      "execution_count": 225,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_train.head(2)\n",
        "# df_train.iloc[:, 1:7].head(2)\n",
        "# label_cols"
      ],
      "metadata": {
        "id": "NMTyK09qtgMg"
      },
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Split Data** into **X and Y**\n"
      ],
      "metadata": {
        "id": "0ekOzuscyefN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df_val"
      ],
      "metadata": {
        "id": "jM3lZd4WCnAD"
      },
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(label_map_cols)\n",
        "# print(cat_label_cols)\n",
        "# print(label_cols)"
      ],
      "metadata": {
        "id": "9bBtkiqTCyXa"
      },
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, X_test = df_train['full_text'], df_val['full_text'], df_test['full_text']\n",
        "y_train, y_val, y_test = np.array(df_train[label_cols]), np.array(df_val[label_cols]), np.array(df_test[label_cols])\n",
        "\n",
        "# # For Classification with 9 classes (0-8)\n",
        "# # Handling map columns, this maintains the same number of levels as present in the original kpi sets.\n",
        "# y_train_map, y_val_map, y_test_map = np.array(df_train[label_map_cols]), np.array(df_val[label_map_cols]), np.array(df_test[label_map_cols])\n",
        "# y_train_map_combined = get_label_dict(df_train, label_map_cols, cat_label_cols)\n",
        "# y_test_map_combined = get_label_dict(df_test, label_map_cols, cat_label_cols)\n",
        "# y_val_map_combined = get_label_dict(df_val, label_map_cols, cat_label_cols)\n",
        "# y_val_map_combined\n",
        "# # # For Classification with 5 classes (1-5)\n",
        "# # # Handling scaled values. Here we are converting the decimal values to nearest integers.\n",
        "# # # Thus .5, 1.5, 2.5, 3.5 and 4.5 map to 1, 2, 3, 4 and 5 respectively.\n",
        "# # y_train_scaled, y_val_scaled, y_test_scaled = np.array(df_train[label_rounded_cols]), np.array(df_val[label_rounded_cols]), np.array(df_test[label_rounded_cols])\n",
        "# # y_train_scaled_combined = get_label_dict(df_train, label_rounded_cols, cat_label_cols)\n",
        "# # y_test_scaled_combined = get_label_dict(df_test, label_rounded_cols, cat_label_cols)\n",
        "# # y_val_scaled_combined = get_label_dict(df_val, label_rounded_cols, cat_label_cols)"
      ],
      "metadata": {
        "id": "bZSjgsFgfhNm"
      },
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Generate Input Embeddings** - Train/Validation/Test Set"
      ],
      "metadata": {
        "id": "IJCY3zRUydcB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 512"
      ],
      "metadata": {
        "id": "ULNaCJQ9bz1x"
      },
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_encodings = bert_tokenizer(X_train.tolist(), dtype=\"int32\", truncation=True, padding=True, max_length=MAX_LENGTH, return_tensors='tf')\n",
        "val_encodings = bert_tokenizer(X_val.tolist(), dtype=\"int32\", truncation=True, padding=True, max_length=MAX_LENGTH, return_tensors='tf')\n",
        "test_encodings = bert_tokenizer(X_test.tolist(), dtype=\"int32\", truncation=True, padding=True, max_length=MAX_LENGTH, return_tensors='tf')"
      ],
      "metadata": {
        "id": "pm1gV7bIE8Kx"
      },
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Run Experiments**"
      ],
      "metadata": {
        "id": "94djOdz8GWOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def create_dataframes(idc_image_path, idc_image_label, directory_name):\n",
        "#   same_name = directory_name.lower() + '_'\n",
        "#   #creating the dataframes that we will be passing to our generators\n",
        "#   idc_data_cleaned = {'path': idc_image_path,\n",
        "#             'label': idc_image_label}\n",
        "#   idc_df = pd.DataFrame(idc_data_cleaned)\n",
        "#   df = idc_df.sample(frac = 1)\n",
        "#   print(df)\n",
        "#   csv_path = directory_path\n",
        "#   csv_file = df.to_csv(csv_path + '/' + same_name + 'idc_dataframe.csv')\n",
        "#   csv_file_path = csv_path + '/' + same_name + 'idc_dataframe.csv'\n",
        "#   return csv_file_path\n",
        "\n",
        "# train_dataframe = create_dataframes(train_paths, train_labels, train_dir)\n",
        "# train_generator = pd.read_csv(train_dataframe)\n",
        "\n",
        "# # ========== Performace metrics summary ===================================\n",
        "# perf_metrics = pd.DataFrame({'TL Model':chosen_model, \n",
        "#                              'Test_Loss':round(test_loss,2), \n",
        "#                              'Test_Acc':round(test_accuracy, 2), \n",
        "#                              'Train_Acc':round(training_accuracy, 2), \n",
        "#                              'Val_Acc':round(val_accuracy, 2), \n",
        "#                              'Num_Trainable_Params':  f'{count_trainable_params:,}',\n",
        "#                              'Precision':round(precision, 2), \n",
        "#                              'Recall':round(recall, 2), \n",
        "#                              'F1_score': round(f1score, 2),\n",
        "#                              'ROC-AUC':round(area_under_curve, 2), \n",
        "#                              'Cohen Kappa': cohen_kappa,\n",
        "#                              'Zero-One Loss': zo_loss,\n",
        "#                              'lr':lr,\n",
        "#                              'activation':activation,\n",
        "#                              'optimizer':optimizer}, index=[0])\n",
        "# perf_metrics\n"
      ],
      "metadata": {
        "id": "yziS45DjV6P4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def perf_summary(regression_with_bert,\n",
        "#                 num_trainable_params,\n",
        "#                 num_hidden_layer,\n",
        "#                 num_hidden_units,\n",
        "#                 dropout,\n",
        "#                 learning_rate,\n",
        "#                 batch_size,\n",
        "#                 epochs):\n",
        "  \n",
        "#   # model summary and plot model structure\n",
        "#   # display(regression_with_bert.summary())\n",
        "#   # display(keras.utils.plot_model(regression_with_bert, show_shapes=False, show_dtype=False, show_layer_names=True, dpi=90))\n",
        "\n",
        "#   # train model\n",
        "#   df_regression_model_history = train_regression(regression_with_bert, batch_size, epochs)\n",
        "#   print(\"\\nPlotting loss and MCRMSE...\")\n",
        "#   plot_loss_mcrmse(df_regression_model_history, 'MCRMSE')  \n",
        "#   # print(\"\\nTensorBoard: Evolution of Loss and MCRMSE:\\n=============================================\")\n",
        "#   # %tensorboard --logdir logs/fit\n",
        "\n",
        "#   # Evaluate test set\n",
        "#   score_regression = evaluate_test_labels(regression_with_bert)\n",
        "\n",
        "#   # Predict test set\n",
        "#   df_pred = predict_test_labels(regression_with_bert)\n",
        "#   df_pred_scaled = scaled_pred(df_pred)\n",
        "#   # display('\\ndf_pred:\\n==============\\n', df_pred)\n",
        "#   # display('\\ndf_pred_scaled:\\n==============\\n', df_pred_scaled)\n",
        "  \n",
        "#   # Create a final table with y_true, y_pred_raw, and y_pred_scaled\n",
        "#   display(generate_final_table(df_pred))\n",
        "\n",
        "#   # ========== Performace metrics summary ===================================\n",
        "#   perf_metrics = pd.DataFrame({'NLP Model':\"BERT\",\n",
        "#                               'Num_Retrainable_layer': layer,\n",
        "#                               'Epochs':epochs, \n",
        "#                               'Learning_Rate':learning_rate,\n",
        "#                               'Test_MCRMSE':round(score_regression[1], 2), \n",
        "#                               'Test_Loss':round(score_regression[0], 2), \n",
        "#                               'Train_MCRMSE':round(df_regression_model_history.iloc[-1][1], 2), \n",
        "#                               'Train_Loss':round(df_regression_model_history.iloc[-1][0], 2), \n",
        "#                               'Val_MCRMSE':round(df_regression_model_history.iloc[-1][3], 2), \n",
        "#                               'Val_Loss':round(df_regression_model_history.iloc[-1][2], 2), \n",
        "#                               'Num_Trainable_Params':  f'{num_trainable_params:,}',\n",
        "#                               'Num_Hidden_Layer':num_hidden_layer, \n",
        "#                               'Num_hidden_Units':num_hidden_units,                                 \n",
        "#                               'Dropout': dropout, \n",
        "#                               'Batch_Size': batch_size}, index=[0])\n",
        "#   df_perf_summary = df_perf_summary.append(perf_metrics)\n",
        "#   return df_perf_summary"
      ],
      "metadata": {
        "id": "jMjBhuU5d_Pj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# actual_labels = ['true_' + col for col in label_cols]\n",
        "def run_regression_experiment(num_train_layers=0,\n",
        "                              num_hidden_layer=1,\n",
        "                              num_hidden_units=256,\n",
        "                              dropout=0.3,\n",
        "                              learning_rate=0.00005,\n",
        "                              batch_size=8,\n",
        "                              csv_filename='perf_summary_regression_w_BERT.csv',\n",
        "                              epochs=10):\n",
        "\n",
        "# run_regression_experiment(num_train_layers=random.choice([2,4,6,8,10,12]),\n",
        "#                           num_hidden_layer = random.choice([1,2]),\n",
        "#                           num_hidden_units=random.choice([64,128,256]),\n",
        "#                           dropout=random.choice([0.1, 0.3, 0.4]),\n",
        "#                           learning_rate=random.choice([0.00005, 0.00001, 0.000001]),\n",
        "#                           batch_size=random.choice([8,16]))\n",
        "\n",
        "  df_perf_summary = pd.DataFrame()\n",
        "  for layer in num_train_layers:  \n",
        "    print('\\n******************************************************')\n",
        "    print(f'Regression with BERT: Number of Unfrozen Layers = {layer}')\n",
        "    print('******************************************************\\n')\n",
        "\n",
        "\n",
        "    # build a regression model\n",
        "    regression_with_bert, num_trainable_params, num_non_trainable_params = regression_model_with_bert(num_classes = 9,                          # [1, 1.5, 2, 2.5....4.5, 5]: 9 classes\n",
        "                                                                                                      num_train_layers = layer,\n",
        "                                                                                                      num_hidden_layer = num_hidden_layer,\n",
        "                                                                                                      num_hidden_units = num_hidden_units,\n",
        "                                                                                                      dropout = dropout,\n",
        "                                                                                                      learning_rate = learning_rate)\n",
        "    # print(f'Parameter Values:\\n======================\\nnum_hidden_layer = {num_hidden_layer}\\nnum_hidden_units = {num_hidden_units}\\ndropout = {dropout}\\nlearning_rate = {learning_rate}\\nbatch_size = {batch_size}\\n')\n",
        "    \n",
        "    \n",
        "    # model summary and plot model structure\n",
        "    display(regression_with_bert.summary())\n",
        "    display(keras.utils.plot_model(regression_with_bert, show_shapes=False, show_dtype=False, show_layer_names=True, dpi=90))\n",
        "\n",
        "    # train model\n",
        "    df_regression_model_history = train_regression(regression_with_bert, batch_size, epochs)\n",
        "    print(\"\\nPlotting loss and MCRMSE...\")\n",
        "    plot_loss_mcrmse(df_regression_model_history, 'MCRMSE')  \n",
        "    # print(\"\\nTensorBoard: Evolution of Loss and MCRMSE:\\n=============================================\")\n",
        "    # %tensorboard --logdir logs/fit\n",
        "\n",
        "    # Evaluate test set\n",
        "    score_regression = evaluate_test_labels(regression_with_bert)\n",
        "\n",
        "    # Predict test set\n",
        "    df_pred = predict_test_labels(regression_with_bert)\n",
        "    df_pred_scaled = scaled_pred(df_pred)\n",
        "    # display('\\ndf_pred:\\n==============\\n', df_pred)\n",
        "    # display('\\ndf_pred_scaled:\\n==============\\n', df_pred_scaled)\n",
        "    \n",
        "    # Create a final table with y_true, y_pred_raw, and y_pred_scaled\n",
        "    # display(generate_final_table(df_pred))\n",
        "\n",
        "    # ========== Performace metrics summary ===================================\n",
        "    perf_metrics = pd.DataFrame({'NLP Model':\"bert-base-cased\",\n",
        "                                'Num_Trainable_layers': layer,\n",
        "                                'Trainable_Params':  f'{num_trainable_params:,}',\n",
        "                                'Non-Trainable_Params':  f'{num_non_trainable_params:,}',\n",
        "                                'Epochs':epochs,                                 \n",
        "                                'Test_MCRMSE':round(score_regression[1], 4), \n",
        "                                'Test_Loss':round(score_regression[0], 4), \n",
        "                                'Train_MCRMSE':round(df_regression_model_history.iloc[-1][1], 4), \n",
        "                                'Train_Loss':round(df_regression_model_history.iloc[-1][0], 4), \n",
        "                                'Val_MCRMSE':round(df_regression_model_history.iloc[-1][3], 4), \n",
        "                                'Val_Loss':round(df_regression_model_history.iloc[-1][2], 4),  \n",
        "                                'Learning_Rate':learning_rate,                               \n",
        "                                'Num_Hidden_Layers':num_hidden_layer, \n",
        "                                'Num_hidden_Units':num_hidden_units,                                 \n",
        "                                'Dropout': dropout, \n",
        "                                'Batch_Size': batch_size}, index=[0])\n",
        "    df_perf_summary = df_perf_summary.append(perf_metrics)\n",
        "  df_perf_summary.to_csv('perf_summary_regression_w_BERT_1.csv', index=False)\n",
        "  display(df_perf_summary.reset_index(drop=True))\n"
      ],
      "metadata": {
        "id": "qQdfrVfztf_1"
      },
      "execution_count": 234,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def perf_metrics_summary():\n",
        "#   for layer in np.arange(0, 13, 6):  \n",
        "#     run_regression_experiment(num_train_layers=layer,\n",
        "#                               epochs=10)\n",
        "#     # ========== Performace metrics summary ===================================\n",
        "#     perf_metrics = pd.DataFrame({'NLP Model':chosen_model, \n",
        "#                                 'epochs':epochs, \n",
        "#                                 'Test_Acc':round(df_regression_model_history.iloc[-1][1], 2), \n",
        "#                                 'Test_Loss':round(df_regression_model_history.iloc[-1][0], 2), \n",
        "#                                 'Train_Acc':round(training_accuracy, 2), \n",
        "#                                 'Train_Loss':round(training_accuracy, 2), \n",
        "#                                 'Val_Acc':round(val_accuracy, 2), \n",
        "#                                 'Val_loss':round(val_accuracy, 2), \n",
        "#                                 'Num_Trainable_Params':  f'{count_trainable_params:,}',\n",
        "#                                 'num_hidden_layer':round(num_train_layers, 2), \n",
        "#                                 'num_hidden_units':round(recall, 2), \n",
        "#                                 'learning_rate': round(f1score, 2),\n",
        "#                                 'dropout':round(dropout, 2), \n",
        "#                                 'batch_size': batch_size}, index=[0])"
      ],
      "metadata": {
        "id": "Nlz1SGhLYe8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Build Regression Model with BERT**"
      ],
      "metadata": {
        "id": "VKFVHp0YtvnV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def regression_model_with_bert(num_classes=9,                  # [1, 1.5, 2, 2.5....4.5, 5]: 9 classes\n",
        "                               num_train_layers=0,\n",
        "                               num_hidden_layer=1,\n",
        "                               num_hidden_units=256,\n",
        "                               dropout=0.3,\n",
        "                               learning_rate=0.00005):\n",
        "    \"\"\"\n",
        "    Build a simple classification model with BERT. Use the Pooler Output for classification purposes.\n",
        "    \"\"\"\n",
        "    # =========== BEGIN generate \"input features\" using pre-trained model tokenizer ==================================\n",
        "    # bert_model = TFBertModel.from_pretrained(checkpoint)    \n",
        "    if num_train_layers == 0:\n",
        "        bert_model.trainable = False                 # Freeze all layers of pre-trained BERT model\n",
        "        # print(f'IF block: Unfreeze {num_train_layers} layers from BERT:\\n=================================\\n \\\n",
        "        #   Trainable_params: {count_params(bert_model.trainable_weights)}\\nNon_trainable_params: {count_params(bert_model.non_trainable_weights)}\\n')\n",
        "\n",
        "    elif num_train_layers == 12:         \n",
        "        bert_model.trainable = True                  # Train all layers of the BERT model\n",
        "        # print(f'ELIF block: Unfreeze {num_train_layers} layers from BERT:\\n=================================\\n \\\n",
        "        # Trainable_params: {count_params(bert_model.trainable_weights)}\\nNon_trainable_params: {count_params(bert_model.non_trainable_weights)}\\n')\n",
        "\n",
        "    else:                                            # Restrict training to the num_train_layers outer transformer layers\n",
        "        retrain_layers = []\n",
        "        for retrain_layer_number in range(num_train_layers):\n",
        "            layer_code = '_' + str(11 - retrain_layer_number)\n",
        "            retrain_layers.append(layer_code) \n",
        "        # print('retrain layers: ', retrain_layers)\n",
        "\n",
        "        for w in bert_model.weights:\n",
        "            if not any([x in w.name for x in retrain_layers]):\n",
        "                #print('freezing: ', w)\n",
        "                w._trainable = False\n",
        "        # print(f'\\nELSE block: Unfreeze {num_train_layers} layers from BERT:\\n=================================\\n \\\n",
        "        # Trainable_params: {count_params(bert_model.trainable_weights)}\\nNon_trainable_params: {count_params(bert_model.non_trainable_weights)}\\n')\n",
        "    \n",
        "    # Input Layer\n",
        "    input_ids = tf.keras.layers.Input(shape=(MAX_LENGTH), dtype=tf.int64, name='input_ids_layer')\n",
        "    attention_mask = tf.keras.layers.Input(shape=(MAX_LENGTH), dtype=tf.int64, name='attention_mask_layer')\n",
        "\n",
        "    bert_inputs = {'input_ids': input_ids,\n",
        "                  # 'token_type_ids': token_type_ids,\n",
        "                  'attention_mask': attention_mask\n",
        "                  }\n",
        "                      \n",
        "    # Bert output: being used as an input feature in the classification model below\n",
        "    bert_out = bert_model(bert_inputs)        # full features as an input to the following classification model\n",
        "    # pooler_output = bert_out[1]             # one vector for each\n",
        "    cls_token = bert_out[0][:, 0, :]          # give us a raw CLS tokens\n",
        "\n",
        "\n",
        "    layer_list = []\n",
        "    for hidden_layer_number in range(num_hidden_layer):\n",
        "        if hidden_layer_number == 0:\n",
        "            hidden_layer = tf.keras.layers.Dense(units = num_hidden_units\n",
        "                                        , activation = 'relu'\n",
        "                                        , name = 'hidden_layer_' + str(hidden_layer_number + 1)\n",
        "                                        )(cls_token)\n",
        "        else:\n",
        "            hidden_layer = tf.keras.layers.Dense(units = num_hidden_units\n",
        "                                        , activation = 'relu'\n",
        "                                        , name = 'hidden_layer_' + str(hidden_layer_number + 1)\n",
        "                                        )(layer_list[-1])\n",
        "        layer_list.append(hidden_layer)\n",
        "        dropout_layer = tf.keras.layers.Dropout(dropout, name = 'dropout_layer_' + str(hidden_layer_number + 1))(hidden_layer) \n",
        "        layer_list.append(dropout_layer)\n",
        "    # print('layer_list: ', layer_list)\n",
        "    # print('layer_list[-1]: ', layer_list[-1])\n",
        "\n",
        "    output = tf.keras.layers.Dense(6,)(layer_list[-1])\n",
        "    regression_model = tf.keras.Model(inputs = [input_ids, attention_mask], outputs = output)\n",
        "\n",
        "    # for layer in bert_model.layers[-num_train_layers:]:\n",
        "    #   print('layer: ', layer)\n",
        "    #   layer.trainable = True\n",
        "    # print(f'AFTER Unfreeze - Trainable_params: {count_params(bert_model.trainable_weights)}\\nAFTER Unfreeze - Non_trainable_params: {count_params(bert_model.non_trainable_weights)}')\n",
        "\n",
        "    regression_model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate),\n",
        "                             loss=MCRMSE,\n",
        "                             metrics=MCRMSE) \n",
        "                            # loss=[MCRMSE, addtl_loss],\n",
        "                            # metrics=[MCRMSE, addtl_metrics]) \n",
        "    return regression_model, count_params(regression_model.trainable_weights), count_params(regression_model.non_trainable_weights)"
      ],
      "metadata": {
        "id": "Qdt1Vtl9RVnc"
      },
      "execution_count": 235,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up a TensorBoard\n",
        "[Get started with TensorBoard](https://www.tensorflow.org/tensorboard/get_started#:~:text=TensorBoard%20is%20a%20tool%20for,dimensional%20space%2C%20and%20much%20more)"
      ],
      "metadata": {
        "id": "KW5UFWhmiJkJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Load the TensorBoard notebook extension\n",
        "# %load_ext tensorboard"
      ],
      "metadata": {
        "id": "l8bZDErgg1NE"
      },
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Clear any logs from previous runs\n",
        "# !rm -rf ./logs/"
      ],
      "metadata": {
        "id": "U0IdoA8og1Ei"
      },
      "execution_count": 237,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
      ],
      "metadata": {
        "id": "c37lLIBMhgtz"
      },
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the Regression Model with:\n",
        "- **Early Stopping callback** - Stop training when start overfitting\n",
        "- **Model Checkpoint callback** - Save the model output in the temp folder (Model_Checkpoint) created in Google Drive. Whenever you re-run your model, the existing logs will be replaced with the output of new run.\n",
        "- **Tensorboard callback** - Display the loss and MCRMSE evolution"
      ],
      "metadata": {
        "id": "Bb7jUXUFiTxy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want to run until val_loss started increasing and over passing the training loss (overfitting). That's where the right number of epochs we need to have to run the model. To control this, we set up the Early Stopping callback."
      ],
      "metadata": {
        "id": "QOsxqmOww8GX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# batch_size = random.choice([8,16])\n",
        "def train_regression(model, batch_size, epochs):  \n",
        "  checkpoint_filepath = '/content/gdrive/MyDrive/Kaggle/Model_Checkpoint'         #  Create a new directory, Model_Checkpoint, in my Google Drive first and navigate the path here\n",
        "  model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath,\n",
        "                                                                  save_weights_only=True,\n",
        "                                                                  monitor='val_loss',\n",
        "                                                                  mode='min',\n",
        "                                                                  save_best_only=True)  \n",
        " \n",
        "  callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
        "  print('Training Regression with BERT.....\\n====================================='  )\n",
        "  regression_model_history = model.fit([train_encodings.input_ids, \n",
        "                                        train_encodings.attention_mask\n",
        "                                        ], \n",
        "                                        y_train,   \n",
        "                                        validation_data =([val_encodings.input_ids, \n",
        "                                                            val_encodings.attention_mask], \n",
        "                                                          y_val\n",
        "                                                          ),    \n",
        "                                        batch_size = batch_size, \n",
        "                                        # callbacks=[callback, model_checkpoint_callback, tensorboard_callback],\n",
        "                                        callbacks=[callback, model_checkpoint_callback],\n",
        "                                        epochs = epochs \n",
        "                                        # verbose=0    # make output invisible\n",
        "                                        )    \n",
        "  df_regression_model_history = pd.DataFrame(regression_model_history.history)\n",
        "  display(df_regression_model_history.T)     \n",
        "  return df_regression_model_history                                       "
      ],
      "metadata": {
        "id": "SxfupcqtYVML"
      },
      "execution_count": 239,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_loss_mcrmse(df, eval_metric):\n",
        "    x_arr = np.arange(len(df['loss'])) + 1\n",
        "    fig = plt.figure(figsize=(12, 4))\n",
        "    ax = fig.add_subplot(1, 2, 1)\n",
        "    ax.plot(x_arr, df['loss'], '-o', label = 'Train loss')\n",
        "    ax.plot(x_arr, df['val_loss'], '--<', label = 'Validation loss')\n",
        "    ax.legend(fontsize = 12)\n",
        "    ax.set_xlabel('Epoch', size = 15)\n",
        "    ax.set_ylabel('Loss', size = 15)\n",
        "\n",
        "    ax = fig.add_subplot(1, 2, 2)\n",
        "    ax.plot(x_arr, df[eval_metric], '-o', label = 'Train ' + eval_metric)\n",
        "    ax.plot(x_arr, df['val_' + eval_metric], '--<', label = 'Validation ' + eval_metric)\n",
        "    ax.legend(fontsize = 12)\n",
        "    ax.set_xlabel('Epoch', size = 15)\n",
        "    ax.set_ylabel('Accuracy', size = 15)\n",
        "    #ax.set_ylim(0,1)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "pryZ84H5mTm8"
      },
      "execution_count": 240,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate Test Set"
      ],
      "metadata": {
        "id": "2VtKGJ_4la2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_test_labels(model):\n",
        "  score_regression = model.evaluate([test_encodings.input_ids, \n",
        "                                          test_encodings.attention_mask\n",
        "                                          ], \n",
        "                                          y_test\n",
        "                                          ) \n",
        "  print('\\nEvaluate Test Metrics:\\n=================================')\n",
        "  print('\\nTest loss: {:.4f}'.format(score_regression[0]))\n",
        "  print('\\nTest MCRMSE score: {:.4f}'.format(score_regression[1]),'\\n')\n",
        "  return score_regression"
      ],
      "metadata": {
        "id": "sVxTurgBNXh7"
      },
      "execution_count": 241,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict Scores for 6 Metrics in Test Set"
      ],
      "metadata": {
        "id": "NW4pawEWleeb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_test_labels(model):\n",
        "  predictions = model.predict([test_encodings.input_ids, test_encodings.attention_mask])    # -1 in reshape function is used when you don't know or want to explicitly tell the dimension of that axis.\n",
        "  df_pred = pd.DataFrame(predictions, columns=['pred_'+ col for col in label_cols])\n",
        "  return df_pred"
      ],
      "metadata": {
        "id": "djJZFfnwHh54"
      },
      "execution_count": 242,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# regression_with_bert = regression_model_with_bert(num_classes = 9,                          # [1, 1.5, 2, 2.5....4.5, 5]: 9 classes\n",
        "#                                                     num_train_layers = 0,\n",
        "#                                                     num_hidden_layer = 1,\n",
        "#                                                     num_hidden_units = 256,\n",
        "#                                                     dropout = .3,\n",
        "#                                                     learning_rate = .00005)\n",
        "#                                                     # max_length = MAX_LENGTH)\n",
        "# # print(f'Parameter Values:\\n======================\\nnum_hidden_layer = {num_hidden_layer}\\nnum_hidden_units = {num_hidden_units}\\ndropout = {dropout}\\nlearning_rate = {learning_rate}\\nbatch_size = {batch_size}\\n')\n",
        "# # model summary and plot model structure\n",
        "# # display(regression_with_bert.summary())\n",
        "# # display(keras.utils.plot_model(regression_with_bert, show_shapes=False, show_dtype=False, show_layer_names=True, dpi=90))\n",
        "\n",
        "# # train model\n",
        "# # train_regression(regression_with_bert, 8, 1)\n",
        "# # print(\"\\nTensorBoard: Evolution of Loss and MCRMSE:\\n=============================================\")\n",
        "# # %tensorboard --logdir logs/fit\n",
        "\n",
        "# # Evaluate test set\n",
        "# # evaluate_test_labels(regression_with_bert)\n",
        "\n",
        "# # Predict test set\n",
        "# df_pred = predict_test_labels(regression_with_bert)\n",
        "# # df_pred_scaled = scaled_pred(df_pred)\n",
        "\n",
        "# # # Create a final table with y_true, y_pred_raw, and y_pred_scaled\n",
        "# # generate_final_table(df_pred)"
      ],
      "metadata": {
        "id": "Y0clkhTMho3U"
      },
      "execution_count": 243,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Output Table:\n",
        "- True Scores of Test Set\n",
        "- Raw Predicted Scores of Test Set \n",
        "- Scaled Predicted Scores of Test Set "
      ],
      "metadata": {
        "id": "ygp2LO33o-VE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scaled_pred(df):\n",
        "  pred_scaled = []\n",
        "  for col in df:\n",
        "    df[col + '_scaled'] = df[col].apply(lambda val: round(val/0.5) * 0.5)\n",
        "    pred_scaled.append(df[col + '_scaled'])\n",
        "  return pd.DataFrame(pred_scaled).T\n",
        "\n",
        "# df_pred_scaled = scaled_pred(df_pred)"
      ],
      "metadata": {
        "id": "kFENH_N5ozGI"
      },
      "execution_count": 244,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_final_table(df_pred):\n",
        "  print('\\nFinal Table: y_true vs. y_pred_raw vs. y_pred_scaled\\n======================================================')\n",
        "  df_final = pd.concat([df_test[['full_text']].reset_index(drop=True), df_test[label_cols].reset_index(drop=True), df_pred], axis=1)\n",
        "  display(df_final)\n",
        "# generate_final_table(df_pred)"
      ],
      "metadata": {
        "id": "xq3L18WTIWIC"
      },
      "execution_count": 245,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(round(2.967866/0.5) * 0.5)\n",
        "# pd.cut(df_pred['pred_cohesion'], bins=np.arange(1, 6, 0.5).tolist(), labels= np.arange(1, 5.5, 0.5).tolist())"
      ],
      "metadata": {
        "id": "AasZCMCsyLH-"
      },
      "execution_count": 246,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Experiment** - Regression with BERT:\n",
        "1) Unfreeze 0, 6 or all 12 layers with the following parameter values over 10 epochs:\n",
        "- num_hidden_layer = 1,\n",
        "- num_hidden_units = 256,\n",
        "- dropout = 0.3,\n",
        "- learning_rate = 0.00005,\n",
        "- batch_size = 8\n"
      ],
      "metadata": {
        "id": "9X9RmKEe6bh2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_regression_experiment(num_train_layers=np.arange(0,13,6),\n",
        "                          csv_filename='perf_summary_regression_w_BERT_1.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "c2mJZOrelrJx",
        "outputId": "fded3c68-f67b-4f6a-9347-a775e5eab016"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "******************************************************\n",
            "Regression with BERT: Number of Unfrozen Layers = 0\n",
            "******************************************************\n",
            "\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " attention_mask_layer (InputLay  [(None, 512)]       0           []                               \n",
            " er)                                                                                              \n",
            "                                                                                                  \n",
            " input_ids_layer (InputLayer)   [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  108310272   ['attention_mask_layer[0][0]',   \n",
            "                                thPoolingAndCrossAt               'input_ids_layer[0][0]']        \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  (None, 768)         0           ['tf_bert_model[0][0]']          \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " hidden_layer_1 (Dense)         (None, 256)          196864      ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dropout_layer_1 (Dropout)      (None, 256)          0           ['hidden_layer_1[0][0]']         \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 6)            1542        ['dropout_layer_1[0][0]']        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 108,508,678\n",
            "Trainable params: 198,406\n",
            "Non-trainable params: 108,310,272\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Regression with BERT.....\n",
            "=====================================\n",
            "Epoch 1/10\n",
            "391/391 [==============================] - 182s 434ms/step - loss: 1.0587 - MCRMSE: 1.0587 - val_loss: 0.5526 - val_MCRMSE: 0.5525\n",
            "Epoch 2/10\n",
            "391/391 [==============================] - 162s 414ms/step - loss: 0.7060 - MCRMSE: 0.7060 - val_loss: 0.5114 - val_MCRMSE: 0.5112\n",
            "Epoch 3/10\n",
            "391/391 [==============================] - 162s 413ms/step - loss: 0.6627 - MCRMSE: 0.6627 - val_loss: 0.4904 - val_MCRMSE: 0.4903\n",
            "Epoch 4/10\n",
            "313/391 [=======================>......] - ETA: 27s - loss: 0.6378 - MCRMSE: 0.6378"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Unfreeze 0, 2, 4, 6, 8, 10, or all 12 layers with randomly chosen values of hyper parameters over 10 epochs"
      ],
      "metadata": {
        "id": "fHQsrIzD60sO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_regression_experiment(num_train_layers=np.arange(2,13,2),\n",
        "                          num_hidden_layer=random.choice([1,2]),\n",
        "                          num_hidden_units=random.choice([64,128,256]),\n",
        "                          dropout=random.choice([0.1, 0.3, 0.4]),\n",
        "                          learning_rate=random.choice([0.00005, 0.00001, 0.000001]),\n",
        "                          batch_size=random.choice([8,16]),\n",
        "                          csv_filename='perf_summary_regression_w_BERT_2.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6Z3V2v-vCsA_",
        "outputId": "f764589e-ae9e-4711-8578-13283e468c1d"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "******************************************************\n",
            "Regression with BERT: Number of Unfrozen Layers = 2\n",
            "******************************************************\n",
            "\n",
            "Training Regression with BERT.....\n",
            "=====================================\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "391/391 [==============================] - 228s 538ms/step - loss: 0.8482 - MCRMSE: 0.8482 - val_loss: 0.4708 - val_MCRMSE: 0.4709\n",
            "Epoch 2/10\n",
            "391/391 [==============================] - 200s 511ms/step - loss: 0.7071 - MCRMSE: 0.7071 - val_loss: 0.4711 - val_MCRMSE: 0.4710\n",
            "Epoch 3/10\n",
            "391/391 [==============================] - 195s 500ms/step - loss: 0.6632 - MCRMSE: 0.6632 - val_loss: 0.4849 - val_MCRMSE: 0.4848\n",
            "Epoch 4/10\n",
            "391/391 [==============================] - 202s 516ms/step - loss: 0.6432 - MCRMSE: 0.6432 - val_loss: 0.4362 - val_MCRMSE: 0.4362\n",
            "Epoch 5/10\n",
            "391/391 [==============================] - 199s 509ms/step - loss: 0.6319 - MCRMSE: 0.6319 - val_loss: 0.4371 - val_MCRMSE: 0.4371\n",
            "Epoch 6/10\n",
            "391/391 [==============================] - 199s 509ms/step - loss: 0.6315 - MCRMSE: 0.6315 - val_loss: 0.4431 - val_MCRMSE: 0.4432\n",
            "Epoch 7/10\n",
            "391/391 [==============================] - 199s 509ms/step - loss: 0.6308 - MCRMSE: 0.6308 - val_loss: 0.4496 - val_MCRMSE: 0.4496\n",
            "Epoch 8/10\n",
            "391/391 [==============================] - 199s 508ms/step - loss: 0.6286 - MCRMSE: 0.6286 - val_loss: 0.4380 - val_MCRMSE: 0.4381\n",
            "Epoch 9/10\n",
            "391/391 [==============================] - 199s 510ms/step - loss: 0.6161 - MCRMSE: 0.6161 - val_loss: 0.4503 - val_MCRMSE: 0.4503\n",
            "Epoch 10/10\n",
            "391/391 [==============================] - 199s 509ms/step - loss: 0.6202 - MCRMSE: 0.6202 - val_loss: 0.4504 - val_MCRMSE: 0.4505\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                   0         1         2         3         4         5         6         7         8         9\n",
              "loss        0.848189  0.707123  0.663206  0.643167  0.631945  0.631540  0.630760  0.628583  0.616105  0.620216\n",
              "MCRMSE      0.848189  0.707123  0.663206  0.643167  0.631945  0.631540  0.630760  0.628583  0.616105  0.620216\n",
              "val_loss    0.470845  0.471068  0.484944  0.436191  0.437056  0.443138  0.449568  0.437965  0.450281  0.450427\n",
              "val_MCRMSE  0.470934  0.471011  0.484843  0.436229  0.437144  0.443161  0.449605  0.438090  0.450287  0.450453"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1fe8246c-7933-4f31-8bc7-963d5f815e36\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>loss</th>\n",
              "      <td>0.848189</td>\n",
              "      <td>0.707123</td>\n",
              "      <td>0.663206</td>\n",
              "      <td>0.643167</td>\n",
              "      <td>0.631945</td>\n",
              "      <td>0.631540</td>\n",
              "      <td>0.630760</td>\n",
              "      <td>0.628583</td>\n",
              "      <td>0.616105</td>\n",
              "      <td>0.620216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MCRMSE</th>\n",
              "      <td>0.848189</td>\n",
              "      <td>0.707123</td>\n",
              "      <td>0.663206</td>\n",
              "      <td>0.643167</td>\n",
              "      <td>0.631945</td>\n",
              "      <td>0.631540</td>\n",
              "      <td>0.630760</td>\n",
              "      <td>0.628583</td>\n",
              "      <td>0.616105</td>\n",
              "      <td>0.620216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val_loss</th>\n",
              "      <td>0.470845</td>\n",
              "      <td>0.471068</td>\n",
              "      <td>0.484944</td>\n",
              "      <td>0.436191</td>\n",
              "      <td>0.437056</td>\n",
              "      <td>0.443138</td>\n",
              "      <td>0.449568</td>\n",
              "      <td>0.437965</td>\n",
              "      <td>0.450281</td>\n",
              "      <td>0.450427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val_MCRMSE</th>\n",
              "      <td>0.470934</td>\n",
              "      <td>0.471011</td>\n",
              "      <td>0.484843</td>\n",
              "      <td>0.436229</td>\n",
              "      <td>0.437144</td>\n",
              "      <td>0.443161</td>\n",
              "      <td>0.449605</td>\n",
              "      <td>0.438090</td>\n",
              "      <td>0.450287</td>\n",
              "      <td>0.450453</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1fe8246c-7933-4f31-8bc7-963d5f815e36')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1fe8246c-7933-4f31-8bc7-963d5f815e36 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1fe8246c-7933-4f31-8bc7-963d5f815e36');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Plotting loss and MCRMSE...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+8AAAF5CAYAAADu2htSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACMXUlEQVR4nOzdd3wT9f8H8Ncl3St0L7qorFJkly0gICAgIIIsQZZ7AG5/IuDii4rgQgRZCsgSBFSWCMi0bCh7t5QOSkv3TO73xzVpQ9Od9JL29Xw88mhz98ndO6Hkfe+7z30+giiKIoiIiIiIiIjIbCnkDoCIiIiIiIiIysbinYiIiIiIiMjMsXgnIiIiIiIiMnMs3omIiIiIiIjMHIt3IiIiIiIiIjPH4p2IiIiIiIjIzLF4JyIiIiIiIjJzLN6JiIiIiIiIzJyV3AGYC41Ggzt37sDZ2RmCIMgdDhEREURRRHp6Ovz8/KBQ8Hy7MTDfExGROalMrmfxXujOnTsICAiQOwwiIqISYmJiUL9+fbnDqBWY74mIyBxVJNezeC/k7OwMQPrQXFxcZI6GiIgISEtLQ0BAgC5HUfUx3xMRkTmpTK5n8V5I23XOxcWFyZyIiMwKu3cbD/M9ERGZo4rket5AR0RERERERGTmWLwTERERERERmTkW70RERERERERmjsU7ERERERERkZnjgHVEZLFEUYRarUZBQYHcoRBVipWVFZRKJQeiIyLZqdVq5Ofnyx0GUa1kbW0NpVJptO2xeCciiyOKIu7fv4+7d+9CrVbLHQ5RlSiVSnh5eUGlUrGIJ6IaJ4oi4uPjcf/+fblDIarV6tWrBx8fH6PkehbvRqbWiIi8kYzE9Bx4OdshIsQNSgUPyoiMSXuwoZ3qycrKisUPWQxRFFFQUIC0tDTExcUhOzsbvr6+codFlcR8T5ZOm0u9vLzg4ODAPEpkZKIoIisrC4mJiQBglFzP4t2ItkfFYdbW84hLzdEt81XZYcbAMPQN54EZkTGo1WqkpqbC09MTHh4ecodDVGXOzs6wtbVFUlISvLy8jNqtjkyL+Z4snVqt1hXu7u7ucodDVGvZ29sDABITE42S6zlgnZFsj4rDiytP6CVyAIhPzcGLK09ge1ScTJER1S75+fkQRRGOjo5yh0JUbY6OjhBFkfebWhDme6oNtN85Dg4OMkdCVPtp/58ZI9ezeDcCtUbErK3nIRpYp102a+t5qDWGWhBRVbB7H9UG/Du2LMz3VNvwO4jI9Iz5/4zFuxFE3kgucQa+OBFAXGoOIm8k11xQREREZFTM90REJCcW70aQmF56Iq9KOyIiIjI/zPdERCQnFu9G4OVsZ9R2RESm9OyzzyI4ONho29u7dy8EQcDevXuNtk0ic8R8T0SA8fMoUUWxeDeCiBA3+KrsUNrdDAKkUWgjQtxqMiwisjCCIFTowSKZSB7M90TmzVLzqPYkuCAIWLlypcE2nTt3hiAICA8PL7FOrVZj2bJl6N69O9zc3GBra4vg4GCMHz8ex44d07Vbvny53udgZWUFf39/PPvss4iNjS2x3e7du0MQBDRs2NBgTLt27dJta8OGDXrrzp49i6eeegpBQUGws7ODv78/evfujW+//VavXXBwcKn/Tn379i33s6trOFWcESgVAmYMDMOLK09AAEoMZCMCmDEwjPO/ElGZfvnlF73nP//8M3bt2lViedOmTau1n8WLF0Oj0VRrG0R1UXn5HmC+J5KTpedROzs7rF69GmPGjNFbfvPmTRw6dAh2diV79WRnZ+PJJ5/E9u3b8cgjj+D999+Hm5sbbt68iXXr1mHFihWIjo5G/fr1da/56KOPEBISgpycHBw5cgTLly/HgQMHEBUVVWIfdnZ2uHr1KiIjIxEREaG3btWqVbCzs0NOjv6tQocOHUKPHj0QGBiIyZMnw8fHBzExMThy5Ai+/vprvPrqq3rtW7ZsiTfeeKPEe/Pz86vYB1eHsHg3kr7hvvhhTOsS874CwEOeTpz3lcgCqDUiIm8kIzE9B17O0tWzmjwIfzBZHzlyBLt27Sqx/EFZWVmVmu7H2tq6SvERUdn5/ounHma+pzqNebR6Hn/8cWzZsgVJSUnw8PDQLV+9ejW8vb3RsGFDpKSk6L3mrbfewvbt2zFv3jxMmTJFb92MGTMwb968Evvp168f2rZtCwCYNGkSPDw8MGfOHGzZsgXDhw/XaxsaGoqCggL8+uuvesV7Tk4ONm3ahP79++O3337Te82nn34KlUqFo0ePol69enrrEhMTS8Tj7+9f7r8RSdht3oj6hvviwDuP4tfJHfD1iJZYMLo1rBTA1bsZOB1zX+7wiKgM26Pi0GXOPxi5+AheX3MKIxcfQZc5/5jdnM3du3dHeHg4jh8/jkceeQQODg54//33AQCbN29G//794efnB1tbW4SGhuLjjz+GWq3W28aD9+rdvHkTgiDgyy+/xKJFixAaGgpbW1u0a9cOR48erXKs69evR5s2bWBvbw8PDw+MGTOmRLe8+Ph4jB8/HvXr14etrS18fX0xaNAg3Lx5U9fm2LFj6NOnDzw8PGBvb4+QkBBMmDChynERVZdevn+6JYLdpYP+hPRcmSMjkg/zaPXz6KBBg2Bra4v169frLV+9ejWGDx8OpVKpt/z27dv48ccf0bt37xKFOwAolUq8+eabelfdDenatSsA4Nq1awbXjxw5EmvXrtXrbbB161ZkZWWVKPa122nWrFmJwh0AvLy8yoyFysYr70amVAjoGOque/73eX9sPBmLJQdu4JuRrWSMjIhKsz0qDi+uPFGiC2x8ag5eXHkCP4xpbVZX0+7du4d+/fphxIgRGDNmDLy9vQFI97I5OTlh2rRpcHJywj///IMPP/wQaWlp+OKLL8rd7urVq5Geno7nn38egiDg888/x5NPPonr169X+irD8uXLMX78eLRr1w6zZ89GQkICvv76axw8eBAnT57UJfShQ4fi3LlzePXVVxEcHIzExETs2rUL0dHRuuePPfYYPD098e6776JevXq4efMmNm7cWOnPjciYiud7DURMXXsayw/dxKSuIbC1UpbzaqLahXlUUt086uDggEGDBuHXX3/Fiy++CAA4ffo0zp07h59++glnzpzRa79t2zYUFBTgmWeeqcKnUER7wtzV1dXg+lGjRmHmzJnYu3cvHn30UQDSe+3Zs6fBYjwoKAiHDx9GVFSUwXv0H5Sfn4+kpKQSyx0dHWFvb1+Jd1L7sXg3sQldQrDxZCz+PBuHd/s1gV89/gESmYIoisjOV5ff8AFqjYgZW84ZvHdVhDQA1cwt59H5IY9Kdf2zt1ZCEEzTVTA+Ph4LFy7E888/r7d89erVeknuhRdewAsvvIAFCxbgk08+ga2tbZnbjY6OxpUrV3TJu3Hjxhg0aBB27NiBAQMGVDi+/Px8vPPOOwgPD8e///6ru3+uS5cuGDBgAObNm4dZs2bh/v37OHToEL744gu8+eabute/9957ut8PHTqElJQU7Ny5U9fFDwA++eSTCsdDZGr9m/vhf9suIiEtF3+cjsPQNmVf5SIyV1XJpabKo4Dpcqk559FRo0Zh4MCBiImJQUBAAFatWoUGDRqgQ4cOJdpeuHABANC8efMKbVsrNTUVSUlJyMnJwX///YdZs2bB1ta21BgbNmyItm3bYvXq1Xj00Udx//59/PXXX1i8eLHB9m+++Sb69euHli1bIiIiAl27dkXPnj3Ro0cPgycxdu7cCU9PzxLLZ8+ejXfffbdS7622Y/FuYuH+KnRs4I7D1+9hxaGbeO/x6g2QQUSGZeerEfbhDqNvVwQQn5aD5jN3Vup15z/qAwcb03zF2traYvz48SWWFz/gSE9PR25uLrp27Yoff/wRFy9eRIsWLcrc7tNPP6131l3bje769euViu/YsWNITEzEzJkz9Qa+6d+/P5o0aYI///wTs2bNgr29PWxsbLB3715MnDjR4Bl/7RX6P/74Ay1atOD9+mSWbKwUGNcpGJ9vv4SfDtzAk639TXbyjsiUTJFLq5pHAdPlUnPOo4899hjc3NywZs0avPnmm1izZg3Gjh1rsG1aWhoAwNnZucLbB4BevXrpPQ8ODsbKlSvL7F4/atQofPzxx1iwYAE2bNgApVKJIUOG4Pjx4yXa9u7dG4cPH8bs2bOxY8cOHD58GJ9//jk8PT3x008/4YknntBr3759e4Mn5Usb5b4u4z3vNWBS1xAAwOrIaGTkFsgcDRFZOn9/f9jY2JRYfu7cOQwZMgQqlQouLi7w9PTUDQCTmppa7nYDAwP1nmsPQB4cHKc8t27dAiBdcXhQkyZNdOttbW0xZ84cbNu2Dd7e3njkkUfw+eefIz4+Xte+W7duGDp0KGbNmgUPDw8MGjQIy5YtQ24u7y0m8zIqIhD21kpciEvD4Wv35A6HiMpgznnU2toaw4YNw+rVq/Hvv/8iJiYGo0aNMtjWxcUFgHSioTK+//577Nq1Cxs2bMDjjz+OpKSkcnsVjBgxAqmpqdi2bRtWrVqFAQMGlHnSoF27dti4cSNSUlIQGRmJ9957D+np6Xjqqadw/vx5vbYeHh7o1atXiUdQUFCl3lddwCvvNaBHYy808HTE9buZWH8sBuM7h8gdElGtY2+txPmP+lT6dZE3kvHssvIHk1k+vl2l5m62tzbdPa+G7v+6f/8+unXrBhcXF3z00UcIDQ2FnZ0dTpw4gXfeeadCU9o8OBCOliga6gxpHFOmTMHAgQPx+++/Y8eOHZg+fTpmz56Nf/75B61atdLNHXvkyBFs3boVO3bswIQJEzB37lwcOXIETk5OJouNqDLqOdhgWNv6+PnwLfx04AY6PeRR/ouIzExVcqmp8qg2HlMw9zw6atQoLFy4EDNnzkSLFi0QFhZmsF2TJk0ASHOqt2zZssLbj4iI0N2KNnjwYHTp0gWjRo3CpUuXSs2rvr6+6N69O+bOnYuDBw+WGGG+NDY2NmjXrh3atWuHRo0aYfz48Vi/fj1mzJhR4XipCK+81wCFQsDELlLBvvTgDag1pjsQJqqrBEGAg41VpR9dG3rCV2WH0jq4CgB8VXbo2tCzUtut6S6ze/fuxb1797B8+XK8/vrrGDBgAHr16lXq4DOmpD1TfunSpRLrLl26VOJMemhoKN544w3s3LkTUVFRyMvLw9y5c/XadOjQAZ9++imOHTuGVatW4dy5c1izZo3p3gRRFYzvHAJBAP65mIiriRlyh0NUaVXJpabKozWdS80pj3bp0gWBgYHYu3dvqVfdAWnKN6VSiZUrV1Z5X0qlErNnz8adO3fw3Xffldl21KhR2L9/P1xcXPD4449Xel/aEwZxceY1A4ElYfFeQ55sVR+uDtaISc7GrvPx5b+AiGqEUiFgxkDpjPaDhwja5zMGhtXoPLVVoT3bX/zsfl5eHhYsWFDjsbRt2xZeXl5YuHChXvf2bdu24cKFC+jfvz8AaV7dnBz9ebJDQ0Ph7Oyse11KSkqJKxbaqwvsOk/mJsTDEb2aSqNWLz14Q+ZoiGoG86jxCYKAb775BjNmzChzJPmAgABMnjwZO3fuxLfffltivUajwdy5c3H79u0y99e9e3dERERg/vz5JfJycU899RRmzJiBBQsWGLztQGvPnj0Gexv89ddfAAzfVkcVw27zNcTeRokxHYLw7T9X8dP+G2Y1XQZRXdc33Bc/jGmNWVvPIy61KGn5qOwwY2CYRfx/7dSpE1xdXTFu3Di89tprEAQBv/zyi0m7vJfG2toac+bMwfjx49GtWzeMHDlSN1VccHAwpk6dCgC4fPkyevbsieHDhyMsLAxWVlbYtGkTEhISMGLECADAihUrsGDBAgwZMgShoaFIT0/H4sWLq3zWn8jUJnUJwa7zCfjt+G28+VhjuDmWfoBLVFswjxrfoEGDMGjQoHLbzZ07F9euXcNrr72GjRs3YsCAAXB1dUV0dDTWr1+Pixcv6nJqWd566y0MGzYMy5cvxwsvvGCwjUqlwsyZM8vd1quvvoqsrCwMGTIETZo0QV5eHg4dOoS1a9ciODi4xGCBsbGxBnsPODk5YfDgweXury5h8V6DnukYhB/3XcexWyk4GZ2CVoE13w2HiAzrG+6L3mE+iLyRjMT0HHg52yEixM3srxRoubu7448//sAbb7yBDz74AK6urhgzZgx69uyJPn0qPxZAdT377LNwcHDA//73P7zzzjtwdHTEkCFDMGfOHN0I8gEBARg5ciR2796NX375BVZWVmjSpAnWrVuHoUOHApAGrIuMjMSaNWuQkJAAlUqFiIgIrFq1CiEhHD+EzE9EiBua+6twNjYVq47cwqs9OVoy1Q3Mo/JwcHDAtm3bsHz5cqxYsQIff/wxsrKy4Ofnh0cffRSrVq2Cv79/udt58sknERoaii+//BKTJ08u9f79ivjyyy+xfv16/PXXX1i0aBHy8vIQGBiIl156CR988IHuOEDr1KlTBnsYBAUFsXh/gCDKdTrJzKSlpUGlUiE1NVU3cqMpvLn+NDYcv40BD/viu1GtTbYfotoqJycHN27cQEhIiN40ZESWqLy/55rKTXVJTXymm0/F4vU1p+DhZIuD7/aArZXpBrAkqgrmUqKaY8xcz3vea5h24LptUfG4nZIlczRERERkbI8394WPix2SMnKx5dQducMhIqJagsV7DWvq64IuD3lArRGx4tBNucMhIiIiI7NWKvBs52AAwJIDN2S7Z5aIiGoXFu8ymNhVuvq+JjIG6Tn5MkdDRERExjayXSAcbJS4GJ+Og1fvyR0OERHVAizeZdCtoSce8nJCem4B1h0re+oGIiIisjwqB2sMbxsAAPjpwHWZoyEiotqAxbsMFApBd+/7soM3UKDWyBwRERERGdv4zsEQBGDvpbu4kpAudzhERGThWLzLZEgrf7g52uB2SjZ2nk+QOxwiIiIysiB3RzwW5g0AWHrwhszREBGRpWPxLhM7ayXGdAgCAPy0n93piIiIaqNJXRsAAH47EYt7GbkyR0NERJaMxbuMnukQBBulAiei7+P4rRS5wyEiIiIjaxvkihb1Vcgr0GDlkWi5wyEiIgvG4l1Gns62GNzKDwCwhIPZEBER1TqCIGBi4dX3X47cRE6+WuaIiIjIUrF4l9nELlJC3x4Vj5jkLJmjISIiImPrF+4DP5UdkjLysOXUHbnDISIiC8XiXWaNfZzRtaEHNCKw7OBNucMhIiIiI7NWKvBs52AA0rRxoijKGxAREVkkFu9mQDuYzdqj0UjLyZc5GiKqTW7evAlBELB8+XLdspkzZ0IQhAq9XhAEzJw506gxde/eHd27dzfqNiti7969EAQBe/furfF9Ez3dLhCONkpcTsjA/itJcodDRBXEPErmxGyL9++//x7BwcGws7ND+/btERkZWWb7+fPno3HjxrC3t0dAQACmTp2KnJycGoq2eh5p6IGGXk7IzFNjbWSM3OEQkUyeeOIJODg4ID299PmgR48eDRsbG9y7d68GI6u88+fPY+bMmbh586bcoZCZqyv5XmVvjeHtAgAAPx3gtHFEpsA8alrak+CCIGDlypUG23Tu3BmCICA8PLzEOrVajWXLlqF79+5wc3ODra0tgoODMX78eBw7dkzXbvny5br9CIIAKysr+Pv749lnn0VsbGyJ7Xbv3h2CIKBhw4YGY9q1a5duWxs2bNBbd/bsWTz11FMICgqCnZ0d/P390bt3b3z77bd67YKDg/ViKv7o27dvuZ+dsZhl8b527VpMmzYNM2bMwIkTJ9CiRQv06dMHiYmJBtuvXr0a7777LmbMmIELFy5gyZIlWLt2Ld5///0ajrxqBEHApK4hAIBlB2+gQK2ROSIiksPo0aORnZ2NTZs2GVyflZWFzZs3o2/fvnB3d6/yfj744ANkZ2dX+fUVcf78ecyaNcvgQcfOnTuxc+dOk+6fLENdy/fjO4VAIQD/Xr6LS/GlFxdEVDXMozXDzs4Oq1evLrH85s2bOHToEOzs7Eqsy87OxoABAzBhwgSIooj3338fP/zwA8aOHYvDhw8jIiICt2/f1nvNRx99hF9++QULFy5Ev379sHLlSnTr1s3gCVs7OztcvXrV4AngVatWGYzp0KFDaNu2LU6fPo3Jkyfju+++w6RJk6BQKPD111+XaN+yZUv88ssvJR5vv/12mZ+XMVnV2J4q4auvvsLkyZMxfvx4AMDChQvx559/YunSpXj33XdLtD906BA6d+6MUaNGAZDOjIwcORL//fdfjcZdHYNa+uPz7ZdwJzUH26LiMbCFn9whEREAiCKgzgOsbE2+qyeeeALOzs5YvXo1xo4dW2L95s2bkZmZidGjR1drP1ZWVrCyku/r38bGRrZ9k3mpa/k+0N0BfZr5YFtUPJYeuIE5Tz0sd0hEpsc8anRy59HHH38cW7ZsQVJSEjw8PHTLV69eDW9vbzRs2BApKfrTYL/11lvYvn075s2bhylTpuitmzFjBubNm1diP/369UPbtm0BAJMmTYKHhwfmzJmDLVu2YPjw4XptQ0NDUVBQgF9//RURERG65Tk5Odi0aRP69++P3377Te81n376KVQqFY4ePYp69erprTN0Etnf3x9jxowp/YOpAWZ35T0vLw/Hjx9Hr169dMsUCgV69eqFw4cPG3xNp06dcPz4cd2ZluvXr+Ovv/7C448/Xup+cnNzkZaWpveQk521Es90DAIA/LSfg9kQyU4Ugat/A4t7APPCgdTb5b+mmuzt7fHkk09i9+7dBpPG6tWr4ezsjCeeeALJycl488030bx5czg5OcHFxQX9+vXD6dOny92PoXv1cnNzMXXqVHh6eur28eAZcAC4desWXnrpJV23ZXd3dwwbNkzvysDy5csxbNgwAECPHj103cq095obulcvMTEREydOhLe3N+zs7NCiRQusWLFCr432vsMvv/wSixYtQmhoKGxtbdGuXTscPXq03PddmvXr16NNmzawt7eHh4cHxowZU6JbXnx8PMaPH4/69evD1tYWvr6+GDRokN77PnbsGPr06QMPDw/Y29sjJCQEEyZMqHJctV1dzffannabTsXibnqurLEQmRTzaK3No4MGDYKtrS3Wr1+vt3z16tUYPnw4lEql3vLbt2/jxx9/RO/evUsU7gCgVCrx5ptvon79+mXut2vXrgCAa9euGVw/cuRIrF27FhpNUS/mrVu3Iisrq0Sxr91Os2bNShTuAODl5VVmLHIxuyvvSUlJUKvV8Pb21lvu7e2NixcvGnzNqFGjkJSUhC5dukAURRQUFOCFF14osxvd7NmzMWvWLKPGXl1jOgRhwd5rOH07FcdvpaBtsJvcIRHVPaIIXNsN/PMJcOckpHOcGiAzCVCVnVSMYfTo0VixYgXWrVuHV155Rbc8OTkZO3bswMiRI2Fvb49z587h999/x7BhwxASEoKEhAT8+OOP6NatG86fPw8/v8r13pk0aRJWrlyJUaNGoVOnTvjnn3/Qv3//Eu2OHj2KQ4cOYcSIEahfvz5u3ryJH374Ad27d8f58+fh4OCARx55BK+99hq++eYbvP/++2jatCkA6H4+KDs7G927d8fVq1fxyiuvICQkBOvXr8ezzz6L+/fv4/XXX9drv3r1aqSnp+P555+HIAj4/PPP8eSTT+L69euwtrau1Ptevnw5xo8fj3bt2mH27NlISEjA119/jYMHD+LkyZO6hD506FCcO3cOr776KoKDg5GYmIhdu3YhOjpa9/yxxx6Dp6cn3n33XdSrVw83b97Exo0bKxVPXVJX833rQFe0DKiHUzH3sfLILUzt3UjukIiMi3m01udRBwcHDBo0CL/++itefPFFAMDp06dx7tw5/PTTTzhz5oxe+23btqGgoADPPPNMhT7L0mhPcLi6uhpcP2rUKMycORN79+7Fo48+CkB6rz179jRYjAcFBeHw4cOIiooyeI/+g/Lz85GUVHLAUUdHR9jb21finVSDaGZiY2NFAOKhQ4f0lr/11ltiRESEwdfs2bNH9Pb2FhcvXiyeOXNG3LhxoxgQECB+9NFHpe4nJydHTE1N1T1iYmJEAGJqaqpR309lvbPhtBj0zh/i8z8fkzUOInOVnZ0tnj9/XszOzjbcIDej9Ededultc9JF8cIforiwqyjOcBHFma7ST+3j1qEytptltPdXUFAg+vr6ih07dtRbvnDhQhGAuGPHDlEUpe8wtVqt1+bGjRuira2t3nffjRs3RADismXLdMtmzJghFv/6P3XqlAhAfOmll/S2N2rUKBGAOGPGDN2yrKyS7/Xw4cMiAPHnn3/WLVu/fr0IQNyzZ0+J9t26dRO7deumez5//nwRgLhy5Urdsry8PLFjx46ik5OTmJaWpvde3N3dxeTkZF3bzZs3iwDErVu3lthXcXv27NGLKS8vT/Ty8hLDw8P1/p7++OMPEYD44YcfiqIoiikpKSIA8Ysvvih125s2bRIBiEePHi0zhgeV9/ecmppqFrnJFOpyvt96OlYMeucPsfVHO8XsvALZ4qC6yyS5tLw8GnuynO0aJ5cyj0pMmUfXr18v/vHHH6IgCGJ0dLQoitJ3d4MGDXTxNWvWTPe6qVOnigDEkydPlrl9rWXLlokAxL///lu8e/euGBMTI27YsEH09PQUbW1txZiYmBKfh3Z/bdu2FSdOnCiKopS/bWxsxBUrVujFrrVz505RqVSKSqVS7Nixo/j222+LO3bsEPPy8krEFBQUJAIw+Jg9e3aZ78eYud7srrx7eHhAqVQiISFBb3lCQgJ8fHwMvmb69Ol45plnMGnSJABA8+bNkZmZieeeew7/93//B4Wi5N0Btra2sLU1/b03lTWhSwjWHI3BjvPxuHUvE0HujnKHRGRZPivjTHnDx4DRxbp4ffEQkJ9luK2o1n+++mkgJ9VwW79WwHN7KxVmaZRKJUaMGIF58+bh5s2bCA4OlnZfeB9Zz549AUDv+0utVuP+/ftwcnJC48aNceLEiUrt86+//gIAvPbaa3rLp0yZUmJAmuJnlvPz85GWloaHHnoI9erVw4kTJ6p0Vv2vv/6Cj48PRo4cqVtmbW2N1157DSNHjsS+ffswYMAA3bqnn35a76y7thvd9evXK7XfY8eOITExETNnztQbyKZ///5o0qQJ/vzzT8yaNQv29vawsbHB3r17MXHiRINn/LVX6P/44w+0aNGi0j0A6qK6nO/7NvOBfz17xN7Pxu8nYzEiIlDukIj0GSOXPphHAWB+cyCrlFHejZRLmUclps6jjz32GNzc3LBmzRq8+eabWLNmjcFxBgDobldydnau1PsqflsVII1zsnLlyjK7148aNQoff/wxFixYgA0bNkCpVGLIkCE4fvx4iba9e/fG4cOHMXv2bOzYsQOHDx/G559/Dk9PT/z000944okn9Nq3b98en3zySYntlDbKvSmY3T3vNjY2aNOmDXbv3q1bptFosHv3bnTs2NHga7KyskokbO29FqKF3TveyNsZ3Rp5QhSBZQdvyh0OEclAO5CONuHfvn0b+/fvx4gRI3TfbRqNBvPmzUPDhg1ha2sLDw8PeHp64syZM0hNLeUkQylu3boFhUKB0NBQveWNGzcu0TY7OxsffvghAgIC9PZ7//79Su+3+P4bNmxY4ntc2z3w1q1bessDA/ULHe0ByIOD41Rkv4Dh99mkSRPdeltbW8yZMwfbtm2Dt7c3HnnkEXz++eeIj4/Xte/WrRuGDh2KWbNmwcPDA4MGDcKyZcuQm8t7mktTl/O9lVKB8Z2DAUjTxllS7ESWgHlUYso8am1tjWHDhmH16tX4999/ERMToxtM9EEuLi4AUOYUfoZ8//332LVrFzZs2IDHH38cSUlJ5Z6MHTFiBFJTU7Ft2zasWrUKAwYMKPOkQbt27bBx40akpKQgMjIS7733HtLT0/HUU0/h/Pnzem09PDzQq1evEo+goKBKva/qMLsr7wAwbdo0jBs3Dm3btkVERATmz5+PzMxM3Wi0Y8eOhb+/P2bPng0AGDhwIL766iu0atUK7du3x9WrVzF9+nQMHDiwxIAJlmBS1xDsu3wX647FYGrvRlDZ8woOUYW9f6f0dcID3wdvXZV+3vgX2DsbiDsttTF0tWDUWsCnlJGhBeOeB23Tpg2aNGmCX3/9Fe+//z5+/fVXiKKoNzruZ599hunTp2PChAn4+OOP4ebmBoVCgSlTpugN1GJsr776KpYtW4YpU6agY8eOUKlUEAQBI0aMMOl+iyvte92UBdCUKVMwcOBA/P7779ixYwemT5+O2bNn459//kGrVq10c8ceOXIEW7duxY4dOzBhwgTMnTsXR44cgZOTk8lis2R1Od8PbxeA+X9fwdXEDOy7fBfdG5vn4EhUR1U2l1YkjwLAlLNlbNd4uZR5tGzGyqOjRo3CwoULMXPmTLRo0QJhYWEG2zVp0gSANKd6y5YtK7z9iIgI3WjzgwcPRpcuXTBq1ChcunSp1Lzq6+uL7t27Y+7cuTh48GCJEeZLY2Njg3bt2qFdu3Zo1KgRxo8fj/Xr12PGjBkVjrcmmGXx/vTTT+Pu3bv48MMPER8fj5YtW2L79u26QW2io6P1zix98MEHEAQBH3zwAWJjY+Hp6YmBAwfi008/lestVEuXhzzQ2NsZlxLSsSYyGs93Cy3/RUQksanErSbato37AY366g+w8+DBh5V95bZdTaNHj8b06dNx5swZrF69Gg0bNkS7du106zds2IAePXpgyZIleq+7f/++3rQtFREUFASNRoNr167pXSW4dOlSibYbNmzAuHHjMHfuXN2ynJwc3L9/X6/dg6Pwlrf/M2fOQKPR6H23awctM9UZbe12L126pBvYRuvSpUsl9hsaGoo33ngDb7zxBq5cuYKWLVti7ty5WLlypa5Nhw4d0KFDB3z66adYvXo1Ro8ejTVr1ui6eZO+upzvXeys8XS7ACw5cANLDtxg8U7mpbK5tCJ5tLLbrSbmUdPn0S5duiAwMBB79+7FnDlzSm3Xr18/KJVKrFy5ssqD1imVSsyePRs9evTAd999Z3A6Ua1Ro0Zh0qRJqFevXpmzkZRGe8IgLi6uSrGaktl1m9d65ZVXcOvWLeTm5uK///5D+/btdev27t2L5cuX655bWVlhxowZuHr1KrKzsxEdHY3vv//e4LD/lkAQBEwsnEpm+aGbyFfXzFk4ojpNEICHegGT9wBjfgN8tVfZ5fma1F4d+PDDD3Hq1KkSc9IqlcoSZ8jXr19fYoqziujXrx8A4JtvvtFbPn/+/BJtDe3322+/hVqtf4Dm6CgdoD14MGLI448/jvj4eKxdu1a3rKCgAN9++y2cnJzQrVu3iryNSmvbti28vLywcOFCve7t27Ztw4ULF3SjBGdlZSEnJ0fvtaGhoXB2dta9LiUlpcTnor26wK7zZavL+f7ZTsFQCMD+K0m4GC/vFHZE1cY8WufyqCAI+OabbzBjxowyi/KAgABMnjwZO3fuxLfffltivUajwdy5cw1OrVdc9+7ddb20HszLxT311FOYMWMGFixYABsbm1Lb7dmzx2BvA+0YBoZue5CbWV55J2BQSz98vv0S4lJz8NfZOAxq6S93SER1g/bgI7Rn0RWEtFjA0bNGwwgJCUGnTp2wefNmAChx0DFgwAB89NFHGD9+PDp16oSzZ89i1apVaNCgQaX31bJlS4wcORILFixAamoqOnXqhN27d+Pq1asl2g4YMAC//PILVCoVwsLCcPjwYfz9999wd3cvsU2lUok5c+YgNTUVtra2ePTRRw1O1fLcc8/hxx9/xLPPPovjx48jODgYGzZswMGDBzF//vxKD3BTUdbW1pgzZw7Gjx+Pbt26YeTIkbqp4oKDgzF16lQAwOXLl9GzZ08MHz4cYWFhsLKywqZNm5CQkIARI0YAAFasWIEFCxZgyJAhCA0NRXp6OhYvXgwXF5cqnfWnuiHAzQH9wn3x59k4LNl/A18MayF3SETVxzxaZ/IoIM35PmjQoHLbzZ07F9euXcNrr72GjRs3YsCAAXB1dUV0dDTWr1+Pixcv6nJqWd566y0MGzYMy5cvxwsvvGCwjUqlwsyZM8vd1quvvoqsrCwMGTIETZo0QV5eHg4dOoS1a9ciODhYdwuXVmxsrF5vOy0nJycMHjy43P0ZA4t3M2VrpcTYjkH4atdlLDlwA0+08KtU9xkiqqbiBx/qPMCq5kerHj16NA4dOoSIiAg89NBDeuvef/99ZGZmYvXq1Vi7di1at26NP//8s8xuZGVZunQpPD09sWrVKvz+++949NFH8eeffyIgIECv3ddffw2lUolVq1YhJycHnTt3xt9//40+ffrotfPx8cHChQsxe/ZsTJw4EWq1Gnv27DF40GFvb4+9e/fi3XffxYoVK5CWlobGjRtj2bJlePbZZ6v0firq2WefhYODA/73v//hnXfegaOjI4YMGYI5c+boruYGBARg5MiR2L17N3755RdYWVmhSZMmWLduHYYOHQpAGrAuMjISa9asQUJCAlQqFSIiIrBq1SqEhISY9D2QZZvYNQR/no3D5lN38FbfxvBytiv/RUSWgHm0TuTRinJwcMC2bduwfPlyrFixAh9//DGysrLg5+eHRx99FKtWrYK/f/kXK5988kmEhobiyy+/xOTJk6s13smXX36J9evX46+//sKiRYuQl5eHwMBAvPTSS/jggw9K9Oo6deqUwR4GQUFBNVa8CyKHOAUgTWGgUqmQmpqqGxFRbvcyctHpf/8gt0CDdc93RESIm9whEckuJycHN27cQEhIiN70XkSWqLy/Z3PMTZbOHD/TJxccxIno+3j10YfwxmPm102Tah/mUqKaY8xcb7b3vBPg7mSLJ1tL8xj+tL9y8xcTERGRZZjUVeqmu/LILWTnlTJKNxER1Xks3s3cxC7BAIBdFxJwMylT3mCIiIjI6B4L80Z9V3ukZOVj48myB2wiIqK6i8W7mXvIyxk9GntCFIFlB2/IHQ4REREZmZVSgfGdpbERlhy4AY2GdzQSEVFJLN4tgLY73bpjt5GalS9zNERERGRsw9vWh7OtFa7fzcTey4lyh0NERGaIxbsF6BTqjiY+zsjOV2N1ZLTc4RAREZGROdtZY0SENCr1T/vZ046IiEpi8W4BBEHQXX1ffugG8go0MkdERERExjauUzCUCgGHrt3DuTupcodDRERmhsW7hRjYwheezrZISMvFX2fj5A6HSHac5ZJqA/4dU3H1XR3QL9wHgHTvO5Gp8TuIyPSM+f+MxbuFsLVS4tlOwQCAnw5c55ct1VlKpRIAkJ/P8R/I8mn/jrV/10TannZbT99BQlqOzNFQbWVlZQUAKCgokDkSotpP+/9M+/+uOli8W5BREYGws1YgKjYN/91IljscIllYW1vD1tYWqampPIlFFk0URaSmpsLW1hbW1tZyh0NmomVAPbQNckW+WsTPh2/KHQ7VUkqlEkqlEmlpaXKHQlTrpaWl6f7PVVf1y3+qMa6ONniqTX2sPBKNn/bfQIcG7nKHRCQLDw8PxMbG4vbt21CpVLC2toYgCHKHRVQhoigiPz8fqampyMjIgL+/v9whkZmZ1DUEx26lYNV/0Xi5x0NwsOHhGhmXIAjw8vJCXFwcbG1t4ejoyDxKZGSiKCIzMxNpaWnw9fU1yv8xZgMLM6FzCFYeicbuiwm4fjcDDTyd5A6JqMa5uLgAAJKSkhAbGytzNERVY2trC39/f93fM5FW7zAfBLjZIyY5G7+diMUzHYLkDolqIZVKhezsbCQlJeHu3btyh0NUKwmCgHr16kGlUhlleyzeLUwDTyf0auqFvy8kYtnBm/h4cLjcIRHJwsXFBS4uLsjPz4darZY7HKJKUSqV7CpPpVIqBEzoHIJZW89j6YEbGB0RCIWCV0XJuARBgK+vL7y8vDiODJGJWFtbG3VcGxbvFmhilwb4+0Ii1h+PwRuPNUI9Bxu5QyKSjbW1NYsgIqp1hrUNwFe7LuNGUib+uZiIXmHecodEtZSx7sUlItPjgHUWqEMDNzTzc0FOvgar/ouWOxwiIiIyMidbK4yKCAQgzTJDRETE4t0CCYKASV1DAAArDt1EXoFG5oiIiIjI2MZ1CoZSIeDI9WRExabKHQ4REcmMxbuF6t/cD94utkhMz8UfZ+7IHQ4REREZmV89e/Rv7gsAWHLghszREBGR3Fi8WygbKwXGdQoGAPy0/wbnuyYiIqqFtD3ttp6+g/jUHJmjISIiObF4t2CjIgJhb63E+bg0HL5+T+5wiIiIyMgerl8PEcFuKNCIWHH4ptzhEBGRjFi8W7B6DjYY1rY+AGDJfnanIyIiqo0mFl59X3XkFjJzC2SOhoiI5MLi3cKN7xwCQQB2X0zEtbsZcodDRERERtarqTeC3B2QllOA307cljscIiKSCYt3Cxfi4YheTaW5X5dyMBsiIqJaR6kQMKGzdPV96YEbUGs4zg0RUV3E4r0WmNRFSui/nbiN5Mw8maMhIiIiY3uqTX242Fnh5r0s7L6QIHc4REQkAxbvtUBEiBua+6uQk6/B6v9uyR0OERERGZmjrRVGtQ8CAPzEnnZERHUSi/daQBAE3VQyKw7fQm6BWuaIiIiIyNjGdQqClUJA5I1knLl9X+5wiIiohrF4ryUeb+4LHxc73E3PxZZTd+QOh4iIiIzMV2WPAQ/7AgCW8Oo7EVGdw+K9lrBWKvBs52AAUkIXRQ5mQ0REVNtM7NIAAPDnmTjcuZ8tczRERFSTWLzXIiPbBcLBRomL8ek4ePWe3OEQERGRkTWvr0L7EDcUaESsOHxT7nCIiKgGsXivRVQO1hjeNgAA8NOB6zJHQ0RERKYwqat09X31f9HIzC2QORoiIqopLN5rmfGdgyEIwN5Ld3ElIV3ucIiIiMjIejbxQrC7A9JzCrD+WIzc4RARUQ1h8V7LBLk74rEwbwDA0oMczIaIiKi2USgETOwizTKz9OBNqDUc54aIqC5g8V4LabvT/XYiFvcycmWOhoiIiIxtaJv6UNlbIzo5C7vOJ8gdDhER1QAW77VQ2yBXtKivQl6BBiuPRMsdDhERERmZg40VRrcPBAAs4Tg3RER1Aov3WkgQBEwsvPr+y5GbyMlXyxwRERERGdu4TsGwVgo4ejMFp2Luyx0OERGZGIv3WqpfuA/8VHZIysjDllN35A6HiIiIjMzbxQ4DH/YDACw5wHFuiIhqOxbvtZS1UoFnOwcDkKaNE0UOZkNERFTbTCgcuO6vs3GIvZ8tczRERGRKLN5rsafbBcLRRonLCRnYfyVJ7nCIiIjIyML9VejYwB1qjYgVh27KHQ4REZkQi/daTGVvjeHtAgAAP7E7HRERUa00qat09f3X/6KRkVsgczRERGQqLN5rufGdQqAQgH8v38Wl+HS5wyEiIiIj69HYCw08HJGeW4B1R2PkDoeIiEyExXstF+jugD7NfAAAS3n1nYiIqNZRKATdve9LD96AWsNxboiIaiMW73WAtjvdplOxuJueK3M0REREZGxDW9dHPQdr3E7Jxs5z8XKHQ0REJsDivQ5oHeiKlgH1kFegwcojt+QOh4iIiIzM3kaJMe2DAHCcGyKi2orFex0gCILu6vvKI7eQk6+WOSIiIiIytrEdg2CtFHD8VgpORKfIHQ4RERkZi/c6om8zH/jXs8e9zDz8fjJW7nCIiIjIyLxc7PBEC38AwBJefSciqnVYvNcRVkoFxncOBiB1pxNFDmZDRERU20wsHLhu29k4xCRnyRwNEREZE4v3OmR4uwA42VrhamIG9l2+K3c4REREZGRhfi7o/JA7NCKw4tBNucMhIiIjYvFeh7jYWePpdgEA2J2OiIiotprUpQEAYM3RGKTn5MscDRERGQuL9zpmfOdgKARg/5UkXIxPkzscIiIiMrJujTwR6umIjNwCrD0aI3c4RERkJCze65j6rg7o19wXALBkP6++ExER1TYKhYCJhVfflx28iQK1RuaIiIjIGFi810GTCgez2XzqDhLTc2SOhoiIiIztydb+cHWwRuz9bOw4lyB3OEREZAQs3uugVoGuaBPkijy1Bv/76wI2n4rF4Wv3oNZwBHoiIqLawM5aiWc6BAEA5v19ibmeiKgWsJI7AJJHm8B6OH4rBRtP3sHGk3cAAL4qO8wYGIa+4b4yR0dERETV5e9qDwC4mpiJ19ecAsBcT0RkyXjlvQ7aHhWHxQbud49PzcGLK09ge1ScDFERERGRsWyPisO7v50tsZy5nojIcrF4r2PUGhGztp6HoU5z2mWztp5ntzoiIiILxVxPRFQ7sXivYyJvJCMutfRB6kQAcak5iLyRXHNBERGR2VmxYgVycjioqSViriciqp3Munj//vvvERwcDDs7O7Rv3x6RkZGltu3evTsEQSjx6N+/fw1GbP4qOro8R6EnIqrbxo8fDz8/P7z66qs4ffq0yfbDXG98zPVERLWT2Rbva9euxbRp0zBjxgycOHECLVq0QJ8+fZCYmGiw/caNGxEXF6d7REVFQalUYtiwYTUcuXnzcrarUDsHa6WJIyEiInM2adIkFBQU4Pvvv0fr1q3RoUMHLFmyBJmZmUbbB3O9aVQ01+fkq00cCRERGZPZFu9fffUVJk+ejPHjxyMsLAwLFy6Eg4MDli5darC9m5sbfHx8dI9du3bBwcGBCf0BESFu8FXZQSin3fubzmLf5bs1EhMREZmfRYsWIS4uDosWLUK7du0QGRmJ5557Dn5+fnjhhRdw7Nixau+Dud40KprrP9gUhUX/XoOG974TEVkEsyze8/LycPz4cfTq1Uu3TKFQoFevXjh8+HCFtrFkyRKMGDECjo6OBtfn5uYiLS1N71EXKBUCZgwMA4ASSV373NvFFncz8jBuaSRmbjnHM/NERHWUo6MjJk2ahCNHjuDMmTN4+eWXYWVlhUWLFqF9+/Zo1aoVFi5cWKUcWhO5Hqib+b4iuf5hfxfka0R89tdFjPrpCGLvZ9dojEREVHlmWbwnJSVBrVbD29tbb7m3tzfi4+PLfX1kZCSioqIwadKkUtvMnj0bKpVK9wgICKh23Jaib7gvfhjTGj4q/W51Pio7LBzTGnvf7IFxHYMAAMsP3cSAbw8gKjZVjlCJiMhMhIeH45tvvsGdO3ewcuVKPPLIIzh9+jRefvll+Pn5YeLEiTh+/HiFt1cTuR6ou/m+vFy/+ZUumP1kc9hbK3HkejL6zv8Xv5+MhSjyKjwRkbmykjsAU1iyZAmaN2+OiIiIUtu89957mDZtmu55WlpanUnogJTUe4f5IPJGMhLTc+DlbIeIEDcoFdI5+VmDwvFoU2+8tf40riZmYPD3BzG1dyO80C1U14aIiOqe/Px8pKenIz09HQAgiiLy8/OxbNkyLF++HEOGDMFPP/2EevXqmTSOiuR6oG7n+/Jy/ciIQHRo4I6pa0/hVMx9TFl7Cn9fSMCng5tD5WAtc/RERPQgs7zy7uHhAaVSiYSEBL3lCQkJ8PHxKfO1mZmZWLNmDSZOnFhmO1tbW7i4uOg96hqlQkDHUHcMaumPjqHuJYrybo08sWPKI+gX7oMCjYgvdlzC0z8eRkxylkwRExGRXI4cOYKJEyfC19cXL730Es6cOYMnn3wSO3fuRFpaGlatWoXmzZtj06ZNeO2118rdXk3keoD5vrxcH+LhiA0vdMTUXo2gVAj440wc+sz/FweuJMkUMRERlcYsi3cbGxu0adMGu3fv1i3TaDTYvXs3OnbsWOZr169fj9zcXIwZM8bUYdYJro42WDC6Nb4c1gJOtlY4disFfef/i3XHYti1joiolktJScE333yD5s2bo3Pnzli2bBnc3Nwwa9YsREdHY8OGDejVqxdsbW0xcuRIHDt2DGFhYfjrr7/K3TZzvfmwUirweq+G+O3FTgjxcER8Wg7GLPkPs7Zy3BsiInNilsU7AEybNg2LFy/GihUrcOHCBbz44ovIzMzE+PHjAQBjx47Fe++9V+J1S5YsweDBg+Hu7l7TIddagiDgqTb1se31rmgX7IrMPDXe3nAGL6w8juTMPLnDIyIiExgzZgz8/f0xdepUXLhwAf369cOWLVtw48YNfPDBBwavjltZWaFdu3ZISUmp0D6Y681Ly4B6+PO1LhjdPhAAsOzgTQz89gDO3eG4N0RE5sBs73l/+umncffuXXz44YeIj49Hy5YtsX37dt3ANtHR0VAo9M89XLp0CQcOHMDOnTvlCLnWC3BzwJrnOuLHf69h3q7L2HEuASei/8XnTz2MHo295A6PiIiMaPXq1fDx8cGECRPw3HPPITAwsEKvGzJkCIKCgirUlrne/DjYWOHTIc3Rs6kX3t5wBlcKx71547HGmNy1Ace9ISKSkSCy7zMAaQAblUqF1NTUOnc/XFVExaZiytpTuJqYAQB4pkMQ3n+8KextlDJHRkRUe8iZm3777TcMGjQIVlZme56/SpjvK+5eRi7e3XgWu85L4xJEhLjhq+EtUN/VQebIiIhqj8rkJbPtNk/mLdxfhT9e7YLxnYMBAL8cuYX+3+7Hmdv3ZY2LiIiMY+jQobWucKfKcXeyxaJn2mDO0OZwsFEi8kYy+s3fj40nbnPcGyIiGbB4pyqzs1ZixsBm+GViBLxdbHH9biaeXHAI3+6+ggK1Ru7wiIioGk6cOIFp06bh6NGjpbaJjIzEtGnTcOrUqZoLjGqUIAh4ul0gtr3eFa0D6yE9twDT1p3GK6tPIoXj3hAR1SgW71RtXRtKU8r1f9gXBRoRc3ddxvAfD+PWvUy5QyMioir67rvvsGDBAgQHB5faJiQkBAsWLMD3339fc4GRLILcHbHu+Y54o3cjWCkE/HlWmlLu38t35Q6NiKjOYPFORlHPwQbfjWyFeU+3gLOtFU5E38fjX+/H2qPR7FpHRGSB9u/fj9atW8PT07PUNp6enmjdujX27dtXg5GRXKyUCrzasyE2vtQJDTwdkZiei7FLIzFzC6eUIyKqCSzeyWgEQcCQVvWxbUpXtA9xQ2aeGu/8dhbP/XIc9zJy5Q6PiIgqITY2tsyr7lpBQUG4c+eO6QMis/Fw/Xr489WuGNtRmlVg+aGbGPDtAUTFcko5IiJTYvFORlff1QGrJ3fAe/2awFopYNf5BPSZvx//XEyQOzQiIqogW1tb3L9/v9x2aWlpUCo500hdY2+jxEeDwrF8fDt4OtviamIGhiw4iO/3XIVawx53RESmwOKdTEKpEPB8t1BsfrkLGnk7ISkjFxOWH8P/bTqLrLwCucMjIqJyNGvWDAcOHEBycnKpbZKTk/Hvv/8iLCysBiMjc9K9sRd2THkEfZv5IF8t4osdlzBi0WHEJGfJHRoRUa3D4p1MKszPBVte6YKJXUIAAKv+i0b/bw7gVMx9eQMjIqIyjRkzBhkZGXjqqadw+/btEutjY2MxfPhwZGVlYfTo0TJESObCzdEGP4xpjS+eehiONkocvZmCfl/vx/pjMRz3hojIiASR36oApG5/KpUKqampcHFxkTucWung1SS8uf404lJzoFQIePXRh/BKj4dgpeQ5JCIiQ+TMTQUFBejZsyf2798POzs79O3bF6GhoQCAa9euYceOHcjOzkbnzp2xZ88ei5kTnvnetGKSszB17Skcu5UCAOjbzAefPdkcbo42MkdGRGSeKpOXWLwXYjKvGalZ+Zi+OQpbTkuDG7UMqId5T7dEiIejzJEREZkfuXNTVlYWXnvtNaxYsQJqtf5o4kqlEmPHjsXXX38NJyenGo+tquT+TOsCtUbEwn3XMG/XZRRoRHg62+KLpx5G98ZecodGRGR2WLxXAZN5zdp8KhYf/B6F9JwC2FsrMX1AGEZGBEAQBLlDIyIyG+aSm+Li4rB3717ExMQAAAICAtC9e3f4+vrKFlNVmctnWhdExaZiytpTuJqYAQAY2zEI7/VrCnsbDnBIRKTF4r0KmMxrXuz9bLy57jQOX78HAOjV1Auzn3wYns62MkdGRGQemJuMj59pzcrJV+N/2y5i+aGbAIBQT0fMf7oVmtdXyRsYEZGZqExe4s3GJBv/evZYNak9PujfFDZKBf6+kIi+8//F3+c5pRwREVFtYGetxMwnmmHFhAh4Odvi2t1MDFlwEN/9cwUFao3c4RERWRReeS/EM/HyuhifhilrTuFifDoAYGREAD7oHwZHW2kAJLVGROSNZCSm58DL2Q4RIW5QKtjFnohqN3PITVlZWdizZw+uXLmC9PR0g6OHC4KA6dOnyxBd5ZnDZ1pXpWTm4f9+P4u/zsYDANoEuWLe8JYIdHcAwFxPRHVTjXWbz8rKQlJSEtzd3eHoWDTgWEpKCubMmYOoqCgEBgbijTfe0I1Qa66YzOWXW6DG3J2XsXj/dYgiEOzugK+ebonEtBzM2noecak5ura+KjvMGBiGvuGWd78lEVFFyZ2bli9fjqlTpyItLU23TBRFvfFJtM8fHNDOXMn9mdZ1oihi44lYzNhyDhm5BXC0UWLGwGZwtrPCR38w1xNR3VNjxft7772Hzz//HJGRkWjTpg0AIDc3Fw8//DCuXr2qOzvv4eGB06dPm/XANkzm5uPwtXt4Y90p3EnNgUIANAb+QrWHjT+Mac2kTkS1lpy56e+//0afPn2gUqnw8ssvY8+ePTh8+DAWLlyIa9euYdOmTbhy5QpeeeUVtGnTBuPGjavR+KqK+d48xCRn4Y11pxF5M7nUNsz1RFQX1Ng97//88w9CQ0N1hTsArFy5EleuXEGPHj2wY8cOvPbaa0hKSsK8efOqsyuqQzqGumPblEcwqIWvwcIdALSLZ209D3VpjYiIqMrmzp0LQRCwZ88efPzxx2jYsCEAYPLkyfjf//6Hc+fOYcqUKVi6dKnecQBRRQS4OeDX5zrgrT6NS23DXE9EpK9axXt0dLQumWtt2bIFgiBg2bJl6N27N+bPn49GjRph27Zt1QqU6haVvTVGRASV2UYEEJeag8gbpZ+1JyKiqjl69Cg6dOiAFi1aGFxvZWWFL7/8El5eXpgxY0YNR0e1gVIhoHWga5ltmOuJiIpUq3hPSUlBvXr1dM9FUcSBAwfw8MMPIyAgQLe8RYsWurlhiSoqMT2n/EYAEtMq1o6IiCouIyMDgYGBuue2ttI0nunp6bplCoUC7du3x/79+2s8PqodKprr41KzTRwJEZH5q1bx7uPjgxs3buieHz9+HCkpKejWrZteu+ID2xBVlJezXYXaffLXeXz653kcv5UMDbvVEREZhY+PD5KTi652asetuXz5sl675ORkZGezsKKqqWiun745Cm+uP41d5xOQk28ZgyMSERlbtYr3li1bIjIyEr///jvS09Px8ccfQxAEDBgwQK/dlStX4OfnV61Aqe6JCHGDr8oO5Z36uZueh8X7b2DoD4fRfvZu/N+ms/j38l3kc/5YIqIqa9KkCa5cuaJ73qlTJ4iiiM8//1w3IO2hQ4fwzz//oHHj0u9bJipLRXK9IACZuWpsOH4bk38+htYf78LLq05g86lYpOfk11isRERyq9Zo84cOHcIjjzyiS+KiKKJly5Y4duwYFArpvEBCQgL8/f0xcuRI/PLLL8aJ2gQ4+qx52h4VhxdXngBQNHANUDQC7fwRLWGjVGDHuXjsvpCI9NwCXRsXOyv0auqNPuE+eKShJ+xtlDUXOBGREciZm7799lu8/vrrOHLkCCIiIqDRaNC6dWucPXsW3t7e8PX1RVRUFAoKCrBixQqMGTOmRuOrKuZ781Nerv9uVCu4O9lie1Q8dpyL15tOzkapQOeH3NGnmQ96hXnDw8m25gInIjKCGpsqDgC2bt2KL7/8EklJSWjTpg0+++wz1K9fX7d+/vz5mDVrFr777juMHj26OrsyKSZz87U9Kq5C87znFWhw+Po9bI+Kx67z8UjKyNOts7NWoHsjL/QJ98ajTbyhsreu0fdARFQVcuam1NRUHDlyBE2aNEFQkDSAaGxsLCZOnIi///4bGo0GKpUKb7/9Nt57770aja06mO/NU0VzvSiKOBubiu1R8dh+Lh7X72bq1ikEoG2wG/o280GfcB/417Ov0fdARFQVNVq81xZM5uZNrREReSMZiek58HK2Q0SIG5SK0jvZqTUijt9KwY5z8dgeFY/Y+0X3Y1opBHR6yAN9mnmjd5h3he+3IyKqaeaam7KyspCamgovLy8olZbVq8lcP1OqfK4HgKuJ6YVX5BNwNjZVb11zfxX6hvugTzMfPOTlZMrQiYiqjMV7FTCZ116iKOLcnTRdIX8lMUO3ThCAtkGu6NNMSu4Bbg4yRkpEpE/O3DRt2jS4urpi+vTpNbpfU2O+r71up2Rhx7kE7DgXj6M3k1H8CDfU0xF9w33Qt5kvwv1dOJgyEZmNGiveExIScOnSJTRu3Bje3t665deuXcP//d//ISoqCoGBgZg+fTo6duxY1d3UCCbzuuPa3QzsOCedpT8dc19vXTM/F/Rp5oO+4T5o6OXE5E5EspIzN9nY2GDQoEFYv359je7X1Jjv64a76bn4+4JUyB+8moR8ddHhrn89ezzWzBt9m/mgbXD5V/eJiEypxor3qVOn4ptvvsGFCxfQqFEj3c4bN26MxMRE3UB29vb2OHXqFBo2bFjVXZkck3nddOd+Nnaek+6bi7yRjOIzzTXwcMRjhYV8i/oqFvJEVOPkzE0NGjRAq1at8Ntvv9Xofk2N+b7uScvJx56LidhxLh57Lt5FdrGp5twdbdA7TBrctlOoO2ytLOs2ECKyfDVWvLdq1QoFBQU4e/asbtk333yDKVOmYNSoUZgxYwb+/PNPTJs2Dc899xwWLlxY1V2ZHJM53cvIxe4LUnLffyUJecWmmvNV2eGxwuQeEewGK2XpsyxW5Z49IiJD5O42//PPP+PGjRtwdnau0X2bEvN93ZaTr8b+K0nYHhWPvy8kIDW7aKo5J1srPNrEC32a+aB7Y0842lqVuh3meiIylhor3r28vNCxY0ds3rxZt6xPnz7Ys2cP7ty5Aw8PDwBSkZ+Tk4MLFy5UdVcmx2ROxaXn5GPvpbuFZ+kTkZlXdJbe1cEavZp6o2+4Dzo/5AE766Kz9BUdLZeIqCLkzE3p6eno1q0bHB0d8c0336BVq1Y1un9TYb4nrXy1BpE3knVT0CWm5+rW2Vgp8EhDT/QN90Gvpl6o52CjW8dcT0TGVGPFu729PQYPHoxff/0VAKBWq+Hq6opmzZrh8OHDunYjR47EH3/8gfT09KruyuSYzKk0OflqHLyahB3n4rHrfAJSsorO0jvaKNG9iRf6NvNBgUbEtLWn8OB/KO15+B/GtGZSJ6JKkTM3Pfroo8jOzsZ///0HQRDg6+uLwMBA2NmVnKFDEATs3r27RuOrKuZ7MkSjEXHq9n3sKJyC7ta9LN06pUJAhwZu6NPMB9ZKBd7feJa5noiMpjJ5qfT+QBXg5+eHixcv6p4fOHAAGRkZ6N69u167goIC2NjYgMgS2Vkr0bOpN3o29UaBWoOjN4umoItPy8GfZ+Lw55m4Ul8vQkrqs7aeR+8wH3arIyKLsHfvXt3voijizp07uHPnjsG2HBOELJ1CIaB1oCtaB7ri3X5NcClBmoJue1Q8Lsan4+DVezh49V6pr2euJ6KaUK3ivWPHjvj1118xf/589OzZEx988AEEQcDAgQP12l24cAH+/v7VCpTIHFgpFegY6o6Ooe74cEAYzsSmYse5ePx+IhZxaTmlvk4EEJeag8gb99Ax1KPmAiYiqqIbN27IHQKRLARBQBMfFzTxccGUXo1w614mdpyLx4bjt3E5IaPU12lz/eFrSejS0LPmAiaiOqNa3ebPnTuHdu3aITdXukdIFEX06NFDr+vczZs30aBBA0ycOBGLFy+ufsQmwm50VB2bT8bi9bWnym1nZ6VAuL8KjX2c0cTXBU19nNHYxxnOdtamD5KILA5zk/HxM6Wq2nwqFq+vOVVuO6VCQBMfZzTxcUFTXynPN/FxgaezremDJCKLU2Pd5ps1a4YDBw7g66+/RlJSEtq0aYO33npLr82OHTvQokULDB48uDq7IjJrXi4l7wE1JKdAg2O3UnDsVorecv969mjqKyX3xj7OaOrrjGB3xzJHtSciIqKa4+VcsVyv1og4dycN5+6k6S33cLLR5fkmPs5o6uuCh7yc9Aa+JSIqS7WuvNcmPBNP1aHWiOgy5x/Ep+aUGMQGkO6D81HZYemz7XA5IR0X49NxKT4dF+PScCfVcHd7GysFGnk7obG3i66wb+LrDA8nnrknqivkzE3R0dGVah8YGGiiSIyL+Z6qqqK5ftWk9rickCHl+fg0XIxPx817mTB0xK0QgBAPx2K98VzQxMcZ9V3tOZYEUR1RY6PN1yZM5lRd26Pi8OLKEwCgl9TLG4E2NSsfF+PTcCkhHRfipER/KT4dWcWmpytOe+a+SWGX+6qeubekOWoZK9VVcuYmhUJR4eJBEAQUFBSYOCLjYL6n6qhqrs/KK8CVhAxdMX+xMN8Xn8GmOGdbKzQuzPPawr6RjzNcqnCbnaXkJUuJk8jYarx4T0hIwNKlS7F//37ExsYCAPz9/fHII49g/Pjx8Pb2ru4uTI7JnIzBWHO/ajQibqdk40J8mi7BX4pPx41SztwrFQJCPBylYt6nqPt9aWfuLWmOWsZKdZmcual79+4Gvz80Gg1iYmIQHR0NjUaDjh07wsbGBnv27KnR+KqK+Z6qy1jf9aIoIjE9t7CYLyzq49NxNTEd+WrDh+eVvc3OUvKSpcSpxRMNZEw1Wrz/9ttvmDBhAjIyMvDgpgRBgLOzM5YsWYKhQ4dWZzcmx2ROxmLKL/TsPHVht/vKnblv4it1xWvq44yY5CxMW3faIuao1V7hYKzGxwMPy2DOueny5cuYNGkSRFHErl27DM7/bo7M+TMly2HK79B8tQbX72YWy/XSz7gybrNr6OWkGyBPW9gfv5VsEXnJ0vInTzSQsdVY8X7s2DF06tQJGo0GgwcPxjPPPIPg4GAIgoCbN2/il19+waZNm6BUKnHw4EG0bdu2qrsyOSZzslRVOXNfFlcHa3wyKBxKpQBBEKAQBAgAFArphJwAQKFdLkB6QIBCkObJFYDC1xX9VBRevVMIgrQdaNdDfx/FtimKwNAfDiExPddgnAIAb5Ud9r3ZHTZWFe/eawra+yBLO7DS3gd54J1HzSJhWtqBR11m7rkpKSkJjRs3xqRJkzBnzhy5w6kQc/9MiUqjvc3uYrF76cu6zU4hAJoyDgNcHawxe0hzWCkVEITiObgodxvK6UJhO4X2OQS91+uWl5HjtccRGlHE4O8PlpnrfVR22P92D7MYxJcnGsgUaqx4Hzp0KH7//Xds2LABQ4YMMdhm06ZNGDp0KJ588kls2LChqrsyOSZzqm0Mnbk/ffs+kjMNX6W3dIIAKAUBCoUAK4Wg+12pkA4QlArASqGAQlHUTilI65V67fSXS+1QajuFQsC9jFzsuXS33Bhf7hGK5v4q2ForYWelhJ21AnbWysKHArbaZVZKKExU5FvagUddZwm56fHHH8e5c+dw69YtuUOpEEv4TIkqSqMREZOSpdcb72J8Om4kZcodmtEVz/OG87f+cUDxdtq8rX+MAL11Vg+009uHdKUCW0/fKfVkCQCo7K0xc2AY7G2sdDne1ko/10v5X1puqlwPMN9bkhor3r29vdGoUSPs37+/zHZdu3bF5cuXkZCQUNVdmRyTOdUFFZ2jNtTDEa6ONtCIIkQUnrkXRWhESMuK/RRRtBza5ZB+ajTS9jSiWOx1Um8BbRu9bRXbR4FGhLqsSwa1nI1SAVtdcS8le9tiSd/OWlHiJEDRAULhT+1rCtfZKBV49deTuJeZZ3Cf5tZDgCwjN/Xr1w979uxBTo7hnifmxhI+U6LqWn8sBm9tOFNuuyB3B9RzsJHysqjN19B7rs3XKL4eUo4vns+l1z2wTCP9LpZy/FCgEQ2O5VNX2Fgp9HN3sRwv5e7iud9wO9tiuV7K/QpYKxV47pdjSMpgvrcENTbPe2pqaoWmhgkMDMTRo0ersysiMoKKzlH7yZDm6BjqbuJoynb42j2MXHyk3HY/jW2LVoH1oC48WaAuPFjQFv8aUfqpexSuL/odKNBoCttB95oCzYPtCpcV2572NTeSMrDu2O1yYw33c4GttRK5BWrk5GuQky/9zM1XI6dArXebQ55agzy1Buk5NTeCtwggLjUHuy8k4LFmPjW2X7JcJ0+exL59+xAUFCR3KERUTH1Xhwq1+9+TD8ua7yua638c0xqtglzLzfOG83fF87z6gWOGotdocO5OGrZFxZcba0MvJzjbWUl5vkCNXF2+VyO3QIOCYhcm8go0yCuo2VwPFOX7yBv30DHUo0b3TdVTreLdx8cHJ0+eLLfdqVOn4OPDA0EiuUWEuMFXZVfuHLURIW41HVoJFY21RxMv2c8aqzUi9l9JKjfWza90KTNWtUbUJXdtotcm/5z8ogMAvfUFRScBpHWF7fROEEi/J2XklnpfYXHP/XIcfio7hPur0NxfhfD60k8PJ9uqf0hkcT766KNS12VkZODy5cvYtm0bCgoK8Pzzz9dgZERUHkvJ9xWNs1eYj+y5/vC1exUq3j8aFF7mCZECtaZY7i4vfxf+LLYuN7+UY4QCje6CQHJmHu5nl3+b5KQVx9A6yFWX75v7q0qdqYjMQ7WK9z59+uCnn37C+++/j48//hhKpf4806IoYvr06bh48SImT55crUCJqPqUCgEzBobhxZUnIMDwHLUzBobJniCBuhmrUiHA0dYKjiaqkSt6hQMA7qTm4E5qDnaeL7rdybewoA/3U6F5fReE+6sq3JujrqhNo/rOnDkTgiCUmEmmOAcHB7z33nuYNm1aDUZGROWxlBxqKXECxjshYqVUwEmpgJNttcqwMlU032fmqbH/ShL2X0nSLavnYI1wP1XRCXx/FwS6ObCgL0bOXF+te95v376NVq1aITk5GYGBgRg+fDiCg4MBALdu3cL69etx8+ZNuLu748SJE6hfv76x4jY63gNHdYkljT7KWI1HOyp+eQce217viovx6YiKTcXZ2FRExabielKmwfsSvV1sC5O7tqhXwdulbhb0pvj3lzM3rVixotR1NjY28PX1Rbt27eDo6FiDUVUf8z3VJeael7QsKc4XV54AYPhEg7kMAleRfO+tssOCUa1xPi4NUbGpiLqTikvxhmcqcrGzKlbMSz+D3OtmQS93rq/2PO9nz57F6NGjERUVJW2w8B9Ru9nmzZtj1apVCA8Pr85uTI7JnOoaS7pCyFiNp6oHHhm5BTh/J01XzJ+NTcW1uxkGC3pPZ1u9BB/u7wIfF7sqJ3lz/0wB043qy9xkfPxMqa6xhO9QwHLirM0nGnIL1Lgcn4GzxU7eX4pPR55aU2L7znZWaObnopfvg90dqzyCviX8+5tDrq928a61d+9e7N+/H3fu3AEA+Pn5oWvXrujevbsxNm9yTOZEVFcY68AjM7cAF+LS9JL81cQMg/MKezjZ6J21D/dXwU9VfkFvzgdJoigiu/DewsHfHzTJqL7MTcbHz5SIqssSCk3AODk0r0CDywn6vfEuxKcjr8BAQW9rhbDCgr55fRWa+anQwKP8gt6ccz0gjVOQkpWPx7/ej7sZhscOqqlcb7TivSxLly7F7du38eGHH5p6V1XGZE5EdYmpDjyy8qSCPiq26Cr9lcQMg9P+uTvaoJm/Cs39i87c+9crGiinJuao1WhEpOcWIC07H6nZ+bqfqdn5SMsp+j01u2SbtJx8g90LS/Pr5A6VHtVZztx04sQJrFy5EiNHjkS7du0MtomMjMSaNWswduxYtGzZskbjqyrmeyKqS0yR7/PVUkF/LrboBP6FuDTkGijoHW2UaKa9h76+lO9DPJx0MdTUfPQ5+Wqklcjt+UjLLtB7rpfnC39m5qkrvB9T5/oaKd47duyIyMhIqNUVf+M1jcmciMg0cvLVRffUxabibGwariSk602Xo+XqYI1wfxXC/Fyw9mgM7mcZHi23+BlujSgWK6gLSiTgNIPFuJSw03PyDfYUqAyFgApt4+sRLTGopX+lti1nbpowYQJWr16NmJgYeHp6Gmxz9+5dBAQE4JlnnsHixYtrNL6qYr4nIjK+fLUGVxMz9G6vuxCXhpz8kgW9g40SYb4uCPNzweZTd5Baysj4xXO9QgCy8tQGi2z9E+sljwNSs/MNnlgwBVPnetMNc0hERATAzlqJ1oGuaB3oqluWk6/Gxfh0KcnflpL85YR0pGTllxj51hDtHLXNPtyOHCMkZDtrBVT21nCxs4bKXnq4PPjTzkq3TuVQ1PbM7fsYufi/cvdhaSPz79+/H61bty61cAcAT09PtG7dGvv27avByIiIyNxYKxVo6uuCpr4uGN42AIDU3fza3Uy9gv78nTRk5alx7FYKjt1KKXOb2lzf8qOdyM5TGzzpXxkKAXB5INdLed5Kl+sfPBbQHgecv5OKMUsiy92HqXM9i3ciIqpxdtZKtAyoh5YB9XTLcvLVuJwgFfR/nLmDw9eSy91O8cLd2VZKvlICtiqZgIsV3C7FErbK3hq2Vsoy9lK2iBB3i5hPubJiY2NL7S5fXFBQEM6cOVMDERERkSWxUirQ2McZjX2c8VQbadYxtUbE9bvSFfrNp2Kx73LZJ+sBID2nQPe7tVJ44MR6yUK8eNGtW+9gDScbqyoPqNcx1MMscj2LdyIiMgt21ko8XL8eHq5fDw08nHD4Wvlz1M5/ugW6NfKCs50VrJSKGoiyJEuap7gybG1tcf/+/XLbpaWlQams+skPIiKqO5QKAQ29ndHQ2xm+KvsKFe+fD30YjzTyhMreGnbWClmmqDOXXC/PkQ4REVEZIkLc4KuyQ2kpUIA0Eu3AFv5wdbSRrXDX6hvuix/GtIaPSr+7nI/Kzmzm/a2sZs2a4cCBA0hOLr0HRHJyMv7991+EhYXVYGRERFQbVDTXD21THz4qO9jbKGWdW94ccj2vvBMRkdkxlzPcldE33Be9w3wsYvqgihgzZgxeeuklPPXUU/j5559Rv359vfWxsbEYN24csrKyMHr0aJmiJCIiS8VcX3kcbb4QR58lIjI/5j73q6nJmZsKCgrQs2dP7N+/H3Z2dujbty9CQ0MBANeuXcOOHTuQnZ2Nzp07Y8+ePbCysozrAcz3RETmhbneRFPFVfeeNhbvRERUWaaak94SyJ2bsrKy8Nprr2HFihUlcrhSqcTYsWPx9ddfw8nJqcZjqyq5P1MiIiqJud4ExbtCUfV7CgVBYPFORERUCeaSm+Li4rB3717ExMQAAAICAtC9e3f4+lreFRFz+UyJiIiAyuWlSlXjGo2myo/KFu7ff/89goODYWdnh/bt2yMysux59e7fv4+XX34Zvr6+sLW1RaNGjfDXX39Vap9ERERUkq+vL0aOHIm3334bb7/9NkaOHGm0wp35noiIqGLM8ga1tWvXYtq0aVi4cCHat2+P+fPno0+fPrh06RK8vLxKtM/Ly0Pv3r3h5eWFDRs2wN/fH7du3UK9evVqPngiIqJaQKPRICMjA/b29rC2tjbYJj8/H9nZ2XBycqpS7zzmeyIiooozy6nivvrqK0yePBnjx49HWFgYFi5cCAcHByxdutRg+6VLlyI5ORm///47OnfujODgYHTr1g0tWrSo4ciJiIhqh3nz5sHV1RX79u0rtc2+ffvg6uqKb7/9tkr7YL4nIiKqOLMr3vPy8nD8+HH06tVLt0yhUKBXr144fPiwwdds2bIFHTt2xMsvvwxvb2+Eh4fjs88+K7Orfm5uLtLS0vQeREREJNm0aRMCAgL08vGDevXqhfr16+O3336r9PaZ74mIiCrH7Ir3pKQkqNVqeHt76y339vZGfHy8wddcv34dGzZsgFqtxl9//YXp06dj7ty5+OSTT0rdz+zZs6FSqXSPgIAAo74PIiIiS3blyhU0a9as3Hbh4eG4cuVKpbfPfE9ERFQ5Zle8V4VGo4GXlxcWLVqENm3a4Omnn8b//d//YeHChaW+5r333kNqaqruoR1Bl4iIiIDU1FSoVKpy26lUKqSkpNRARMz3RERUt5ndgHUeHh5QKpVISEjQW56QkAAfHx+Dr/H19YW1tbXePPRNmzZFfHw88vLyYGNjU+I1tra2sLW1NW7wREREtYSvry/OnDlTbrszZ84YHFyuPMz3RERElWN2V95tbGzQpk0b7N69W7dMo9Fg9+7d6Nixo8HXdO7cGVevXoVGo9Etu3z5Mnx9fQ0mciIiIirbo48+igsXLmDt2rWltlm3bh3Onz+PHj16VHr7zPdERESVY3bFOwBMmzYNixcvxooVK3DhwgW8+OKLyMzMxPjx4wEAY8eOxXvvvadr/+KLLyI5ORmvv/46Ll++jD///BOfffYZXn75ZbneAhERkUV76623YGNjg7Fjx+KVV17BmTNnkJmZiczMTJw5cwavvPIKnnnmGdjY2OCtt96q0j6Y74mIiCrO7LrNA8DTTz+Nu3fv4sMPP0R8fDxatmyJ7du36wa1iY6O1ptPNiAgADt27MDUqVPx8MMPw9/fH6+//jreeecdud4CERGRRWvSpAl+/vlnjBs3Dj/88AN++OEHvfWiKMLOzg7Lli1DeHh4lfbBfE9ERFRxgiiKotxBmIO0tDSoVCqkpqbCxcVF7nCIiIjMIjddvXoVX331FXbv3q0b7E07hdyUKVPQsGFDaDQavSLbnJnDZ0pERKRVmbxkllfeiYiIyDw89NBDWLBggcF1J0+exLRp07BmzRrcuXOnhiMjIiKqW1i8ExERUYXFxMRg1apVWLlyJS5cuABRFCEIgtxhERER1Xos3omIiKhM6enpWL9+PVauXIl///0XoihCFEX4+/vj6aefxsiRI+UOkYiIqNZj8U5EREQlqNVqbN++Hb/88gu2bt2KnJwcaIfJEQQBe/fuRdeuXXnVnYiIqIZYxugyREREVCOOHj2K1157DX5+fnjiiSewbt06FBQU4IknnsD69evRrl07AMAjjzzCwp2IiKgG8co7ERER4ZNPPsGqVatw+fJl3RX2Tp06YcyYMRg+fDjc3NwAAPPnz5cxSiIiorqLxTsRERHhww8/hCAI8PHxwUsvvYTRo0cjODhY7rCIiIioELvNExEREQBAFEXEx8djx44d2LVrF+7fvy93SERERFSIxTsRERHhv//+w8svvwx3d3ccOHAAL7zwAnx9fTF06FBs3LgR+fn5codIRERUp7F4JyIiIrRr1w7ffvst7ty5g82bN+Opp56CIAjYtGkThg0bBl9fXzz//PNISEiQO1QiIqI6icU7ERER6VhZWWHgwIFYu3Yt4uPjsXjxYnTt2hUpKSlYvHgxrl27BgB49913cerUKXmDJSIiqkNYvBMREZFBLi4umDhxIvbu3YubN2/i008/RZMmTSCKIr744gu0adMGTZs2xccffyx3qERERLWeIGrng6nj0tLSoFKpkJqaChcXF7nDISIiMtvcdOLECfzyyy9Ys2YNEhISIAgC1Gq13GFViLl+pkREVDdVJi/xyjsRERFVSuvWrTFv3jzExsbizz//xIgRI+QOiYiIqNbjPO9ERERUJQqFAv369UO/fv3kDoWIiKjW45V3IiIiIiIiIjPH4p2IiIiIiIjIzLF4JyIiIiIiIjJzLN6JiIiIiIiIzByLdyIiIiIiIiIzx+KdiIiIiIiIyMyxeCciIiIiIiIycyzeiYiIiIiIiMwci3ciIiIiIiIiM8finYiIiIiIiMjMsXgnIiIiIiIiMnMs3omIiIiIiIjMHIt3IiIiIiIiIjPH4p2IiIiIiIjIzLF4JyIiIiIiIjJzLN6JiIiIiIiIzByLdyIiIiIiIiIzx+KdiIiIiIiIyMyxeCciIiIiIiIycyzeiYiIiIiIiMwci3ciIiIiIiIiM8finYiIiIiIiMjMsXgnIiIiIiIiMnMs3omIiIiIiIjMHIt3IiIiIiIiIjPH4p2IiIiIiIjIzLF4JyIiIiIiIjJzLN6JiIiIiIiIzByLdyIiIiIiIiIzx+KdiIiIiIiIyMyxeCciIiIiIiIycyzeiYiIiIiIiMwci3ciIiIiIiIiM8finYiIiIiIiMjMsXgnIiIiIiIiMnMs3omIiIiIiIjMHIt3IiIiIiIiIjPH4p2IiIiIiIjIzLF4JyIiIiIiIjJzLN6JiIiIiIiIzByLdyIiIiIiIiIzx+KdiIiIiIiIyMyZdfH+/fffIzg4GHZ2dmjfvj0iIyNLbbt8+XIIgqD3sLOzq8FoiYiIqLKY64mIiCrGbIv3tWvXYtq0aZgxYwZOnDiBFi1aoE+fPkhMTCz1NS4uLoiLi9M9bt26VYMRExERUWUw1xMREVWc2RbvX331FSZPnozx48cjLCwMCxcuhIODA5YuXVrqawRBgI+Pj+7h7e1dgxETERFRZTDXExERVZxZFu95eXk4fvw4evXqpVumUCjQq1cvHD58uNTXZWRkICgoCAEBARg0aBDOnTtXatvc3FykpaXpPYiIiKhm1ESuB5jviYio9jDL4j0pKQlqtbrE2XRvb2/Ex8cbfE3jxo2xdOlSbN68GStXroRGo0GnTp1w+/Ztg+1nz54NlUqlewQEBBj9fRAREZFhNZHrAeZ7IiKqPcyyeK+Kjh07YuzYsWjZsiW6deuGjRs3wtPTEz/++KPB9u+99x5SU1N1j5iYmBqOmIiIiCqjsrkeYL4nIqLaw0ruAAzx8PCAUqlEQkKC3vKEhAT4+PhUaBvW1tZo1aoVrl69anC9ra0tbG1tqx0rERERVV5N5HqA+Z6IiGoPs7zybmNjgzZt2mD37t26ZRqNBrt370bHjh0rtA21Wo2zZ8/C19fXVGESERFRFTHXExERVY5ZXnkHgGnTpmHcuHFo27YtIiIiMH/+fGRmZmL8+PEAgLFjx8Lf3x+zZ88GAHz00Ufo0KEDHnroIdy/fx9ffPEFbt26hUmTJsn5NoiIiKgUzPVEREQVZ7bF+9NPP427d+/iww8/RHx8PFq2bInt27frBraJjo6GQlHUcSAlJQWTJ09GfHw8XF1d0aZNGxw6dAhhYWFyvQUiIiIqA3M9ERFRxQmiKIpyB2EO0tLSoFKpkJqaChcXF7nDoYoQRUCdB1jxXkYiqp2Ym4yPn6mFYa4nolquMnnJLO95JyqTKAJX/wYW9wDmhQOppU8RRERERBaIuZ6IqASz7TZPVIIoAtd2A/98Atw5CenckwbITAJU9eWOjoiIiKqLuZ6IqFQs3sn8qQuAq7uAfXOkRC4oC1doZA2LiIiIjEQUgau7gT2fMNcTEZWCxTuZn6xk4PYx4HYkcHkHkBAFiJqiRC6q5Y2PiIiIqkcUgeTrwO2jwLnfget7gYJs5noiojKweCfzkBYH7J4lJfF7Vw23YSInIiKybAfmA7cOSfk+O7nkeuZ6IqJSsXinmpWZJCXsmEigXiDQVprLFzaOwOk1AAonP3B/CKgfAdi5SGfj716UzsYzqRMREZk3jQa4d0XK92l3gG5vF627sAWIPS79rrQBfFsCzr5A/Bkg5QZzPRFRGVi8k+mIIhB3SuoCHxMpJfGUG0XrAzoUFe92LkDf2YBbKFC/LeDgpr+d4oPXCAqpG73Wpb8Av5Y18Y6IiIjoQdkpwO3jUp6/fRSIPQbkpErrBCXQ8RXAxkF63m4y0HyYdILeJ7xoCrjycv3RJcDA+YBCCSKiuorFOxlPegKQGiMV31qrhgGZd/XbeTaR2gR10V/e4UXD2xUE4KFeQGjPB0agLbRvDpAeD/T7HLC2M857ISIiopI0aqk3nGdTQFE44/CfbwJRG/TbWdkD/q2lfF+QU1S8txxpeLvl5fqTP0vHGEOXAI7uxn9fREQWgMV7TRBFQJ1XdHbZnFU01oI8IP6sNKjc7aNAzFEgNRpw8gHeuCglYUEAHuoNZCYC9dtJD/82gH29qsVmKLEnXQbyMoETK6SB7SbsAJTWVds+ERFRdVhKvq9MnJlJRYPI3j4KxJ4A8jKAl48Cno2kNvXbAXdOSFfT67eVnns3q1o+NpTr712T4r2+B/ixKzB2C+DxUOW3TURk4Vi8m1LxLmCpscBze8x3jtLKxPrHVODkKkCd+8AKAXBwB3LTADuVtGjID8aPtXhiV+cBNw8Av00CmvRn4U5ERDXPUvJ9ZeI8twnY/ZE0IvyDbJyB+7eKivf2zwMdXjBurA/m+nvXgHXPADZO5vnZEhHVABbvpvDgfVtQANBIZ6/NLeGUFuv1fYX3sB2Vzqa/eBiwdZJeY2UvFe72roVn2dsBAe0Av9bSves1RRCkqwYP9QReOgI4ehaty7grnUjQdukjIiIyNkvJ96XFefeS9DwmUrq63u0tIPRR6TVW9kWFu0fjolxfv510+1vxe88FwXSxa3O9dxgweY901V97i5xGXdgl39F0+yciMiMs3o2pxGAr2sSmKfNlNUIUi/0UpZFgr+8F9n5aNDAMAF2sm1/Sf/2dk0BIV+n39s8DbScA7qGmTdiV4exd9HteJvDzE4CLH/DkYv3B74iIiKrLnPN9cYYGgQOgi3Plk/rtbx0uKt6DOgJjfiu83c21xkIuk52L/kWCvbOBC38AT69kN3oiqhNYvBvLtT3SPOXFk/iDU52sHCp16xZF4JmN0v1gAHBkIfDv50WFtbbQhijNnDZ6PRDYXlp09Cdg5/RS2orAqDVSNzMAOPEzsOXVsuPWxfrAAYddPSCoU+G9axFS8tZyDarIJyKfuNNA8g0g8TzwYzfg6Z8Bv1ZyR0VERLWBXr4vLIYfzPc/PwEorICubwIdC0+Gx58FVgwsaqPL34U6vQI88pb0+71rwKIe2oYl20dMAnrNlH5PuwN8W2ygWG17jVrqbg6x9FwPQToW0eb64GIDydqpio4nzFFOKnByJZAeByzqDgz+HggbJHdUREQmxeLdWLa9AyRdkn4vbX7SrKSi39V5Rb/nZwFZ90rftqag2OsKpPalefBgoDylxTr2d8steIM6AZP+lu6NS74OLHkMePwLoPU48+kpQERElkkv35dypV07TVpBdtEyjVq6Ha00+TlFv4saIDe19LYFxY4hRBHIzyw75tJy/fi/pJxpiexUwHN7gfXjgehDwLqx0pR0vWZy/BsiqrUEUaxstVc7paWlQaVSITU1FS4uVbhv+8Er74YS5ZOLAc/GAATA/aGiaVMykwqnUyscoV33E9LvLn5FbXNSC5N/KW0d3IvuBcvPBnLT9dsCwK2DwL9fAPFnSo/1uX2WP3d69n3g95eAS39Kz1uOAfp/CVjbyxoWEVFFVTs3UQk1ku+HrZDuC3f0LJrWLD8HuB+t3674CWV7V8DRQ/q9IE+aFq00dqqituoCIO32Aw0EIPoIcOhrIOFc7c716nzp3+PQt9LzwE7AsGWAs4+8cRERVVBl8hKL90JGOUAydA9c8WRpTknSkmKtDo0GODgf+Odj6UpG63HAE9/IHRURUYWweDe+OpXvLSVOYzi/RTphn5cOuAZLU9lZ2cgdFRFRuSqTlzgUtzFppzWZvEca5MX34cIVZvgxW1Ks1aFQAF2nAc9sArzCgO7vyh0RERFZOkvJoZYSpzGEPSF1o/cKA7q9y8KdiGol3vNuCsXnJtWe8U6L1Z/KzFxYUqzV0aA78MJB/anjrvwNhPbQn+6GiIiooiwlh1pKnNXl8ZDUm6B44Z54AXDxr9mpbImITITd5guZtGuiKEoD1FnZGne7pmBJsVbH+S3SgHYNugNDlxTdO0hEZEbYbd74mO9hOXFWV2YS8OMjgJWdNJ2cd5jcERERlcBu8+ZGECwnQVpSrNUhqgFrB2mu+x+7AbePyR0RERFZOkvJoZYSZ3VlJAAQgORrwE89gTPr5I6IiKhaWLxT3dRsCDD5H2nU/7TbwNK+QOTiyk+1R0RERObJuxnw/L9Agx7SNLsbJwN/vgEU5ModGRFRlbB4p7rLq6k0iE/TgYAmH/jrTWDT80BeltyRERERkTE4ukuD9XV7R3p+9Cdg2eNA6oPT6xERmT8W71S32bkAw38BHvtEmkLnzFrgxr9yR0VE5RFFy7l6ZkmxEtVGCiXQ431g1HrArh4QewzY85ncURFReSwpf9ZQrCzeiQQB6PQqMG4L0P19oHFfuSOi2saSko+5E0Xg6t/A4h7AvHDzvnpmSbES1QWNHpO60YcNBvrOljsaqm2Y643HkvJnDcfKqeKItIK7SA+t9HjgxM9Al2mAkv9VqApEsWhaptRY4Lk9gKq+3FFZpuKf5Z2TkM49a6TRpM3tM7WkWInqGtcgYPiKoueiCBz+Hmg5CnBwky8uslzM9cZjSflTplhZkRAZotEAGyYAtw5K3eifWgo4eckdFVkKS0o+5u7Bz1JQFq7QyBqWQZYUKxFJIhcDO/8PiPwRGP4z4NdK7ojIUjDXG48l5U+ZY2XxTmSIQgFETAbiTgM390vzxA5bAQS2lzsyMkcatZSs0+4AV3YAp1YB96MBQXtnkhkmH0twbY80MnTytaJlolq/zb1rgF9L6fcjPwD/flE4a0ThzBHFfx+9AQiIkH4/ugTYNeOBdih6PmI1ENpD+v3kSuCPadK64u20vw9fAdg4AbtnFR7AlRIrEZmfwA6AazCQchNY0gd4/AugzTi5oyJzJIpATqqU6y9vA46vAO7fYq6vrmt7gJ0fAAlRRcsezJ/HlwN+86Xf0+KARd0M5HpIz1uMBPp8Kj3Nvg983aJYO+i/ptlgYNB30vOCXOB/QTB4/CCKQJPHgTbjZc/1LN6JStNsCOAVBqx9Bki6BCx/HHjsU6D989J98iQvUQTUeaadq1gUgewU6RaK9Lhij3igxSigfhup3blNwG8TDbzeQCIvyJP+fpTWpovb0uRmAPFnpZNlcaeBnh8CLr7Atnf0C3dDiifN/Cwg617pbTUFRb+r84G89IptV6MG1GXcxyiKUqxJl8qOlYjMj+/DwHN7gU0vSgXZ1teAmEig/5eAtb3c0VFN5HpAmmmoeI7X/nQNli7mAFIOmRNkIMZSiva8LMDGwWQhWxx1gZQntbnevy3w8LCK5c+8jKLfRQ2QkVB629ziuV0Ecu6X3vbBMQoKsktvq1GbRa5n8U5UFs/G0nzwW16RCrTt7wC3I4GB3wC2TnJHVzcZ696y3Az9BJ1+B3iolzQvMABc/AvYMB4oyDH8eq+wouLd2bfi+72yU9quZxPA52HAJxzwDpd+2rtW/n1YonvXgEt/FSXwpCvQnd0GpOkbXXyBfnOKEqWgMHyAVK/YgVTrcUDj/tLvuhNsQtFzF/+iti1GAA17F2sr6P9e/DaZ8KHAQz2Ltld824IA2KkAW+eis/GlxUpE5sneVeptc3CelFtOrQTiT0uz0biFyB1d3WSsXK/OL8zxxU7CO7gDzZ+S1mvUwOcNSi/wgrsWFe9Ka6mLdEWutKoLpO06eQE+zYvyvHe4lLcUdWDM8Pxs4PSaolyfcE7/RHjYYKl47zen2NVsAXrHA1rNhxf97ugJvHCg8IlQMofb1Stqa+sCvHKsqK22jW69c9HvShvg9TMPtCmW863sgfgzsud6Fu9E5bF1Ap5aBtSPAHZNB+Kjyn8NGV9F7y0ryNVP1L4PA24NpHU3/pW6YafHA7lpJfdh41RUvNupigp3e1fA2Q9w9pEKdWcfwLdl0esC2gOjfwP2FLv/qbTknnhBuooQf0Z6FOdSH3hyERDcWXqenyMlE0tN8pn3gLhTUtJu1BfwDpOWxx6XusgV5+wndX/3bQG4PyQtC+0BvPxfyXvLin+2xa/GOHpIj4qwryc9KsLWqfyTdaE9gAbdy46ViMyXQgF0fQPwbwNsmAgknAfSYlm817SK5nqNBshKKjoBb2UHNOhWtI1F3aV/v8y7JfcR3LWoeFcopTwLANYOhTm+MM87+xQdE2iNXAvs/bT87/iUm9JV3Pu3pMfFP4rW2ThLJwR6zSiKNz8LsHGs3GdlLnLTpWPjuNNSrmw1RlouKIFtb0vHPFo2ztJxmW+LokGiK5I/i59Qt7KRTohUhEIJeDSsWFtBkAa0LIsZ5HoW70QVIQhAx5ekgWwc3HjVvSaVGBjkgXvL7l4A/vm4qFh/sNt0/7lFxbvCCki6XLTO2lG6wqtN1sW/tP1bA6+fBpx8AGu7smNUWgENe0lXZ8v7Qu/6hnTQkBAlJbuEKKmIvx8NpN2WzihrRf4I7PtcusrvE1549r65VASbW5LPSQOiDwN3ThWdZU8rNl2K0qaoePdvI11d921Z+Hi49AEhBUHqERHa0/ABnTmxpFiJyLAG3aXp5KIP689AQ6ZVXq6HCKwbK12FT48HMuL1b4UK6lJUvAuCdDygLdwV1voFue/D+vueuLPw2M6l/NsiG/WW8n15ud7jIeDtGw/k+rPA3YvSLVvaEwaANLXY/ObSsYpPuJTntVfpVfVNc6tmdW5HuL6v6MR83GmpN532arnPw0XFu5UN0HqsdGHEt4X0cA0xfEHCkvKnzLGyeCeqjKCO+s8PfiMlkd6zasc9zDV1b1lx+dnSZ2inKpqmJ+E8cOR76WfiBf17kB7solSQL82vWZzStugqefHuU97hwNgtgEvhVfTi3aUeZG0v3etWGRX5QlcopCs5biFSAauVkyp1KXMPLVqWeEG6z+t2pPQo2pGU5Mf8VnRVKD9H+nerTpKvyL+/KEoHGnGnAZV/0cjMSZeB1cNLtncLla6oFz/z7R4KPL2ycrEZ+mzTYvVPdpgLS4qViEpS+RddmQWAu5eBv2cCA78GnGrJ/+OazvfqAiAzUeodV7w3w7Z3gTsnpAI3P7NYfA8WQQIQ/Z9UtBdf5uQl5XPPRvrNh62QLrQ4+wL2bmX3YKts74qKFm8ObkDII9JDS50P3Luqf/xx9yIAURrjJfkacH5z0To7lTQOTLtJRa/XFFR9PIbK3I6QHi/l+swkoNXoouV/TC05Ho2Lv1Sc+7fRX95/buXis6T8KVOsgijqhuer09LS0qBSqZCamgoXFxe5wyFLkHIT+LaN9CUa2AkYtkxKIIbIURRXhrHnKBULBwhRWBUlqKSrwPFlhWfMEwp/JgK5qdL6x78suq/s1mFgWd+K7WvsViA1urBYLyzK7V3NY1DB4p9rWiwwea90UFhR6gIpyWvP2MeflX7PSJCuSrx/pyiBb50CnP+98L665kX32Hk2kc5+VzTO4v/+ogik3Cg6u669qp6dLL2u7URgwFfS7/nZwOJHpf36tpSSuE9zwM5E36fm/n+quGrEytxkfPxMqVJEEfipp3S7j7OfNLuEdtYKQ23N/XvJmPleFKUTzHlZgLN30XLttjMK83x6fGGvOFE6Xpqwrajt3CbSVfLyPLcPSL4uXbHWXkV38pZ6vsmturkeADLuAglni12lj5LGe9EUAE8uBh4uPDl+fR/wy2DAvWGxMXMK872zT+nHPqXdjvDcPukE+/0Yabk238efKRoUzsYZeDe66ATI9vel96m9mu7bouK3rFWWJfyf0qqhXG8Gf/FEFso1WLoX/veXgOhDhdPJLQeCOhW1MXZRbGyVnaNUo5YSifaLKeUWcGadlKC1xbg2WRfkAP0+l0bnB6R70w5/ZzgOKzup+NNyfwh49ANpio9L26QzvKUNDGLnAjQYU40PwYSKn5Wtyhe60grwaiI9il8FykiUivriZ94Tzkkj49/cLz20FNZSAT95d9H+C3Kl30v8+xcOFKP9989KBr4xMOexwgrwair1YNCytgdeOly591cdgmAZyRywrFiJSJ8gAIMWAOuekXoYLesH9PkMiHiuqFAy91wPVC7fa9RAXqb+ydeD30i9rooX5BkJ0r3agR2BCduL2p5cabggF5Ql83jXN6TP9cou6WRxWYOAhT9ZlXduetXN9YDUo8PpUSD00aJlBbnA3Uv6/z53L0mfT9Il6RH1W9E6B3fpb7Vx4cWP/GwACuDW/vLnJP9jKnB11wPvSwF4NJZuM8jPLLoY0/ezyr+/qrKk/FlDsbJ4J6qOsCek+5HXPQMkngeWDwB6fwR0eAm4/k/Fi+KaVuLesge+zKM2Ahe2FF4hTygszhOkArzv/4oK8vR4aZC20mSnFP3uGgJ0fKXwbLmPdJbeyUfq8man0j9b7OQJPPKW9Ptjn1j+IGDG/kJ38ip5j/i4rVLXO91V+ijpLH5OqtQLovj+Vxbec68peGDgvgc6Yjm6SydSbF2Kzq77tZT+5i0lmRIRVZdXE2nmmc2vSD2ctr0NxPwHDPgauP2f+eZ6oPx8f3Sx9DM9Qcr5GQnSveL1I4CJO4q2899C6WqrIXpTc0E6BtIUSFfGnb2ln04+UjdyhVK/rbbHnaE463qut7IteX9+xGSg6YCiHK+9Un/vqtS7ofgV8L9nAf/9oA1O+lHaZ1q/nXRbgzbX+7SQBuvjVHdmh93mC7EbHVVLXiaw9XXg7Hrpub2rVLg+mHy6TJOuVmoKiq5iN+ojXcUEgMSLwJk1hesK14vqovYtRhQNoBN/Ftj7P+kMbPHtadTSayImS1NcAVIXqI3PS+vz0qUrqsVH/6yMLtOKRkhNj5cGi3PyKerCVjxZG3OO3PK6fFFJ2vvTMxKLprW7tgdYObTsg6Lin6lGY7mj3dcCzE3Gx8+UqkwUgSM/SLNliGppfBV1bslc33Wa1MW+eG52CwHCBhW1+Xtm0f3LuvxdIOV0j4ZAl6lFbTdMkAYFLd5G+7tnU2Dw90VtlzwmXfXWqKXu7LlpVSuC3RoAr50ser53jvRetXlem+sdvYw7iC9zfdXkZ0vj5HiFFQ2y+79gICelzJfxczUP7DZPVNNsHIGWo6XRaVNvS929gZIJ88BXJV/r7FNUvCdfBw7MK30/fq2Kivese/pTjzyoSf+i3wvypFHZKyq4q9TVuvgZc+2V8uJndZ19gEHfl74dY7KkQUzMhSAA9QKkh9a2dyp3IMfCnYhIIghSvnYLBe5dLpqz+sHv1P0Gcn2jfvrF++EF+nNeFxfcVb94v/aPfk+2sqTG6s/0UZ6wIYBPs6Jcrx0AzuGBe5i7v1PxbVYHc33VWNtLs+QUN2wZsPP/pNvqSps/nSwOi3ciY9n2jlS4Ayj1CzK4q9RtTFBK9w0rlEC9YtOTuYVI3c0USv02Civp3qPio3h6NAL6f1Vsvba9QvrpHV7U1rOR1K1aUAJxZ6SB45IulX5v2WOfmO+ZWGPcW1aX9ZsD7J5lud0SiYjktO0dqXAvS3BX6f5jbX5WWJWcl7rjS1L+1cvfhT+Ln3AFpPFj1PnF2hTbrr2rftsRK6Wr7gql9D3/3yLp5H1p+b7LFPPM98z11RfaA3jhoOXfjkB62G2+ELvRUbVd21N+UWQu3ZPKu7fMXOIk0+C/v8VgbjI+fqZULZaU6wF+35OEtyOYtcrkJfaHJDKW0B7A5D3S3NvaAUZ0A8OYGe0Z7Qfj5VdC3cB/fyKiqrGkXA/w+54kD/4d+LWQbpHg7QgWh93miYzJ0L1axc9wmhveW1a38d+fiKjyLC3XA/y+JwlvR7B4LN6JTMHSkiS/zOs2/vsTEVWepeV6gN/3JLGk+dNJD4t3IlOytCTJL/O6jf/+RESVZ2m5HuD3PZGF4g0vRDWBSZKIiKh2Y64nIhNj8U5ERERERERk5li8ExEREREREZk5Fu9EREREREREZo7FOxEREREREZGZY/FOREREREREZOZYvBMRERERERGZOc7zXkgURQBAWlqazJEQERFJtDlJm6Oo+pjviYjInFQm17N4L5Seng4ACAgIkDkSIiIifenp6VCpVHKHUSsw3xMRkTmqSK4XRJ7OBwBoNBrcuXMHzs7OEARB7nBqTFpaGgICAhATEwMXFxe5w6k1+LkaHz9T4+NnahrG/FxFUUR6ejr8/PygUPBON2Ooi/me/9dNg5+r8fEzNQ1+rsYnV67nlfdCCoUC9evXlzsM2bi4uPA/swnwczU+fqbGx8/UNIz1ufKKu3HV5XzP/+umwc/V+PiZmgY/V+Or6VzP0/hEREREREREZo7FOxEREREREZGZY/Fex9na2mLGjBmwtbWVO5RahZ+r8fEzNT5+pqbBz5XMDf8mTYOfq/HxMzUNfq7GJ9dnygHriIiIiIiIiMwcr7wTERERERERmTkW70RERERERERmjsU7ERERERERkZlj8U5ERERERERk5li811GzZ89Gu3bt4OzsDC8vLwwePBiXLl2SO6xa5X//+x8EQcCUKVPkDsXixcbGYsyYMXB3d4e9vT2aN2+OY8eOyR2WxVKr1Zg+fTpCQkJgb2+P0NBQfPzxx+D4pZXz77//YuDAgfDz84MgCPj999/11ouiiA8//BC+vr6wt7dHr169cOXKFXmCpTqJud70mOuNh7neuJjrjcPccj2L9zpq3759ePnll3HkyBHs2rUL+fn5eOyxx5CZmSl3aLXC0aNH8eOPP+Lhhx+WOxSLl5KSgs6dO8Pa2hrbtm3D+fPnMXfuXLi6usodmsWaM2cOfvjhB3z33Xe4cOEC5syZg88//xzffvut3KFZlMzMTLRo0QLff/+9wfWff/45vvnmGyxcuBD//fcfHB0d0adPH+Tk5NRwpFRXMdebFnO98TDXGx9zvXGYW67nVHEEALh79y68vLywb98+PPLII3KHY9EyMjLQunVrLFiwAJ988glatmyJ+fPnyx2WxXr33Xdx8OBB7N+/X+5Qao0BAwbA29sbS5Ys0S0bOnQo7O3tsXLlShkjs1yCIGDTpk0YPHgwAOlMvJ+fH9544w28+eabAIDU1FR4e3tj+fLlGDFihIzRUl3FXG88zPXGxVxvfMz1xmcOuZ5X3gmA9IcGAG5ubjJHYvlefvll9O/fH7169ZI7lFphy5YtaNu2LYYNGwYvLy+0atUKixcvljssi9apUyfs3r0bly9fBgCcPn0aBw4cQL9+/WSOrPa4ceMG4uPj9b4HVCoV2rdvj8OHD8sYGdVlzPXGw1xvXMz1xsdcb3py5Hork2yVLIpGo8GUKVPQuXNnhIeHyx2ORVuzZg1OnDiBo0ePyh1KrXH9+nX88MMPmDZtGt5//30cPXoUr732GmxsbDBu3Di5w7NI7777LtLS0tCkSRMolUqo1Wp8+umnGD16tNyh1Rrx8fEAAG9vb73l3t7eunVENYm53niY642Pud74mOtNT45cz+Kd8PLLLyMqKgoHDhyQOxSLFhMTg9dffx27du2CnZ2d3OHUGhqNBm3btsVnn30GAGjVqhWioqKwcOFCJvQqWrduHVatWoXVq1ejWbNmOHXqFKZMmQI/Pz9+pkS1FHO9cTDXmwZzvfEx19dO7DZfx73yyiv4448/sGfPHtSvX1/ucCza8ePHkZiYiNatW8PKygpWVlbYt28fvvnmG1hZWUGtVssdokXy9fVFWFiY3rKmTZsiOjpapogs31tvvYV3330XI0aMQPPmzfHMM89g6tSpmD17ttyh1Ro+Pj4AgISEBL3lCQkJunVENYW53niY602Dud74mOtNT45cz+K9jhJFEa+88go2bdqEf/75ByEhIXKHZPF69uyJs2fP4tSpU7pH27ZtMXr0aJw6dQpKpVLuEC1S586dS0xtdPnyZQQFBckUkeXLysqCQqH/9a9UKqHRaGSKqPYJCQmBj48Pdu/erVuWlpaG//77Dx07dpQxMqpLmOuNj7neNJjrjY+53vTkyPXsNl9Hvfzyy1i9ejU2b94MZ2dn3X0ZKpUK9vb2MkdnmZydnUvcR+jo6Ah3d3feX1gNU6dORadOnfDZZ59h+PDhiIyMxKJFi7Bo0SK5Q7NYAwcOxKefforAwEA0a9YMJ0+exFdffYUJEybIHZpFycjIwNWrV3XPb9y4gVOnTsHNzQ2BgYGYMmUKPvnkEzRs2BAhISGYPn06/Pz8dKPUEpkac73xMdebBnO98THXG4fZ5XqR6iQABh/Lli2TO7RapVu3buLrr78udxgWb+vWrWJ4eLhoa2srNmnSRFy0aJHcIVm0tLQ08fXXXxcDAwNFOzs7sUGDBuL//d//ibm5uXKHZlH27Nlj8Ht03LhxoiiKokajEadPny56e3uLtra2Ys+ePcVLly7JGzTVKcz1NYO53jiY642Lud44zC3Xc553IiIiIiIiIjPHe96JiIiIiIiIzByLdyIiIiIiIiIzx+KdiIiIiIiIyMyxeCciIiIiIiIycyzeiYiIiIiIiMwci3ciIiIiIiIiM8finYiIiIiIiMjMsXgnquUEQSj38eyzz8odZrlmzpwJQRCwfPlyuUMhIiIyK8z1RHWDldwBEFHNGDduXKnrunTpUoOREBERkSkw1xPVbizeieoInsUmIiKq3ZjriWo3dpsnIiIiIiIiMnMs3omoBEEQEBwcjLy8PMyYMQOhoaGws7NDgwYN8OGHHyInJ8fg6+7du4e33noLDRs2hJ2dHdzc3NC3b1/s3Lmz1H3du3cP//d//4fmzZvD0dERLi4uaN68Od5++23ExcUZfM3Zs2fxxBNPwNXVFY6OjujWrRsOHTpklPdORERUFzDXE1keFu9EZJAoihg6dCi++OILhIWFoX///khOTsbHH3+MAQMGQK1W67WPjY1FREQEvvzyS+Tl5WHw4MFo1aoV/v77b/Tp0wfz5s0rsY8LFy6gZcuW+Oyzz5CUlIQ+ffqgV69eEEURX3zxBf77778Srzl27Bg6dOiAmzdvok+fPmjYsCH+/fdf9OzZE1FRUSb7PIiIiGob5noiCyMSUa0GQKzsf3Xta+rXry9eu3ZNtzwxMVEMDw8XAYjz5s3Te82AAQNEAOKoUaPE3Nxc3fL9+/eLDg4OolKpFE+ePKlbnp+fLzZu3FgEIE6ZMkXvNaIoilFRUeLVq1d1z2fMmKGL6+uvv9ZrO2XKFBGA+Mwzz1TqfRIREdUGzPVEdQOLd6JaTpsEy3ps2rTJ4GsWLVpUYnvbtm0TAYihoaG6ZdeuXRMBiE5OTuK9e/dKvGbatGkiAHHSpEm6ZWvXrhUBiM2aNRMLCgrKfR/ahN65c+cS65KSkkQAYlBQULnbISIiqm2Y64nqBo42T1RHlDV9TGBgoMHlI0aMKLGsb9++cHV1xbVr1xAXFwdfX18cOHBAt87Nza3Ea5555hl89dVX2L9/v27Z33//DQCYNGkSlEplhd/HY489VmKZu7s73NzcSr1vjoiIqC5grieq3Vi8E9URlZ0+xtXVFc7OzgbXBQUFISUlBXfu3IGvry/u3LkDAAgODjbYXrs8NjZWtywmJgYAEBoaWqm46tevb3C5s7MzkpOTK7UtIiKi2oS5nqh244B1RGRygiAYbVsKBb+2iIiIzA1zPZHp8X8GERmUkpKC9PR0g+uio6MBAH5+fno/b926ZbD9zZs3AQD+/v66ZQEBAQCAa9euGSVeIiIiqhzmeiLLwuKdiEq1bt26Est27tyJ5ORkNGjQAL6+vgCALl26AAC2b9+O+/fvl3jNypUrAQBdu3bVLevVqxcAYMmSJdBoNMYOnYiIiCqAuZ7IcrB4J6JSzZo1S3cmHQCSkpLw1ltvAQBefvll3fIGDRqgf//+SE9Px+uvv478/HzdusOHD+OHH36AUqnUe82TTz6JRo0aISoqCm+//bbeawDg3LlzuH79uoneGREREQHM9USWhAPWEdURzz77bKnrAgMD8dFHH5VY9vDDD6NZs2bo2bMnrK2t8c8//+D+/fvo0aMHXnvtNb32P/74I7p27Yqff/4Z+/btQ8eOHXH37l3s3bsXarUac+fORcuWLXXtrays8Ntvv6F3796YO3cuVq9ejY4dO0IURVy5cgVRUVHYtGkTGjRoYMyPgYiIqNZirieq5eSeq46ITAsVmPu1RYsWJV4TFBQk5uTkiO+//74YHBws2tj8f3t3jBohEAVgODZipzeYQrDzGl5IwcLD7Dk8kQjWti9VAoFNG95mv68WncrhH2ewjlJKbNsW930/fdZ1XTHPc/R9H3VdR9d1MU1T7Pv+6/jO84xlWWIYhmiaJtq2jXEcY13XOI7j+7qvf78+Ho+n9ymlhFcaAO/IXA/voYqI+LulAuAVVFX1UUr5sY0OAPg/zPXwepx5BwAAgOTEOwAAACQn3gEAACA5Z94BAAAgOV/eAQAAIDnxDgAAAMmJdwAAAEhOvAMAAEBy4h0AAACSE+8AAACQnHgHAACA5MQ7AAAAJCfeAQAAILlP0Aqx/va9waAAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 16s 1s/step - loss: 0.4656 - MCRMSE: 0.4621\n",
            "\n",
            "Evaluate Test Metrics:\n",
            "=================================\n",
            "\n",
            "Test loss: 0.4656\n",
            "\n",
            "Test MCRMSE score: 0.4621 \n",
            "\n",
            "13/13 [==============================] - 20s 1s/step\n",
            "\n",
            "******************************************************\n",
            "Regression with BERT: Number of Unfrozen Layers = 4\n",
            "******************************************************\n",
            "\n",
            "Training Regression with BERT.....\n",
            "=====================================\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "193/391 [=============>................] - ETA: 1:30 - loss: 0.9458 - MCRMSE: 0.9458"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-86-da1c1ebb131a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m run_regression_experiment(num_train_layers=np.arange(2,13,2),\n\u001b[0m\u001b[1;32m      2\u001b[0m                           \u001b[0mnum_hidden_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                           \u001b[0mnum_hidden_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                           \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                           \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.00005\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.00001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.000001\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-68-a88862d44a5a>\u001b[0m in \u001b[0;36mrun_regression_experiment\u001b[0;34m(num_train_layers, num_hidden_layer, num_hidden_units, dropout, learning_rate, batch_size, epochs)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m# train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mdf_regression_model_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregression_with_bert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nPlotting loss and MCRMSE...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mplot_loss_mcrmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_regression_model_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'MCRMSE'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-76-7b5a9fd9cb90>\u001b[0m in \u001b[0;36mtrain_regression\u001b[0;34m(model, batch_size, epochs)\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mcallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training Regression with BERT.....\\n====================================='\u001b[0m  \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   regression_model_history = model.fit([train_encodings.input_ids, \n\u001b[0m\u001b[1;32m     13\u001b[0m                                         \u001b[0mtrain_encodings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                                         ], \n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1654\u001b[0m                             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1655\u001b[0m                             \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1656\u001b[0;31m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1657\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1658\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1168\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m             \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1170\u001b[0;31m             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1171\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 665\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m         \u001b[0;31m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0;31m# as-is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \"\"\"\n\u001b[1;32m   1154\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1155\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1156\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1119\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}